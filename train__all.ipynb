{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e9a124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, json\n",
    "from harmonization_env_package.harmonization_environment import *\n",
    "\n",
    "device = 'cpu'\n",
    "melody = torch.tensor([60, 62, 64, 65, 67, 69, 71, 72], dtype = torch.int32)\n",
    "melody += 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed921e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shared: 13600 params \n",
      " actor head: 2492 params \n",
      " critic head: 1969 params \n",
      " total: 18062\n",
      " \n",
      " encoder: 14829 params \n",
      " decoder: 19806 params \n",
      " actor head: 1852 params \n",
      " critic head: 1561 params \n",
      " total: 38049\n",
      " \n",
      " encoder: 11565 params \n",
      " decoder: 13278 params \n",
      " lstm encoder: 7192 params \n",
      " lstm decoder: 6224 params \n",
      " actor head: 1116 params \n",
      " critic head: 393 params \n",
      " total: 39769\n"
     ]
    }
   ],
   "source": [
    "env = HarmonizationEnv(melody, device)\n",
    "\n",
    "net_ac = NetAC(path = 'ac_params_low_entr.pth')\n",
    "net_ae = NetAE(path = 'ae_params.pth')\n",
    "net_m = NetM(path = 'm_params.pth')\n",
    "\n",
    "agent_ac = Agent(env, net_ac, entropy_weight = 0.01)\n",
    "agent_ae = Agent(env, net_ae, entropy_weight = 0.1)\n",
    "# agent_m = Agent(env, net_m)\n",
    "\n",
    "print(net_ac.info)\n",
    "print(' ')\n",
    "print(net_ae.info)\n",
    "print(' ')\n",
    "print(net_m.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26bcfbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent, num_iterations, iter_per_batch, blocks):\n",
    "\n",
    "    progresses = []\n",
    "\n",
    "    for i in range(len(num_iterations)):\n",
    "\n",
    "        prog = agent.train(\n",
    "            num_iterations = num_iterations[i],\n",
    "            check_step = 10,\n",
    "            iter_per_batch = iter_per_batch[i],\n",
    "            save = True,\n",
    "            track_progress = True,\n",
    "            blocks = blocks[i]\n",
    "        )\n",
    "\n",
    "        progresses.append(prog)\n",
    "\n",
    "    progress = {'info' : agent.net.info, 'type' : agent.net.type_}\n",
    "    progress['loss'] = {}\n",
    "\n",
    "    for key in progresses[0].keys():\n",
    "\n",
    "        if key == \"loss\": continue\n",
    "        \n",
    "        progress[key] = []\n",
    "        for i in range(len(progresses)): progress[key] += progresses[i][key]\n",
    "       \n",
    "\n",
    "    for key in progresses[0]['loss'].keys():\n",
    "\n",
    "        progress['loss'][key] = []\n",
    "        for i in range(len(progresses)): progress['loss'][key] += progresses[i]['loss'][key]\n",
    "    \n",
    "    return progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f98668e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter: 0/8000, grad norm: 0.007. Training block: full\n",
      "actor: 0.099, critic: 0.243, entropy: -2.131, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.305\n",
      "\n",
      "n_iter: 10/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.015, critic: 0.170, entropy: -2.115, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.332\n",
      "\n",
      "n_iter: 20/8000, grad norm: 0.004. Training block: full\n",
      "actor: 0.009, critic: 0.165, entropy: -2.107, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.336\n",
      "\n",
      "n_iter: 30/8000, grad norm: 0.003. Training block: full\n",
      "actor: -0.037, critic: 0.142, entropy: -2.077, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.346\n",
      "\n",
      "n_iter: 40/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.034, critic: 0.143, entropy: -2.081, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.319\n",
      "\n",
      "n_iter: 50/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.069, critic: 0.134, entropy: -2.064, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.362\n",
      "\n",
      "n_iter: 60/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.080, critic: 0.130, entropy: -2.037, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.378\n",
      "\n",
      "n_iter: 70/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.115, critic: 0.126, entropy: -2.018, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.391\n",
      "\n",
      "n_iter: 80/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.141, critic: 0.127, entropy: -2.005, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.410\n",
      "\n",
      "n_iter: 90/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.085, critic: 0.127, entropy: -1.994, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.393\n",
      "\n",
      "n_iter: 100/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.061, critic: 0.125, entropy: -1.981, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.383\n",
      "\n",
      "n_iter: 110/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.064, critic: 0.133, entropy: -1.968, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.397\n",
      "\n",
      "n_iter: 120/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.084, critic: 0.125, entropy: -1.941, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.406\n",
      "\n",
      "n_iter: 130/8000, grad norm: 0.003. Training block: full\n",
      "actor: -0.094, critic: 0.139, entropy: -1.907, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.427\n",
      "\n",
      "n_iter: 140/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.052, critic: 0.153, entropy: -1.908, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.373\n",
      "\n",
      "n_iter: 150/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.075, critic: 0.125, entropy: -1.881, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.423\n",
      "\n",
      "n_iter: 160/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.083, critic: 0.125, entropy: -1.873, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.432\n",
      "\n",
      "n_iter: 170/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.134, critic: 0.127, entropy: -1.848, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.457\n",
      "\n",
      "n_iter: 180/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.112, critic: 0.127, entropy: -1.815, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.455\n",
      "\n",
      "n_iter: 190/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.129, critic: 0.124, entropy: -1.782, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.459\n",
      "\n",
      "n_iter: 200/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.088, critic: 0.142, entropy: -1.754, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.463\n",
      "\n",
      "n_iter: 210/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.051, critic: 0.143, entropy: -1.759, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.453\n",
      "\n",
      "n_iter: 220/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.046, critic: 0.156, entropy: -1.752, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.419\n",
      "\n",
      "n_iter: 230/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.001, critic: 0.157, entropy: -1.741, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.442\n",
      "\n",
      "n_iter: 240/8000, grad norm: 0.003. Training block: full\n",
      "actor: -0.069, critic: 0.137, entropy: -1.696, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.462\n",
      "\n",
      "n_iter: 250/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.112, critic: 0.128, entropy: -1.651, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.492\n",
      "\n",
      "n_iter: 260/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.072, critic: 0.136, entropy: -1.638, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.483\n",
      "\n",
      "n_iter: 270/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.105, critic: 0.124, entropy: -1.611, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.497\n",
      "\n",
      "n_iter: 280/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.098, critic: 0.125, entropy: -1.607, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.496\n",
      "\n",
      "n_iter: 290/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.071, critic: 0.132, entropy: -1.620, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.488\n",
      "\n",
      "n_iter: 300/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.119, critic: 0.122, entropy: -1.557, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.513\n",
      "\n",
      "n_iter: 310/8000, grad norm: 0.003. Training block: full\n",
      "actor: -0.015, critic: 0.157, entropy: -1.548, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.477\n",
      "\n",
      "n_iter: 320/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.017, critic: 0.172, entropy: -1.520, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.476\n",
      "\n",
      "n_iter: 330/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.075, critic: 0.131, entropy: -1.505, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 340/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.083, critic: 0.150, entropy: -1.457, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.519\n",
      "\n",
      "n_iter: 350/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.111, critic: 0.116, entropy: -1.447, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.526\n",
      "\n",
      "n_iter: 360/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.086, critic: 0.129, entropy: -1.434, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.525\n",
      "\n",
      "n_iter: 370/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.093, critic: 0.136, entropy: -1.406, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.530\n",
      "\n",
      "n_iter: 380/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.101, critic: 0.113, entropy: -1.415, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.533\n",
      "\n",
      "n_iter: 390/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.118, critic: 0.113, entropy: -1.383, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.544\n",
      "\n",
      "n_iter: 400/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.120, critic: 0.115, entropy: -1.344, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.553\n",
      "\n",
      "n_iter: 410/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.072, critic: 0.133, entropy: -1.356, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.531\n",
      "\n",
      "n_iter: 420/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.107, critic: 0.114, entropy: -1.315, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.552\n",
      "\n",
      "n_iter: 430/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.114, critic: 0.110, entropy: -1.293, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.555\n",
      "\n",
      "n_iter: 440/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.099, critic: 0.110, entropy: -1.304, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.553\n",
      "\n",
      "n_iter: 450/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.112, critic: 0.109, entropy: -1.252, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.565\n",
      "\n",
      "n_iter: 460/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.081, critic: 0.120, entropy: -1.234, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.560\n",
      "\n",
      "n_iter: 470/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.085, critic: 0.128, entropy: -1.207, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.565\n",
      "\n",
      "n_iter: 480/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.104, critic: 0.197, entropy: -1.269, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.487\n",
      "\n",
      "n_iter: 490/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.075, critic: 0.115, entropy: -1.176, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.568\n",
      "\n",
      "n_iter: 500/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.093, critic: 0.108, entropy: -1.158, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.577\n",
      "\n",
      "n_iter: 510/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.031, critic: 0.133, entropy: -1.173, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.559\n",
      "\n",
      "n_iter: 520/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.072, critic: 0.109, entropy: -1.145, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.576\n",
      "\n",
      "n_iter: 530/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.017, critic: 0.156, entropy: -1.142, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.547\n",
      "\n",
      "n_iter: 540/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.082, critic: 0.107, entropy: -1.108, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.583\n",
      "\n",
      "n_iter: 550/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.048, critic: 0.126, entropy: -1.114, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.573\n",
      "\n",
      "n_iter: 560/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.070, critic: 0.116, entropy: -1.089, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.581\n",
      "\n",
      "n_iter: 570/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.100, critic: 0.107, entropy: -1.071, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.594\n",
      "\n",
      "n_iter: 580/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.089, critic: 0.201, entropy: -1.080, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.526\n",
      "\n",
      "n_iter: 590/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.095, critic: 0.106, entropy: -1.038, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.598\n",
      "\n",
      "n_iter: 600/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.082, critic: 0.096, entropy: -1.030, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.591\n",
      "\n",
      "n_iter: 610/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.060, critic: 0.112, entropy: -1.025, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.588\n",
      "\n",
      "n_iter: 620/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.064, critic: 0.110, entropy: -0.986, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.596\n",
      "\n",
      "n_iter: 630/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.012, critic: 0.142, entropy: -1.024, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.570\n",
      "\n",
      "n_iter: 640/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.050, critic: 0.123, entropy: -0.965, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.594\n",
      "\n",
      "n_iter: 650/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.087, critic: 0.107, entropy: -0.932, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.613\n",
      "\n",
      "n_iter: 660/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.033, critic: 0.132, entropy: -0.937, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.597\n",
      "\n",
      "n_iter: 670/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.044, critic: 0.180, entropy: -0.926, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 680/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.072, critic: 0.108, entropy: -0.910, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.609\n",
      "\n",
      "n_iter: 690/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.084, critic: 0.104, entropy: -0.878, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.621\n",
      "\n",
      "n_iter: 700/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.069, critic: 0.115, entropy: -0.866, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.614\n",
      "\n",
      "n_iter: 710/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.103, critic: 0.096, entropy: -0.844, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.632\n",
      "\n",
      "n_iter: 720/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.096, critic: 0.101, entropy: -0.816, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.627\n",
      "\n",
      "n_iter: 730/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.032, critic: 0.120, entropy: -0.849, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.607\n",
      "\n",
      "n_iter: 740/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.086, critic: 0.103, entropy: -0.815, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.631\n",
      "\n",
      "n_iter: 750/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.105, critic: 0.219, entropy: -0.798, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.571\n",
      "\n",
      "n_iter: 760/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.073, critic: 0.097, entropy: -0.787, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.632\n",
      "\n",
      "n_iter: 770/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.002, critic: 0.140, entropy: -0.760, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.608\n",
      "\n",
      "n_iter: 780/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.051, critic: 0.108, entropy: -0.741, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.628\n",
      "\n",
      "n_iter: 790/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.098, critic: 0.193, entropy: -0.789, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.573\n",
      "\n",
      "n_iter: 800/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.115, critic: 0.220, entropy: -0.787, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.570\n",
      "\n",
      "n_iter: 810/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.090, critic: 0.092, entropy: -0.700, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.646\n",
      "\n",
      "n_iter: 820/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.039, critic: 0.114, entropy: -0.711, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.625\n",
      "\n",
      "n_iter: 830/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.087, critic: 0.174, entropy: -0.728, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.587\n",
      "\n",
      "n_iter: 840/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.031, critic: 0.161, entropy: -0.683, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.614\n",
      "\n",
      "n_iter: 850/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.082, critic: 0.098, entropy: -0.653, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.651\n",
      "\n",
      "n_iter: 860/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.072, critic: 0.097, entropy: -0.662, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.651\n",
      "\n",
      "n_iter: 870/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.007, critic: 0.122, entropy: -0.698, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.624\n",
      "\n",
      "n_iter: 880/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.160, critic: 0.201, entropy: -0.759, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.554\n",
      "\n",
      "n_iter: 890/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.037, critic: 0.155, entropy: -0.639, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.613\n",
      "\n",
      "n_iter: 900/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.080, critic: 0.096, entropy: -0.619, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.655\n",
      "\n",
      "n_iter: 910/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.002, critic: 0.108, entropy: -0.669, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.624\n",
      "\n",
      "n_iter: 920/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.048, critic: 0.112, entropy: -0.624, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.648\n",
      "\n",
      "n_iter: 930/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.032, critic: 0.092, entropy: -0.634, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.640\n",
      "\n",
      "n_iter: 940/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.010, critic: 0.136, entropy: -0.602, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.633\n",
      "\n",
      "n_iter: 950/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.019, critic: 0.118, entropy: -0.604, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.638\n",
      "\n",
      "n_iter: 960/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.022, critic: 0.145, entropy: -0.594, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.623\n",
      "\n",
      "n_iter: 970/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.074, critic: 0.094, entropy: -0.568, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.661\n",
      "\n",
      "n_iter: 980/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.085, critic: 0.095, entropy: -0.565, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.665\n",
      "\n",
      "n_iter: 990/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.069, critic: 0.093, entropy: -0.562, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.660\n",
      "\n",
      "n_iter: 1000/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.046, critic: 0.100, entropy: -0.560, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.650\n",
      "\n",
      "n_iter: 1010/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.059, critic: 0.089, entropy: -0.562, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.660\n",
      "\n",
      "n_iter: 1020/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.048, critic: 0.109, entropy: -0.521, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.660\n",
      "\n",
      "n_iter: 1030/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.040, critic: 0.113, entropy: -0.549, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.656\n",
      "\n",
      "n_iter: 1040/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.079, critic: 0.086, entropy: -0.532, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.671\n",
      "\n",
      "n_iter: 1050/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.044, critic: 0.112, entropy: -0.541, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.658\n",
      "\n",
      "n_iter: 1060/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.091, entropy: -0.533, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.663\n",
      "\n",
      "n_iter: 1070/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.075, critic: 0.091, entropy: -0.501, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.676\n",
      "\n",
      "n_iter: 1080/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.023, critic: 0.111, entropy: -0.516, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.655\n",
      "\n",
      "n_iter: 1090/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.018, critic: 0.123, entropy: -0.547, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.636\n",
      "\n",
      "n_iter: 1100/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.141, critic: 0.194, entropy: -0.568, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.582\n",
      "\n",
      "n_iter: 1110/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.077, critic: 0.095, entropy: -0.493, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.672\n",
      "\n",
      "n_iter: 1120/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.066, critic: 0.093, entropy: -0.509, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.667\n",
      "\n",
      "n_iter: 1130/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.053, critic: 0.160, entropy: -0.548, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.627\n",
      "\n",
      "n_iter: 1140/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.065, critic: 0.087, entropy: -0.509, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.669\n",
      "\n",
      "n_iter: 1150/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.110, critic: 0.192, entropy: -0.563, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.600\n",
      "\n",
      "n_iter: 1160/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.074, critic: 0.098, entropy: -0.509, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.667\n",
      "\n",
      "n_iter: 1170/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.085, critic: 0.191, entropy: -0.537, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.616\n",
      "\n",
      "n_iter: 1180/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.044, critic: 0.176, entropy: -0.499, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.635\n",
      "\n",
      "n_iter: 1190/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.048, critic: 0.099, entropy: -0.512, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.660\n",
      "\n",
      "n_iter: 1200/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.002, critic: 0.139, entropy: -0.504, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.651\n",
      "\n",
      "n_iter: 1210/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.019, critic: 0.135, entropy: -0.472, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.661\n",
      "\n",
      "n_iter: 1220/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.036, critic: 0.100, entropy: -0.494, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.664\n",
      "\n",
      "n_iter: 1230/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.003, critic: 0.124, entropy: -0.461, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.658\n",
      "\n",
      "n_iter: 1240/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.162, critic: 0.213, entropy: -0.541, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.595\n",
      "\n",
      "n_iter: 1250/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.054, critic: 0.162, entropy: -0.490, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.635\n",
      "\n",
      "n_iter: 1260/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.004, critic: 0.117, entropy: -0.473, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.655\n",
      "\n",
      "n_iter: 1270/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.089, entropy: -0.459, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.679\n",
      "\n",
      "n_iter: 1280/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.085, critic: 0.172, entropy: -0.492, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.634\n",
      "\n",
      "n_iter: 1290/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.004, critic: 0.133, entropy: -0.425, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.658\n",
      "\n",
      "n_iter: 1300/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.046, critic: 0.099, entropy: -0.458, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.674\n",
      "\n",
      "n_iter: 1310/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.027, critic: 0.115, entropy: -0.433, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.669\n",
      "\n",
      "n_iter: 1320/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.034, critic: 0.159, entropy: -0.501, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.648\n",
      "\n",
      "n_iter: 1330/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.059, critic: 0.091, entropy: -0.439, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.683\n",
      "\n",
      "n_iter: 1340/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.064, critic: 0.162, entropy: -0.490, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.628\n",
      "\n",
      "n_iter: 1350/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.052, critic: 0.091, entropy: -0.408, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.685\n",
      "\n",
      "n_iter: 1360/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.017, critic: 0.117, entropy: -0.409, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.656\n",
      "\n",
      "n_iter: 1370/8000, grad norm: 0.006. Training block: full\n",
      "actor: 0.149, critic: 0.184, entropy: -0.440, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.602\n",
      "\n",
      "n_iter: 1380/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.028, critic: 0.132, entropy: -0.386, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.656\n",
      "\n",
      "n_iter: 1390/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.026, critic: 0.106, entropy: -0.420, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.678\n",
      "\n",
      "n_iter: 1400/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.057, critic: 0.087, entropy: -0.414, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.685\n",
      "\n",
      "n_iter: 1410/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.044, critic: 0.097, entropy: -0.420, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.680\n",
      "\n",
      "n_iter: 1420/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.096, entropy: -0.402, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.687\n",
      "\n",
      "n_iter: 1430/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.007, critic: 0.127, entropy: -0.391, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.667\n",
      "\n",
      "n_iter: 1440/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.038, critic: 0.094, entropy: -0.412, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.676\n",
      "\n",
      "n_iter: 1450/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.125, critic: 0.207, entropy: -0.433, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.625\n",
      "\n",
      "n_iter: 1460/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.041, critic: 0.145, entropy: -0.457, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.654\n",
      "\n",
      "n_iter: 1470/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.053, critic: 0.082, entropy: -0.395, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.689\n",
      "\n",
      "n_iter: 1480/8000, grad norm: 0.004. Training block: full\n",
      "actor: 0.109, critic: 0.199, entropy: -0.443, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.624\n",
      "\n",
      "n_iter: 1490/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.000, critic: 0.132, entropy: -0.443, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.667\n",
      "\n",
      "n_iter: 1500/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.012, critic: 0.131, entropy: -0.431, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.673\n",
      "\n",
      "n_iter: 1510/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.039, critic: 0.156, entropy: -0.426, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.649\n",
      "\n",
      "n_iter: 1520/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.017, critic: 0.107, entropy: -0.389, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.672\n",
      "\n",
      "n_iter: 1530/8000, grad norm: 0.004. Training block: full\n",
      "actor: 0.173, critic: 0.225, entropy: -0.474, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.609\n",
      "\n",
      "n_iter: 1540/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.021, critic: 0.109, entropy: -0.425, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.676\n",
      "\n",
      "n_iter: 1550/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.036, critic: 0.109, entropy: -0.429, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.681\n",
      "\n",
      "n_iter: 1560/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.126, critic: 0.217, entropy: -0.485, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.618\n",
      "\n",
      "n_iter: 1570/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.001, critic: 0.116, entropy: -0.454, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.664\n",
      "\n",
      "n_iter: 1580/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.113, critic: 0.212, entropy: -0.469, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.628\n",
      "\n",
      "n_iter: 1590/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.033, critic: 0.106, entropy: -0.420, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.680\n",
      "\n",
      "n_iter: 1600/8000, grad norm: 0.004. Training block: full\n",
      "actor: 0.152, critic: 0.241, entropy: -0.511, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.607\n",
      "\n",
      "n_iter: 1610/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.035, critic: 0.082, entropy: -0.435, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.683\n",
      "\n",
      "n_iter: 1620/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.033, critic: 0.104, entropy: -0.409, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.684\n",
      "\n",
      "n_iter: 1630/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.051, critic: 0.085, entropy: -0.425, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.690\n",
      "\n",
      "n_iter: 1640/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.041, critic: 0.097, entropy: -0.420, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.686\n",
      "\n",
      "n_iter: 1650/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.022, critic: 0.099, entropy: -0.425, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.677\n",
      "\n",
      "n_iter: 1660/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.021, critic: 0.117, entropy: -0.420, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.686\n",
      "\n",
      "n_iter: 1670/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.005, critic: 0.121, entropy: -0.450, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.675\n",
      "\n",
      "n_iter: 1680/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.048, critic: 0.152, entropy: -0.432, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.658\n",
      "\n",
      "n_iter: 1690/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.012, critic: 0.120, entropy: -0.425, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.672\n",
      "\n",
      "n_iter: 1700/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.078, critic: 0.182, entropy: -0.437, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.647\n",
      "\n",
      "n_iter: 1710/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.057, critic: 0.170, entropy: -0.422, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.655\n",
      "\n",
      "n_iter: 1720/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.046, critic: 0.091, entropy: -0.423, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.690\n",
      "\n",
      "n_iter: 1730/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.123, critic: 0.184, entropy: -0.413, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.624\n",
      "\n",
      "n_iter: 1740/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.046, critic: 0.144, entropy: -0.422, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.655\n",
      "\n",
      "n_iter: 1750/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.010, critic: 0.119, entropy: -0.404, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.671\n",
      "\n",
      "n_iter: 1760/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.019, critic: 0.107, entropy: -0.388, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.678\n",
      "\n",
      "n_iter: 1770/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.072, critic: 0.084, entropy: -0.381, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.700\n",
      "\n",
      "n_iter: 1780/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.061, critic: 0.083, entropy: -0.400, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.698\n",
      "\n",
      "n_iter: 1790/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.031, critic: 0.107, entropy: -0.405, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.684\n",
      "\n",
      "n_iter: 1800/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.047, critic: 0.091, entropy: -0.370, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.694\n",
      "\n",
      "n_iter: 1810/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.031, critic: 0.144, entropy: -0.403, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.667\n",
      "\n",
      "n_iter: 1820/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.015, critic: 0.106, entropy: -0.385, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.677\n",
      "\n",
      "n_iter: 1830/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.069, critic: 0.088, entropy: -0.367, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.698\n",
      "\n",
      "n_iter: 1840/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.020, critic: 0.120, entropy: -0.386, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.681\n",
      "\n",
      "n_iter: 1850/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.044, critic: 0.159, entropy: -0.405, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.657\n",
      "\n",
      "n_iter: 1860/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.023, critic: 0.117, entropy: -0.377, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.687\n",
      "\n",
      "n_iter: 1870/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.014, critic: 0.109, entropy: -0.363, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.682\n",
      "\n",
      "n_iter: 1880/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.027, critic: 0.141, entropy: -0.418, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.666\n",
      "\n",
      "n_iter: 1890/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.035, critic: 0.163, entropy: -0.366, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.671\n",
      "\n",
      "n_iter: 1900/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.021, critic: 0.135, entropy: -0.398, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.673\n",
      "\n",
      "n_iter: 1910/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.044, critic: 0.092, entropy: -0.343, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.700\n",
      "\n",
      "n_iter: 1920/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.136, critic: 0.207, entropy: -0.423, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.631\n",
      "\n",
      "n_iter: 1930/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.185, critic: 0.241, entropy: -0.437, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.611\n",
      "\n",
      "n_iter: 1940/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.173, critic: 0.242, entropy: -0.427, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.615\n",
      "\n",
      "n_iter: 1950/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.045, critic: 0.169, entropy: -0.363, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.663\n",
      "\n",
      "n_iter: 1960/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.135, critic: 0.211, entropy: -0.415, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.626\n",
      "\n",
      "n_iter: 1970/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.049, critic: 0.179, entropy: -0.391, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.648\n",
      "\n",
      "n_iter: 1980/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.073, critic: 0.081, entropy: -0.315, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.700\n",
      "\n",
      "n_iter: 1990/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.090, critic: 0.171, entropy: -0.401, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.644\n",
      "\n",
      "n_iter: 2000/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.012, critic: 0.109, entropy: -0.330, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.669\n",
      "\n",
      "n_iter: 2010/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.050, critic: 0.099, entropy: -0.313, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.697\n",
      "\n",
      "n_iter: 2020/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.095, critic: 0.189, entropy: -0.391, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.646\n",
      "\n",
      "n_iter: 2030/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.062, critic: 0.085, entropy: -0.338, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.701\n",
      "\n",
      "n_iter: 2040/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.068, critic: 0.086, entropy: -0.322, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 2050/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.038, critic: 0.094, entropy: -0.342, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.693\n",
      "\n",
      "n_iter: 2060/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.058, critic: 0.083, entropy: -0.332, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 2070/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.015, critic: 0.135, entropy: -0.364, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.673\n",
      "\n",
      "n_iter: 2080/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.008, critic: 0.119, entropy: -0.376, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.690\n",
      "\n",
      "n_iter: 2090/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.069, critic: 0.159, entropy: -0.357, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.664\n",
      "\n",
      "n_iter: 2100/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.000, critic: 0.115, entropy: -0.353, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.683\n",
      "\n",
      "n_iter: 2110/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.053, critic: 0.083, entropy: -0.354, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.702\n",
      "\n",
      "n_iter: 2120/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.055, critic: 0.159, entropy: -0.364, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.658\n",
      "\n",
      "n_iter: 2130/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.175, critic: 0.241, entropy: -0.453, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.616\n",
      "\n",
      "n_iter: 2140/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.062, critic: 0.174, entropy: -0.369, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.660\n",
      "\n",
      "n_iter: 2150/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.013, critic: 0.118, entropy: -0.322, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.687\n",
      "\n",
      "n_iter: 2160/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.019, critic: 0.120, entropy: -0.377, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.678\n",
      "\n",
      "n_iter: 2170/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.041, critic: 0.101, entropy: -0.349, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.699\n",
      "\n",
      "n_iter: 2180/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.168, critic: 0.248, entropy: -0.408, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.627\n",
      "\n",
      "n_iter: 2190/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.126, critic: 0.217, entropy: -0.381, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.637\n",
      "\n",
      "n_iter: 2200/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.058, critic: 0.085, entropy: -0.343, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.703\n",
      "\n",
      "n_iter: 2210/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.032, critic: 0.098, entropy: -0.369, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.693\n",
      "\n",
      "n_iter: 2220/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.167, critic: 0.239, entropy: -0.428, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.620\n",
      "\n",
      "n_iter: 2230/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.053, critic: 0.099, entropy: -0.319, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.701\n",
      "\n",
      "n_iter: 2240/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.091, critic: 0.184, entropy: -0.366, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.651\n",
      "\n",
      "n_iter: 2250/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.045, critic: 0.101, entropy: -0.338, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.699\n",
      "\n",
      "n_iter: 2260/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.100, critic: 0.181, entropy: -0.399, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.640\n",
      "\n",
      "n_iter: 2270/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.008, critic: 0.126, entropy: -0.329, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.686\n",
      "\n",
      "n_iter: 2280/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.041, critic: 0.107, entropy: -0.339, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.697\n",
      "\n",
      "n_iter: 2290/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.070, critic: 0.086, entropy: -0.298, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.708\n",
      "\n",
      "n_iter: 2300/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.059, critic: 0.088, entropy: -0.312, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 2310/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.104, critic: 0.193, entropy: -0.360, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.642\n",
      "\n",
      "n_iter: 2320/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.002, critic: 0.128, entropy: -0.341, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.688\n",
      "\n",
      "n_iter: 2330/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.132, critic: 0.217, entropy: -0.377, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.642\n",
      "\n",
      "n_iter: 2340/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.030, critic: 0.104, entropy: -0.362, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.691\n",
      "\n",
      "n_iter: 2350/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.013, critic: 0.114, entropy: -0.365, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.685\n",
      "\n",
      "n_iter: 2360/8000, grad norm: 0.004. Training block: full\n",
      "actor: 0.134, critic: 0.212, entropy: -0.359, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.645\n",
      "\n",
      "n_iter: 2370/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.062, critic: 0.083, entropy: -0.329, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.707\n",
      "\n",
      "n_iter: 2380/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.050, critic: 0.097, entropy: -0.316, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.705\n",
      "\n",
      "n_iter: 2390/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.106, critic: 0.205, entropy: -0.397, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.652\n",
      "\n",
      "n_iter: 2400/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.065, critic: 0.189, entropy: -0.375, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.656\n",
      "\n",
      "n_iter: 2410/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.029, critic: 0.124, entropy: -0.348, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.690\n",
      "\n",
      "n_iter: 2420/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.094, critic: 0.193, entropy: -0.344, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.647\n",
      "\n",
      "n_iter: 2430/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.109, critic: 0.197, entropy: -0.372, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.640\n",
      "\n",
      "n_iter: 2440/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.037, critic: 0.110, entropy: -0.351, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.695\n",
      "\n",
      "n_iter: 2450/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.011, critic: 0.138, entropy: -0.366, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.676\n",
      "\n",
      "n_iter: 2460/8000, grad norm: 0.004. Training block: full\n",
      "actor: 0.123, critic: 0.190, entropy: -0.397, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.631\n",
      "\n",
      "n_iter: 2470/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.039, critic: 0.160, entropy: -0.354, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.665\n",
      "\n",
      "n_iter: 2480/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.081, critic: 0.085, entropy: -0.347, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.709\n",
      "\n",
      "n_iter: 2490/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.037, critic: 0.151, entropy: -0.367, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.670\n",
      "\n",
      "n_iter: 2500/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.045, critic: 0.101, entropy: -0.316, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.697\n",
      "\n",
      "n_iter: 2510/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.018, critic: 0.124, entropy: -0.370, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.689\n",
      "\n",
      "n_iter: 2520/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.049, critic: 0.105, entropy: -0.338, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.699\n",
      "\n",
      "n_iter: 2530/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.080, critic: 0.083, entropy: -0.332, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.711\n",
      "\n",
      "n_iter: 2540/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.039, critic: 0.114, entropy: -0.328, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.699\n",
      "\n",
      "n_iter: 2550/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.100, critic: 0.182, entropy: -0.356, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.654\n",
      "\n",
      "n_iter: 2560/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.050, critic: 0.141, entropy: -0.325, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.661\n",
      "\n",
      "n_iter: 2570/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.044, critic: 0.104, entropy: -0.346, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.695\n",
      "\n",
      "n_iter: 2580/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.042, critic: 0.101, entropy: -0.346, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.700\n",
      "\n",
      "n_iter: 2590/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.020, critic: 0.101, entropy: -0.329, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.696\n",
      "\n",
      "n_iter: 2600/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.161, critic: 0.226, entropy: -0.377, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.637\n",
      "\n",
      "n_iter: 2610/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.028, critic: 0.144, entropy: -0.328, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.686\n",
      "\n",
      "n_iter: 2620/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.048, critic: 0.143, entropy: -0.409, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.671\n",
      "\n",
      "n_iter: 2630/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.108, critic: 0.182, entropy: -0.359, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.654\n",
      "\n",
      "n_iter: 2640/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.004, critic: 0.124, entropy: -0.340, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.694\n",
      "\n",
      "n_iter: 2650/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.087, critic: 0.160, entropy: -0.418, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.654\n",
      "\n",
      "n_iter: 2660/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.059, critic: 0.083, entropy: -0.360, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.711\n",
      "\n",
      "n_iter: 2670/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.019, critic: 0.111, entropy: -0.346, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.694\n",
      "\n",
      "n_iter: 2680/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.012, critic: 0.124, entropy: -0.357, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.691\n",
      "\n",
      "n_iter: 2690/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.100, critic: 0.188, entropy: -0.401, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.646\n",
      "\n",
      "n_iter: 2700/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.050, critic: 0.145, entropy: -0.414, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.666\n",
      "\n",
      "n_iter: 2710/8000, grad norm: 0.004. Training block: full\n",
      "actor: 0.154, critic: 0.221, entropy: -0.452, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.621\n",
      "\n",
      "n_iter: 2720/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.050, critic: 0.089, entropy: -0.375, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.703\n",
      "\n",
      "n_iter: 2730/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.054, critic: 0.084, entropy: -0.385, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.707\n",
      "\n",
      "n_iter: 2740/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.041, critic: 0.088, entropy: -0.384, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.705\n",
      "\n",
      "n_iter: 2750/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.017, critic: 0.109, entropy: -0.363, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.692\n",
      "\n",
      "n_iter: 2760/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.032, critic: 0.098, entropy: -0.348, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.703\n",
      "\n",
      "n_iter: 2770/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.057, critic: 0.164, entropy: -0.363, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.673\n",
      "\n",
      "n_iter: 2780/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.027, critic: 0.091, entropy: -0.364, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.697\n",
      "\n",
      "n_iter: 2790/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.037, critic: 0.093, entropy: -0.339, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.701\n",
      "\n",
      "n_iter: 2800/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.057, critic: 0.085, entropy: -0.338, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.708\n",
      "\n",
      "n_iter: 2810/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.043, critic: 0.086, entropy: -0.361, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.708\n",
      "\n",
      "n_iter: 2820/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.035, critic: 0.138, entropy: -0.405, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.677\n",
      "\n",
      "n_iter: 2830/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.005, critic: 0.130, entropy: -0.377, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.689\n",
      "\n",
      "n_iter: 2840/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.023, critic: 0.108, entropy: -0.386, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.695\n",
      "\n",
      "n_iter: 2850/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.046, critic: 0.102, entropy: -0.343, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.705\n",
      "\n",
      "n_iter: 2860/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.092, critic: 0.186, entropy: -0.387, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.656\n",
      "\n",
      "n_iter: 2870/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.042, critic: 0.146, entropy: -0.396, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.668\n",
      "\n",
      "n_iter: 2880/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.021, critic: 0.115, entropy: -0.354, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.694\n",
      "\n",
      "n_iter: 2890/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.016, critic: 0.097, entropy: -0.363, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.696\n",
      "\n",
      "n_iter: 2900/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.051, critic: 0.092, entropy: -0.335, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.712\n",
      "\n",
      "n_iter: 2910/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.088, critic: 0.184, entropy: -0.371, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.663\n",
      "\n",
      "n_iter: 2920/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.001, critic: 0.115, entropy: -0.324, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.696\n",
      "\n",
      "n_iter: 2930/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.024, critic: 0.126, entropy: -0.371, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.682\n",
      "\n",
      "n_iter: 2940/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.023, critic: 0.135, entropy: -0.350, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.685\n",
      "\n",
      "n_iter: 2950/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.040, critic: 0.096, entropy: -0.341, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.702\n",
      "\n",
      "n_iter: 2960/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.010, critic: 0.138, entropy: -0.388, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.686\n",
      "\n",
      "n_iter: 2970/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.001, critic: 0.113, entropy: -0.380, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.689\n",
      "\n",
      "n_iter: 2980/8000, grad norm: 0.005. Training block: full\n",
      "actor: 0.185, critic: 0.240, entropy: -0.391, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.624\n",
      "\n",
      "n_iter: 2990/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.009, critic: 0.093, entropy: -0.381, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.692\n",
      "\n",
      "n_iter: 3000/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.027, critic: 0.091, entropy: -0.338, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.710\n",
      "\n",
      "n_iter: 3010/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.142, critic: 0.181, entropy: -0.423, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.641\n",
      "\n",
      "n_iter: 3020/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.038, critic: 0.147, entropy: -0.370, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.683\n",
      "\n",
      "n_iter: 3030/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.006, critic: 0.135, entropy: -0.359, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.699\n",
      "\n",
      "n_iter: 3040/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.165, critic: 0.218, entropy: -0.377, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.633\n",
      "\n",
      "n_iter: 3050/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.075, critic: 0.176, entropy: -0.370, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.668\n",
      "\n",
      "n_iter: 3060/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.060, critic: 0.085, entropy: -0.358, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.716\n",
      "\n",
      "n_iter: 3070/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.059, critic: 0.084, entropy: -0.353, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.717\n",
      "\n",
      "n_iter: 3080/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.019, critic: 0.103, entropy: -0.386, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.697\n",
      "\n",
      "n_iter: 3090/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.044, critic: 0.107, entropy: -0.373, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.705\n",
      "\n",
      "n_iter: 3100/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.066, critic: 0.083, entropy: -0.361, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.715\n",
      "\n",
      "n_iter: 3110/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.019, critic: 0.122, entropy: -0.388, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.683\n",
      "\n",
      "n_iter: 3120/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.020, critic: 0.132, entropy: -0.354, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.687\n",
      "\n",
      "n_iter: 3130/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.035, critic: 0.097, entropy: -0.365, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.707\n",
      "\n",
      "n_iter: 3140/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.016, critic: 0.128, entropy: -0.363, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.693\n",
      "\n",
      "n_iter: 3150/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.139, critic: 0.196, entropy: -0.398, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.643\n",
      "\n",
      "n_iter: 3160/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.129, critic: 0.205, entropy: -0.398, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.651\n",
      "\n",
      "n_iter: 3170/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.032, critic: 0.096, entropy: -0.364, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 3180/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.059, critic: 0.149, entropy: -0.346, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.675\n",
      "\n",
      "n_iter: 3190/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.179, critic: 0.247, entropy: -0.359, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.635\n",
      "\n",
      "n_iter: 3200/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.103, critic: 0.201, entropy: -0.380, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.658\n",
      "\n",
      "n_iter: 3210/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.059, critic: 0.091, entropy: -0.336, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.715\n",
      "\n",
      "n_iter: 3220/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.056, critic: 0.084, entropy: -0.359, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.711\n",
      "\n",
      "n_iter: 3230/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.061, critic: 0.093, entropy: -0.322, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.713\n",
      "\n",
      "n_iter: 3240/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.044, critic: 0.091, entropy: -0.358, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.708\n",
      "\n",
      "n_iter: 3250/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.059, critic: 0.082, entropy: -0.336, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.719\n",
      "\n",
      "n_iter: 3260/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.025, critic: 0.106, entropy: -0.368, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.705\n",
      "\n",
      "n_iter: 3270/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.123, critic: 0.178, entropy: -0.420, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.642\n",
      "\n",
      "n_iter: 3280/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.018, critic: 0.107, entropy: -0.348, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.702\n",
      "\n",
      "n_iter: 3290/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.059, critic: 0.083, entropy: -0.318, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.719\n",
      "\n",
      "n_iter: 3300/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.089, critic: 0.169, entropy: -0.349, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.668\n",
      "\n",
      "n_iter: 3310/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.052, critic: 0.087, entropy: -0.334, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.716\n",
      "\n",
      "n_iter: 3320/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.028, critic: 0.092, entropy: -0.328, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.710\n",
      "\n",
      "n_iter: 3330/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.062, critic: 0.085, entropy: -0.312, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.721\n",
      "\n",
      "n_iter: 3340/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.032, critic: 0.128, entropy: -0.344, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.687\n",
      "\n",
      "n_iter: 3350/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.029, critic: 0.127, entropy: -0.348, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.693\n",
      "\n",
      "n_iter: 3360/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.042, critic: 0.091, entropy: -0.322, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.714\n",
      "\n",
      "n_iter: 3370/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.033, critic: 0.089, entropy: -0.321, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.713\n",
      "\n",
      "n_iter: 3380/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.007, critic: 0.128, entropy: -0.316, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.700\n",
      "\n",
      "n_iter: 3390/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.029, critic: 0.143, entropy: -0.337, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.686\n",
      "\n",
      "n_iter: 3400/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.014, critic: 0.109, entropy: -0.335, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 3410/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.005, critic: 0.128, entropy: -0.328, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.697\n",
      "\n",
      "n_iter: 3420/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.030, critic: 0.142, entropy: -0.331, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.688\n",
      "\n",
      "n_iter: 3430/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.003, critic: 0.118, entropy: -0.358, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.693\n",
      "\n",
      "n_iter: 3440/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.031, critic: 0.101, entropy: -0.350, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 3450/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.060, critic: 0.083, entropy: -0.343, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.716\n",
      "\n",
      "n_iter: 3460/8000, grad norm: 0.004. Training block: full\n",
      "actor: 0.190, critic: 0.245, entropy: -0.399, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.629\n",
      "\n",
      "n_iter: 3470/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.030, critic: 0.130, entropy: -0.380, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.680\n",
      "\n",
      "n_iter: 3480/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.041, critic: 0.163, entropy: -0.347, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.678\n",
      "\n",
      "n_iter: 3490/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.091, critic: 0.185, entropy: -0.371, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.666\n",
      "\n",
      "n_iter: 3500/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.002, critic: 0.146, entropy: -0.316, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.687\n",
      "\n",
      "n_iter: 3510/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.031, critic: 0.142, entropy: -0.386, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.681\n",
      "\n",
      "n_iter: 3520/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.068, critic: 0.178, entropy: -0.388, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.664\n",
      "\n",
      "n_iter: 3530/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.045, critic: 0.093, entropy: -0.365, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.705\n",
      "\n",
      "n_iter: 3540/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.018, critic: 0.110, entropy: -0.355, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.696\n",
      "\n",
      "n_iter: 3550/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.184, critic: 0.244, entropy: -0.419, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.634\n",
      "\n",
      "n_iter: 3560/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.038, critic: 0.162, entropy: -0.378, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.682\n",
      "\n",
      "n_iter: 3570/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.053, critic: 0.091, entropy: -0.323, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.714\n",
      "\n",
      "n_iter: 3580/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.112, critic: 0.201, entropy: -0.365, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.661\n",
      "\n",
      "n_iter: 3590/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.036, critic: 0.098, entropy: -0.364, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.704\n",
      "\n",
      "n_iter: 3600/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.045, critic: 0.092, entropy: -0.344, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.711\n",
      "\n",
      "n_iter: 3610/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.046, critic: 0.163, entropy: -0.376, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.686\n",
      "\n",
      "n_iter: 3620/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.024, critic: 0.113, entropy: -0.374, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.704\n",
      "\n",
      "n_iter: 3630/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.046, critic: 0.085, entropy: -0.364, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.710\n",
      "\n",
      "n_iter: 3640/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.015, critic: 0.144, entropy: -0.380, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.691\n",
      "\n",
      "n_iter: 3650/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.060, critic: 0.093, entropy: -0.349, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.713\n",
      "\n",
      "n_iter: 3660/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.147, critic: 0.225, entropy: -0.333, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.645\n",
      "\n",
      "n_iter: 3670/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.071, critic: 0.087, entropy: -0.350, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.717\n",
      "\n",
      "n_iter: 3680/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.128, critic: 0.198, entropy: -0.491, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.637\n",
      "\n",
      "n_iter: 3690/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.033, critic: 0.112, entropy: -0.371, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 3700/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.084, critic: 0.083, entropy: -0.361, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.721\n",
      "\n",
      "n_iter: 3710/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.015, critic: 0.130, entropy: -0.392, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.697\n",
      "\n",
      "n_iter: 3720/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.000, critic: 0.136, entropy: -0.385, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.692\n",
      "\n",
      "n_iter: 3730/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.074, critic: 0.090, entropy: -0.385, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.715\n",
      "\n",
      "n_iter: 3740/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.063, critic: 0.086, entropy: -0.379, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.714\n",
      "\n",
      "n_iter: 3750/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.039, critic: 0.097, entropy: -0.403, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.711\n",
      "\n",
      "n_iter: 3760/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.067, critic: 0.091, entropy: -0.392, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.720\n",
      "\n",
      "n_iter: 3770/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.076, critic: 0.086, entropy: -0.395, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.719\n",
      "\n",
      "n_iter: 3780/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.031, critic: 0.096, entropy: -0.426, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.707\n",
      "\n",
      "n_iter: 3790/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.049, critic: 0.088, entropy: -0.388, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.719\n",
      "\n",
      "n_iter: 3800/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.014, critic: 0.133, entropy: -0.357, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.702\n",
      "\n",
      "n_iter: 3810/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.007, critic: 0.114, entropy: -0.380, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.703\n",
      "\n",
      "n_iter: 3820/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.094, critic: 0.187, entropy: -0.375, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.669\n",
      "\n",
      "n_iter: 3830/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.009, critic: 0.109, entropy: -0.404, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.705\n",
      "\n",
      "n_iter: 3840/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.078, critic: 0.084, entropy: -0.364, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.726\n",
      "\n",
      "n_iter: 3850/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.079, critic: 0.176, entropy: -0.409, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.668\n",
      "\n",
      "n_iter: 3860/8000, grad norm: 0.004. Training block: full\n",
      "actor: 0.169, critic: 0.220, entropy: -0.466, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.634\n",
      "\n",
      "n_iter: 3870/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.097, critic: 0.181, entropy: -0.431, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.660\n",
      "\n",
      "n_iter: 3880/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.053, critic: 0.093, entropy: -0.381, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.713\n",
      "\n",
      "n_iter: 3890/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.042, critic: 0.096, entropy: -0.402, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.711\n",
      "\n",
      "n_iter: 3900/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.041, critic: 0.106, entropy: -0.379, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.714\n",
      "\n",
      "n_iter: 3910/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.035, critic: 0.144, entropy: -0.405, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.683\n",
      "\n",
      "n_iter: 3920/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.050, critic: 0.093, entropy: -0.384, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.712\n",
      "\n",
      "n_iter: 3930/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.069, critic: 0.175, entropy: -0.431, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.674\n",
      "\n",
      "n_iter: 3940/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.004, critic: 0.118, entropy: -0.380, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.696\n",
      "\n",
      "n_iter: 3950/8000, grad norm: 0.004. Training block: full\n",
      "actor: 0.140, critic: 0.222, entropy: -0.458, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.642\n",
      "\n",
      "n_iter: 3960/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.051, critic: 0.100, entropy: -0.398, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.711\n",
      "\n",
      "n_iter: 3970/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.073, critic: 0.173, entropy: -0.393, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.670\n",
      "\n",
      "n_iter: 3980/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.054, critic: 0.096, entropy: -0.367, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.716\n",
      "\n",
      "n_iter: 3990/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.033, critic: 0.116, entropy: -0.408, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 4000/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.073, critic: 0.163, entropy: -0.401, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.674\n",
      "\n",
      "n_iter: 4010/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.040, critic: 0.090, entropy: -0.388, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.711\n",
      "\n",
      "n_iter: 4020/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.024, critic: 0.109, entropy: -0.377, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.712\n",
      "\n",
      "n_iter: 4030/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.019, critic: 0.134, entropy: -0.362, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.700\n",
      "\n",
      "n_iter: 4040/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.055, critic: 0.161, entropy: -0.410, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.685\n",
      "\n",
      "n_iter: 4050/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.022, critic: 0.129, entropy: -0.377, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.687\n",
      "\n",
      "n_iter: 4060/8000, grad norm: 0.004. Training block: full\n",
      "actor: 0.169, critic: 0.218, entropy: -0.407, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.637\n",
      "\n",
      "n_iter: 4070/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.081, critic: 0.172, entropy: -0.395, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.668\n",
      "\n",
      "n_iter: 4080/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.017, critic: 0.125, entropy: -0.377, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.691\n",
      "\n",
      "n_iter: 4090/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.040, critic: 0.153, entropy: -0.375, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.682\n",
      "\n",
      "n_iter: 4100/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.065, critic: 0.084, entropy: -0.368, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.723\n",
      "\n",
      "n_iter: 4110/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.061, critic: 0.094, entropy: -0.370, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.722\n",
      "\n",
      "n_iter: 4120/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.030, critic: 0.109, entropy: -0.380, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.713\n",
      "\n",
      "n_iter: 4130/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.032, critic: 0.102, entropy: -0.378, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.711\n",
      "\n",
      "n_iter: 4140/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.036, critic: 0.106, entropy: -0.370, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.710\n",
      "\n",
      "n_iter: 4150/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.040, critic: 0.100, entropy: -0.360, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.713\n",
      "\n",
      "n_iter: 4160/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.048, critic: 0.101, entropy: -0.369, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.716\n",
      "\n",
      "n_iter: 4170/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.072, critic: 0.165, entropy: -0.425, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.673\n",
      "\n",
      "n_iter: 4180/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.046, critic: 0.161, entropy: -0.415, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.679\n",
      "\n",
      "n_iter: 4190/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.067, critic: 0.092, entropy: -0.370, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.718\n",
      "\n",
      "n_iter: 4200/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.054, critic: 0.093, entropy: -0.393, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.712\n",
      "\n",
      "n_iter: 4210/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.011, critic: 0.116, entropy: -0.384, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 4220/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.057, critic: 0.155, entropy: -0.396, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.686\n",
      "\n",
      "n_iter: 4230/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.004, critic: 0.118, entropy: -0.396, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.701\n",
      "\n",
      "n_iter: 4240/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.066, critic: 0.082, entropy: -0.375, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.723\n",
      "\n",
      "n_iter: 4250/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.177, critic: 0.223, entropy: -0.452, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.636\n",
      "\n",
      "n_iter: 4260/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.030, critic: 0.113, entropy: -0.393, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.707\n",
      "\n",
      "n_iter: 4270/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.144, critic: 0.229, entropy: -0.439, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.652\n",
      "\n",
      "n_iter: 4280/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.002, critic: 0.118, entropy: -0.415, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.697\n",
      "\n",
      "n_iter: 4290/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.057, critic: 0.159, entropy: -0.464, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.669\n",
      "\n",
      "n_iter: 4300/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.019, critic: 0.123, entropy: -0.402, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.710\n",
      "\n",
      "n_iter: 4310/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.028, critic: 0.111, entropy: -0.391, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.714\n",
      "\n",
      "n_iter: 4320/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.025, critic: 0.099, entropy: -0.399, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 4330/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.034, critic: 0.148, entropy: -0.413, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.690\n",
      "\n",
      "n_iter: 4340/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.048, critic: 0.102, entropy: -0.379, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.718\n",
      "\n",
      "n_iter: 4350/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.042, critic: 0.095, entropy: -0.396, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.717\n",
      "\n",
      "n_iter: 4360/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.025, critic: 0.136, entropy: -0.388, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.694\n",
      "\n",
      "n_iter: 4370/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.086, entropy: -0.382, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.723\n",
      "\n",
      "n_iter: 4380/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.041, critic: 0.088, entropy: -0.362, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.723\n",
      "\n",
      "n_iter: 4390/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.010, critic: 0.113, entropy: -0.375, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.703\n",
      "\n",
      "n_iter: 4400/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.165, critic: 0.223, entropy: -0.411, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.648\n",
      "\n",
      "n_iter: 4410/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.042, critic: 0.093, entropy: -0.388, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.714\n",
      "\n",
      "n_iter: 4420/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.014, critic: 0.136, entropy: -0.413, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.696\n",
      "\n",
      "n_iter: 4430/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.047, critic: 0.094, entropy: -0.372, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.719\n",
      "\n",
      "n_iter: 4440/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.197, critic: 0.242, entropy: -0.423, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.638\n",
      "\n",
      "n_iter: 4450/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.079, critic: 0.173, entropy: -0.401, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.674\n",
      "\n",
      "n_iter: 4460/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.084, entropy: -0.372, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.722\n",
      "\n",
      "n_iter: 4470/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.033, critic: 0.102, entropy: -0.376, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.717\n",
      "\n",
      "n_iter: 4480/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.011, critic: 0.103, entropy: -0.379, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.698\n",
      "\n",
      "n_iter: 4490/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.083, entropy: -0.396, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.725\n",
      "\n",
      "n_iter: 4500/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.051, critic: 0.091, entropy: -0.367, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.725\n",
      "\n",
      "n_iter: 4510/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.070, critic: 0.168, entropy: -0.424, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.688\n",
      "\n",
      "n_iter: 4520/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.020, critic: 0.098, entropy: -0.404, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.713\n",
      "\n",
      "n_iter: 4530/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.019, critic: 0.122, entropy: -0.418, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.699\n",
      "\n",
      "n_iter: 4540/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.018, critic: 0.100, entropy: -0.409, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.713\n",
      "\n",
      "n_iter: 4550/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.010, critic: 0.114, entropy: -0.411, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.701\n",
      "\n",
      "n_iter: 4560/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.207, critic: 0.247, entropy: -0.478, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.635\n",
      "\n",
      "n_iter: 4570/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.062, critic: 0.163, entropy: -0.421, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.678\n",
      "\n",
      "n_iter: 4580/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.027, critic: 0.132, entropy: -0.409, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.692\n",
      "\n",
      "n_iter: 4590/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.040, critic: 0.137, entropy: -0.404, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.695\n",
      "\n",
      "n_iter: 4600/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.042, critic: 0.089, entropy: -0.385, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.717\n",
      "\n",
      "n_iter: 4610/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.007, critic: 0.119, entropy: -0.392, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.707\n",
      "\n",
      "n_iter: 4620/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.052, critic: 0.083, entropy: -0.391, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.717\n",
      "\n",
      "n_iter: 4630/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.052, critic: 0.085, entropy: -0.378, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.721\n",
      "\n",
      "n_iter: 4640/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.046, critic: 0.087, entropy: -0.378, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.722\n",
      "\n",
      "n_iter: 4650/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.008, critic: 0.121, entropy: -0.402, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.696\n",
      "\n",
      "n_iter: 4660/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.061, critic: 0.089, entropy: -0.366, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.724\n",
      "\n",
      "n_iter: 4670/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.069, critic: 0.178, entropy: -0.433, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.677\n",
      "\n",
      "n_iter: 4680/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.062, critic: 0.085, entropy: -0.415, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.722\n",
      "\n",
      "n_iter: 4690/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.002, critic: 0.107, entropy: -0.413, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.699\n",
      "\n",
      "n_iter: 4700/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.026, critic: 0.093, entropy: -0.398, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.712\n",
      "\n",
      "n_iter: 4710/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.067, critic: 0.148, entropy: -0.399, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.678\n",
      "\n",
      "n_iter: 4720/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.023, critic: 0.133, entropy: -0.398, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.695\n",
      "\n",
      "n_iter: 4730/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.053, critic: 0.089, entropy: -0.371, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.718\n",
      "\n",
      "n_iter: 4740/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.066, critic: 0.088, entropy: -0.373, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.724\n",
      "\n",
      "n_iter: 4750/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.049, critic: 0.086, entropy: -0.380, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.723\n",
      "\n",
      "n_iter: 4760/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.055, critic: 0.154, entropy: -0.384, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.689\n",
      "\n",
      "n_iter: 4770/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.046, critic: 0.154, entropy: -0.406, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.691\n",
      "\n",
      "n_iter: 4780/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.061, critic: 0.084, entropy: -0.412, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.722\n",
      "\n",
      "n_iter: 4790/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.010, critic: 0.121, entropy: -0.407, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.704\n",
      "\n",
      "n_iter: 4800/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.006, critic: 0.125, entropy: -0.406, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.699\n",
      "\n",
      "n_iter: 4810/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.182, critic: 0.245, entropy: -0.447, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.638\n",
      "\n",
      "n_iter: 4820/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.001, critic: 0.132, entropy: -0.407, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.695\n",
      "\n",
      "n_iter: 4830/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.027, critic: 0.116, entropy: -0.385, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 4840/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.027, critic: 0.120, entropy: -0.396, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.701\n",
      "\n",
      "n_iter: 4850/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.065, critic: 0.090, entropy: -0.396, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.718\n",
      "\n",
      "n_iter: 4860/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.091, entropy: -0.393, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.715\n",
      "\n",
      "n_iter: 4870/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.028, critic: 0.112, entropy: -0.398, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 4880/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.159, critic: 0.218, entropy: -0.431, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.638\n",
      "\n",
      "n_iter: 4890/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.054, critic: 0.163, entropy: -0.416, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.680\n",
      "\n",
      "n_iter: 4900/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.036, critic: 0.098, entropy: -0.415, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.713\n",
      "\n",
      "n_iter: 4910/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.103, critic: 0.204, entropy: -0.444, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.663\n",
      "\n",
      "n_iter: 4920/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.007, critic: 0.119, entropy: -0.432, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.704\n",
      "\n",
      "n_iter: 4930/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.061, critic: 0.089, entropy: -0.392, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.717\n",
      "\n",
      "n_iter: 4940/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.059, critic: 0.082, entropy: -0.383, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.721\n",
      "\n",
      "n_iter: 4950/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.047, critic: 0.091, entropy: -0.411, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.715\n",
      "\n",
      "n_iter: 4960/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.096, critic: 0.174, entropy: -0.430, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.668\n",
      "\n",
      "n_iter: 4970/8000, grad norm: 0.004. Training block: full\n",
      "actor: 0.206, critic: 0.242, entropy: -0.458, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.632\n",
      "\n",
      "n_iter: 4980/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.059, critic: 0.145, entropy: -0.451, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.676\n",
      "\n",
      "n_iter: 4990/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.176, critic: 0.253, entropy: -0.462, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.643\n",
      "\n",
      "n_iter: 5000/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.044, critic: 0.154, entropy: -0.440, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.687\n",
      "\n",
      "n_iter: 5010/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.109, critic: 0.175, entropy: -0.456, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.662\n",
      "\n",
      "n_iter: 5020/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.030, critic: 0.107, entropy: -0.426, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.708\n",
      "\n",
      "n_iter: 5030/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.045, critic: 0.151, entropy: -0.442, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.684\n",
      "\n",
      "n_iter: 5040/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.063, critic: 0.159, entropy: -0.427, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.675\n",
      "\n",
      "n_iter: 5050/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.115, critic: 0.202, entropy: -0.464, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.662\n",
      "\n",
      "n_iter: 5060/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.041, critic: 0.090, entropy: -0.422, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.716\n",
      "\n",
      "n_iter: 5070/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.008, critic: 0.091, entropy: -0.411, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 5080/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.039, critic: 0.131, entropy: -0.406, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.684\n",
      "\n",
      "n_iter: 5090/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.077, critic: 0.173, entropy: -0.434, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.672\n",
      "\n",
      "n_iter: 5100/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.049, critic: 0.086, entropy: -0.414, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.715\n",
      "\n",
      "n_iter: 5110/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.027, critic: 0.156, entropy: -0.417, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.695\n",
      "\n",
      "n_iter: 5120/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.068, critic: 0.095, entropy: -0.393, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.724\n",
      "\n",
      "n_iter: 5130/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.149, critic: 0.222, entropy: -0.454, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.652\n",
      "\n",
      "n_iter: 5140/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.044, critic: 0.154, entropy: -0.430, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.682\n",
      "\n",
      "n_iter: 5150/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.054, critic: 0.170, entropy: -0.431, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.678\n",
      "\n",
      "n_iter: 5160/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.056, critic: 0.098, entropy: -0.418, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.717\n",
      "\n",
      "n_iter: 5170/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.102, critic: 0.164, entropy: -0.428, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.659\n",
      "\n",
      "n_iter: 5180/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.042, critic: 0.135, entropy: -0.460, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.686\n",
      "\n",
      "n_iter: 5190/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.035, critic: 0.132, entropy: -0.419, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.690\n",
      "\n",
      "n_iter: 5200/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.020, critic: 0.104, entropy: -0.429, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.708\n",
      "\n",
      "n_iter: 5210/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.043, critic: 0.141, entropy: -0.441, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.683\n",
      "\n",
      "n_iter: 5220/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.078, critic: 0.172, entropy: -0.424, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.677\n",
      "\n",
      "n_iter: 5230/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.121, critic: 0.203, entropy: -0.437, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.663\n",
      "\n",
      "n_iter: 5240/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.019, critic: 0.111, entropy: -0.424, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.710\n",
      "\n",
      "n_iter: 5250/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.041, critic: 0.102, entropy: -0.400, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.715\n",
      "\n",
      "n_iter: 5260/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.030, critic: 0.139, entropy: -0.405, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.695\n",
      "\n",
      "n_iter: 5270/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.009, critic: 0.108, entropy: -0.399, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.703\n",
      "\n",
      "n_iter: 5280/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.079, critic: 0.168, entropy: -0.409, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.680\n",
      "\n",
      "n_iter: 5290/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.070, critic: 0.150, entropy: -0.437, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.682\n",
      "\n",
      "n_iter: 5300/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.014, critic: 0.118, entropy: -0.448, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.694\n",
      "\n",
      "n_iter: 5310/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.048, critic: 0.083, entropy: -0.403, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.725\n",
      "\n",
      "n_iter: 5320/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.113, critic: 0.190, entropy: -0.431, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.663\n",
      "\n",
      "n_iter: 5330/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.036, critic: 0.106, entropy: -0.351, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.718\n",
      "\n",
      "n_iter: 5340/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.053, critic: 0.086, entropy: -0.367, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.728\n",
      "\n",
      "n_iter: 5350/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.178, critic: 0.216, entropy: -0.431, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.641\n",
      "\n",
      "n_iter: 5360/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.074, critic: 0.177, entropy: -0.403, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.683\n",
      "\n",
      "n_iter: 5370/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.047, critic: 0.085, entropy: -0.392, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.720\n",
      "\n",
      "n_iter: 5380/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.072, critic: 0.156, entropy: -0.423, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.681\n",
      "\n",
      "n_iter: 5390/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.025, critic: 0.101, entropy: -0.375, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.718\n",
      "\n",
      "n_iter: 5400/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.045, critic: 0.155, entropy: -0.414, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.692\n",
      "\n",
      "n_iter: 5410/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.039, critic: 0.097, entropy: -0.396, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.712\n",
      "\n",
      "n_iter: 5420/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.000, critic: 0.126, entropy: -0.402, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.701\n",
      "\n",
      "n_iter: 5430/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.016, critic: 0.105, entropy: -0.392, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.704\n",
      "\n",
      "n_iter: 5440/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.001, critic: 0.129, entropy: -0.388, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.700\n",
      "\n",
      "n_iter: 5450/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.014, critic: 0.131, entropy: -0.382, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.692\n",
      "\n",
      "n_iter: 5460/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.050, critic: 0.093, entropy: -0.405, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.717\n",
      "\n",
      "n_iter: 5470/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.054, critic: 0.089, entropy: -0.388, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.717\n",
      "\n",
      "n_iter: 5480/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.087, entropy: -0.380, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.719\n",
      "\n",
      "n_iter: 5490/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.042, critic: 0.156, entropy: -0.396, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.686\n",
      "\n",
      "n_iter: 5500/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.150, critic: 0.220, entropy: -0.412, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.648\n",
      "\n",
      "n_iter: 5510/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.070, critic: 0.176, entropy: -0.419, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.676\n",
      "\n",
      "n_iter: 5520/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.024, critic: 0.110, entropy: -0.393, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.709\n",
      "\n",
      "n_iter: 5530/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.071, critic: 0.162, entropy: -0.388, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.683\n",
      "\n",
      "n_iter: 5540/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.040, critic: 0.092, entropy: -0.376, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.723\n",
      "\n",
      "n_iter: 5550/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.001, critic: 0.118, entropy: -0.399, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.704\n",
      "\n",
      "n_iter: 5560/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.028, critic: 0.128, entropy: -0.421, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.689\n",
      "\n",
      "n_iter: 5570/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.120, critic: 0.209, entropy: -0.444, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.660\n",
      "\n",
      "n_iter: 5580/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.005, critic: 0.136, entropy: -0.401, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.705\n",
      "\n",
      "n_iter: 5590/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.064, critic: 0.175, entropy: -0.425, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.679\n",
      "\n",
      "n_iter: 5600/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.073, critic: 0.189, entropy: -0.438, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.672\n",
      "\n",
      "n_iter: 5610/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.078, critic: 0.088, entropy: -0.369, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.728\n",
      "\n",
      "n_iter: 5620/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.022, critic: 0.122, entropy: -0.367, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.711\n",
      "\n",
      "n_iter: 5630/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.184, critic: 0.240, entropy: -0.416, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.640\n",
      "\n",
      "n_iter: 5640/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.039, critic: 0.097, entropy: -0.366, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.717\n",
      "\n",
      "n_iter: 5650/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.161, critic: 0.221, entropy: -0.416, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.650\n",
      "\n",
      "n_iter: 5660/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.040, critic: 0.101, entropy: -0.352, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.718\n",
      "\n",
      "n_iter: 5670/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.043, critic: 0.146, entropy: -0.391, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.697\n",
      "\n",
      "n_iter: 5680/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.013, critic: 0.118, entropy: -0.378, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.705\n",
      "\n",
      "n_iter: 5690/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.030, critic: 0.128, entropy: -0.365, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.715\n",
      "\n",
      "n_iter: 5700/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.039, critic: 0.098, entropy: -0.378, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.720\n",
      "\n",
      "n_iter: 5710/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.061, critic: 0.088, entropy: -0.380, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.725\n",
      "\n",
      "n_iter: 5720/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.055, critic: 0.090, entropy: -0.370, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.721\n",
      "\n",
      "n_iter: 5730/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.042, critic: 0.096, entropy: -0.363, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.725\n",
      "\n",
      "n_iter: 5740/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.149, critic: 0.227, entropy: -0.396, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.655\n",
      "\n",
      "n_iter: 5750/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.042, critic: 0.146, entropy: -0.379, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.694\n",
      "\n",
      "n_iter: 5760/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.013, critic: 0.096, entropy: -0.361, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.707\n",
      "\n",
      "n_iter: 5770/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.079, critic: 0.163, entropy: -0.386, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.678\n",
      "\n",
      "n_iter: 5780/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.011, critic: 0.108, entropy: -0.365, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.708\n",
      "\n",
      "n_iter: 5790/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.011, critic: 0.110, entropy: -0.387, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 5800/8000, grad norm: 0.004. Training block: full\n",
      "actor: 0.216, critic: 0.263, entropy: -0.454, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.611\n",
      "\n",
      "n_iter: 5810/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.020, critic: 0.148, entropy: -0.396, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.695\n",
      "\n",
      "n_iter: 5820/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.080, critic: 0.087, entropy: -0.374, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.731\n",
      "\n",
      "n_iter: 5830/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.067, critic: 0.085, entropy: -0.373, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.727\n",
      "\n",
      "n_iter: 5840/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.022, critic: 0.107, entropy: -0.396, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.711\n",
      "\n",
      "n_iter: 5850/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.171, critic: 0.222, entropy: -0.460, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.642\n",
      "\n",
      "n_iter: 5860/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.156, critic: 0.221, entropy: -0.419, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.656\n",
      "\n",
      "n_iter: 5870/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.022, critic: 0.110, entropy: -0.372, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.710\n",
      "\n",
      "n_iter: 5880/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.041, critic: 0.154, entropy: -0.386, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.696\n",
      "\n",
      "n_iter: 5890/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.044, critic: 0.162, entropy: -0.403, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.685\n",
      "\n",
      "n_iter: 5900/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.012, critic: 0.122, entropy: -0.411, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 5910/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.038, critic: 0.141, entropy: -0.399, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.690\n",
      "\n",
      "n_iter: 5920/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.002, critic: 0.117, entropy: -0.394, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.703\n",
      "\n",
      "n_iter: 5930/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.060, critic: 0.162, entropy: -0.413, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.685\n",
      "\n",
      "n_iter: 5940/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.009, critic: 0.098, entropy: -0.406, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.710\n",
      "\n",
      "n_iter: 5950/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.020, critic: 0.108, entropy: -0.395, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.714\n",
      "\n",
      "n_iter: 5960/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.120, critic: 0.205, entropy: -0.432, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.667\n",
      "\n",
      "n_iter: 5970/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.003, critic: 0.116, entropy: -0.398, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 5980/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.001, critic: 0.123, entropy: -0.381, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.709\n",
      "\n",
      "n_iter: 5990/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.044, critic: 0.102, entropy: -0.367, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.722\n",
      "\n",
      "n_iter: 6000/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.001, critic: 0.114, entropy: -0.377, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.711\n",
      "\n",
      "n_iter: 6010/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.010, critic: 0.117, entropy: -0.411, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.710\n",
      "\n",
      "n_iter: 6020/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.002, critic: 0.118, entropy: -0.364, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.709\n",
      "\n",
      "n_iter: 6030/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.132, critic: 0.204, entropy: -0.422, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.665\n",
      "\n",
      "n_iter: 6040/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.020, critic: 0.111, entropy: -0.399, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.717\n",
      "\n",
      "n_iter: 6050/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.028, critic: 0.092, entropy: -0.384, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.722\n",
      "\n",
      "n_iter: 6060/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.006, critic: 0.103, entropy: -0.422, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.709\n",
      "\n",
      "n_iter: 6070/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.028, critic: 0.096, entropy: -0.411, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.717\n",
      "\n",
      "n_iter: 6080/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.002, critic: 0.128, entropy: -0.413, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.711\n",
      "\n",
      "n_iter: 6090/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.071, critic: 0.098, entropy: -0.386, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.722\n",
      "\n",
      "n_iter: 6100/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.036, critic: 0.094, entropy: -0.389, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.710\n",
      "\n",
      "n_iter: 6110/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.147, critic: 0.225, entropy: -0.390, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.654\n",
      "\n",
      "n_iter: 6120/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.036, critic: 0.114, entropy: -0.379, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.716\n",
      "\n",
      "n_iter: 6130/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.016, critic: 0.121, entropy: -0.370, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.715\n",
      "\n",
      "n_iter: 6140/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.009, critic: 0.139, entropy: -0.390, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.700\n",
      "\n",
      "n_iter: 6150/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.004, critic: 0.118, entropy: -0.406, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.702\n",
      "\n",
      "n_iter: 6160/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.005, critic: 0.123, entropy: -0.404, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.710\n",
      "\n",
      "n_iter: 6170/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.154, critic: 0.217, entropy: -0.450, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.648\n",
      "\n",
      "n_iter: 6180/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.013, critic: 0.134, entropy: -0.399, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.707\n",
      "\n",
      "n_iter: 6190/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.007, critic: 0.132, entropy: -0.435, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.703\n",
      "\n",
      "n_iter: 6200/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.161, critic: 0.220, entropy: -0.448, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.649\n",
      "\n",
      "n_iter: 6210/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.067, critic: 0.082, entropy: -0.393, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.726\n",
      "\n",
      "n_iter: 6220/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.003, critic: 0.106, entropy: -0.397, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.699\n",
      "\n",
      "n_iter: 6230/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.083, critic: 0.172, entropy: -0.421, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.679\n",
      "\n",
      "n_iter: 6240/8000, grad norm: 0.004. Training block: full\n",
      "actor: 0.191, critic: 0.213, entropy: -0.468, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.629\n",
      "\n",
      "n_iter: 6250/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.004, critic: 0.128, entropy: -0.422, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 6260/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.081, critic: 0.169, entropy: -0.408, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.675\n",
      "\n",
      "n_iter: 6270/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.040, critic: 0.087, entropy: -0.383, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.716\n",
      "\n",
      "n_iter: 6280/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.036, critic: 0.106, entropy: -0.372, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.720\n",
      "\n",
      "n_iter: 6290/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.026, critic: 0.102, entropy: -0.404, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.717\n",
      "\n",
      "n_iter: 6300/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.002, critic: 0.124, entropy: -0.386, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.703\n",
      "\n",
      "n_iter: 6310/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.030, critic: 0.140, entropy: -0.387, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.697\n",
      "\n",
      "n_iter: 6320/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.036, critic: 0.095, entropy: -0.373, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.723\n",
      "\n",
      "n_iter: 6330/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.043, critic: 0.089, entropy: -0.377, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.724\n",
      "\n",
      "n_iter: 6340/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.130, critic: 0.165, entropy: -0.453, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.658\n",
      "\n",
      "n_iter: 6350/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.125, critic: 0.188, entropy: -0.417, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.667\n",
      "\n",
      "n_iter: 6360/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.037, critic: 0.095, entropy: -0.398, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.721\n",
      "\n",
      "n_iter: 6370/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.039, critic: 0.140, entropy: -0.409, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.690\n",
      "\n",
      "n_iter: 6380/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.007, critic: 0.125, entropy: -0.400, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.711\n",
      "\n",
      "n_iter: 6390/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.115, critic: 0.186, entropy: -0.402, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.669\n",
      "\n",
      "n_iter: 6400/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.019, critic: 0.117, entropy: -0.392, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.713\n",
      "\n",
      "n_iter: 6410/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.060, critic: 0.136, entropy: -0.428, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.684\n",
      "\n",
      "n_iter: 6420/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.019, critic: 0.111, entropy: -0.400, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.710\n",
      "\n",
      "n_iter: 6430/8000, grad norm: 0.004. Training block: full\n",
      "actor: 0.136, critic: 0.203, entropy: -0.453, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.657\n",
      "\n",
      "n_iter: 6440/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.064, critic: 0.080, entropy: -0.366, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.729\n",
      "\n",
      "n_iter: 6450/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.179, critic: 0.218, entropy: -0.437, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.646\n",
      "\n",
      "n_iter: 6460/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.024, critic: 0.107, entropy: -0.395, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.716\n",
      "\n",
      "n_iter: 6470/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.044, critic: 0.083, entropy: -0.374, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.726\n",
      "\n",
      "n_iter: 6480/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.033, critic: 0.103, entropy: -0.397, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.720\n",
      "\n",
      "n_iter: 6490/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.050, critic: 0.145, entropy: -0.406, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.693\n",
      "\n",
      "n_iter: 6500/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.038, critic: 0.087, entropy: -0.385, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.723\n",
      "\n",
      "n_iter: 6510/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.052, critic: 0.086, entropy: -0.381, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.729\n",
      "\n",
      "n_iter: 6520/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.026, critic: 0.093, entropy: -0.400, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.724\n",
      "\n",
      "n_iter: 6530/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.160, critic: 0.226, entropy: -0.433, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.651\n",
      "\n",
      "n_iter: 6540/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.017, critic: 0.133, entropy: -0.385, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 6550/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.032, critic: 0.106, entropy: -0.397, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.714\n",
      "\n",
      "n_iter: 6560/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.038, critic: 0.138, entropy: -0.404, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.693\n",
      "\n",
      "n_iter: 6570/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.028, critic: 0.131, entropy: -0.419, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.697\n",
      "\n",
      "n_iter: 6580/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.002, critic: 0.119, entropy: -0.402, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.708\n",
      "\n",
      "n_iter: 6590/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.075, critic: 0.183, entropy: -0.438, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.670\n",
      "\n",
      "n_iter: 6600/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.179, critic: 0.247, entropy: -0.472, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.643\n",
      "\n",
      "n_iter: 6610/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.018, critic: 0.118, entropy: -0.407, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.708\n",
      "\n",
      "n_iter: 6620/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.040, critic: 0.092, entropy: -0.393, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.727\n",
      "\n",
      "n_iter: 6630/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.021, critic: 0.123, entropy: -0.386, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.700\n",
      "\n",
      "n_iter: 6640/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.032, critic: 0.106, entropy: -0.369, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.719\n",
      "\n",
      "n_iter: 6650/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.105, critic: 0.199, entropy: -0.397, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.676\n",
      "\n",
      "n_iter: 6660/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.064, critic: 0.093, entropy: -0.378, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.724\n",
      "\n",
      "n_iter: 6670/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.008, critic: 0.120, entropy: -0.404, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 6680/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.072, critic: 0.162, entropy: -0.381, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.688\n",
      "\n",
      "n_iter: 6690/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.128, critic: 0.207, entropy: -0.411, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.667\n",
      "\n",
      "n_iter: 6700/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.024, critic: 0.123, entropy: -0.372, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.715\n",
      "\n",
      "n_iter: 6710/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.075, critic: 0.170, entropy: -0.399, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.672\n",
      "\n",
      "n_iter: 6720/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.053, critic: 0.090, entropy: -0.369, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.727\n",
      "\n",
      "n_iter: 6730/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.056, critic: 0.085, entropy: -0.394, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.722\n",
      "\n",
      "n_iter: 6740/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.046, critic: 0.101, entropy: -0.393, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.721\n",
      "\n",
      "n_iter: 6750/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.051, critic: 0.094, entropy: -0.376, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.723\n",
      "\n",
      "n_iter: 6760/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.023, critic: 0.118, entropy: -0.407, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.708\n",
      "\n",
      "n_iter: 6770/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.064, critic: 0.085, entropy: -0.371, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.729\n",
      "\n",
      "n_iter: 6780/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.067, critic: 0.089, entropy: -0.366, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.728\n",
      "\n",
      "n_iter: 6790/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.057, critic: 0.088, entropy: -0.373, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.733\n",
      "\n",
      "n_iter: 6800/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.029, critic: 0.149, entropy: -0.421, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.696\n",
      "\n",
      "n_iter: 6810/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.163, critic: 0.228, entropy: -0.387, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.660\n",
      "\n",
      "n_iter: 6820/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.157, critic: 0.225, entropy: -0.409, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.658\n",
      "\n",
      "n_iter: 6830/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.068, critic: 0.088, entropy: -0.367, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.726\n",
      "\n",
      "n_iter: 6840/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.045, critic: 0.157, entropy: -0.402, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.689\n",
      "\n",
      "n_iter: 6850/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.017, critic: 0.101, entropy: -0.400, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.715\n",
      "\n",
      "n_iter: 6860/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.011, critic: 0.120, entropy: -0.386, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.713\n",
      "\n",
      "n_iter: 6870/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.087, entropy: -0.383, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.729\n",
      "\n",
      "n_iter: 6880/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.123, critic: 0.186, entropy: -0.433, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.668\n",
      "\n",
      "n_iter: 6890/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.035, critic: 0.099, entropy: -0.388, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.720\n",
      "\n",
      "n_iter: 6900/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.140, critic: 0.204, entropy: -0.437, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.665\n",
      "\n",
      "n_iter: 6910/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.131, critic: 0.203, entropy: -0.425, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.664\n",
      "\n",
      "n_iter: 6920/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.013, critic: 0.106, entropy: -0.406, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.715\n",
      "\n",
      "n_iter: 6930/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.027, critic: 0.098, entropy: -0.404, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.718\n",
      "\n",
      "n_iter: 6940/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.086, entropy: -0.395, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.731\n",
      "\n",
      "n_iter: 6950/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.098, critic: 0.188, entropy: -0.436, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.674\n",
      "\n",
      "n_iter: 6960/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.192, critic: 0.251, entropy: -0.452, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.647\n",
      "\n",
      "n_iter: 6970/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.027, critic: 0.105, entropy: -0.385, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.725\n",
      "\n",
      "n_iter: 6980/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.048, critic: 0.141, entropy: -0.408, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.699\n",
      "\n",
      "n_iter: 6990/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.032, critic: 0.091, entropy: -0.378, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.722\n",
      "\n",
      "n_iter: 7000/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.119, critic: 0.186, entropy: -0.469, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.666\n",
      "\n",
      "n_iter: 7010/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.029, critic: 0.084, entropy: -0.412, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.714\n",
      "\n",
      "n_iter: 7020/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.063, critic: 0.084, entropy: -0.397, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.729\n",
      "\n",
      "n_iter: 7030/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.062, critic: 0.092, entropy: -0.402, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.727\n",
      "\n",
      "n_iter: 7040/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.016, critic: 0.139, entropy: -0.408, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.696\n",
      "\n",
      "n_iter: 7050/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.076, critic: 0.087, entropy: -0.393, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.733\n",
      "\n",
      "n_iter: 7060/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.047, critic: 0.169, entropy: -0.423, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.693\n",
      "\n",
      "n_iter: 7070/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.011, critic: 0.129, entropy: -0.414, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.702\n",
      "\n",
      "n_iter: 7080/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.099, entropy: -0.408, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.721\n",
      "\n",
      "n_iter: 7090/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.034, critic: 0.108, entropy: -0.428, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.712\n",
      "\n",
      "n_iter: 7100/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.030, critic: 0.109, entropy: -0.401, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.714\n",
      "\n",
      "n_iter: 7110/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.075, critic: 0.091, entropy: -0.380, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.733\n",
      "\n",
      "n_iter: 7120/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.040, critic: 0.095, entropy: -0.381, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.722\n",
      "\n",
      "n_iter: 7130/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.141, critic: 0.204, entropy: -0.432, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.657\n",
      "\n",
      "n_iter: 7140/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.038, critic: 0.106, entropy: -0.403, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.717\n",
      "\n",
      "n_iter: 7150/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.064, critic: 0.090, entropy: -0.402, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.724\n",
      "\n",
      "n_iter: 7160/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.017, critic: 0.107, entropy: -0.403, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.716\n",
      "\n",
      "n_iter: 7170/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.065, critic: 0.089, entropy: -0.404, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.733\n",
      "\n",
      "n_iter: 7180/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.072, critic: 0.150, entropy: -0.476, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.677\n",
      "\n",
      "n_iter: 7190/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.198, critic: 0.257, entropy: -0.457, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.647\n",
      "\n",
      "n_iter: 7200/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.013, critic: 0.109, entropy: -0.375, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.720\n",
      "\n",
      "n_iter: 7210/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.047, critic: 0.147, entropy: -0.415, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.697\n",
      "\n",
      "n_iter: 7220/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.062, critic: 0.084, entropy: -0.422, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.720\n",
      "\n",
      "n_iter: 7230/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.067, critic: 0.097, entropy: -0.430, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.727\n",
      "\n",
      "n_iter: 7240/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.010, critic: 0.098, entropy: -0.434, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.702\n",
      "\n",
      "n_iter: 7250/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.046, critic: 0.096, entropy: -0.401, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.719\n",
      "\n",
      "n_iter: 7260/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.025, critic: 0.133, entropy: -0.428, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.699\n",
      "\n",
      "n_iter: 7270/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.010, critic: 0.118, entropy: -0.415, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.713\n",
      "\n",
      "n_iter: 7280/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.028, critic: 0.099, entropy: -0.419, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.717\n",
      "\n",
      "n_iter: 7290/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.034, critic: 0.131, entropy: -0.409, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.690\n",
      "\n",
      "n_iter: 7300/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.030, critic: 0.103, entropy: -0.409, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.720\n",
      "\n",
      "n_iter: 7310/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.027, critic: 0.090, entropy: -0.404, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.718\n",
      "\n",
      "n_iter: 7320/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.040, critic: 0.084, entropy: -0.449, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.718\n",
      "\n",
      "n_iter: 7330/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.040, critic: 0.150, entropy: -0.441, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.692\n",
      "\n",
      "n_iter: 7340/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.035, critic: 0.139, entropy: -0.439, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.699\n",
      "\n",
      "n_iter: 7350/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.104, critic: 0.169, entropy: -0.455, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.669\n",
      "\n",
      "n_iter: 7360/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.059, critic: 0.087, entropy: -0.402, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.726\n",
      "\n",
      "n_iter: 7370/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.029, critic: 0.131, entropy: -0.415, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.689\n",
      "\n",
      "n_iter: 7380/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.053, critic: 0.101, entropy: -0.411, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.719\n",
      "\n",
      "n_iter: 7390/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.003, critic: 0.117, entropy: -0.422, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.700\n",
      "\n",
      "n_iter: 7400/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.052, critic: 0.162, entropy: -0.410, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.687\n",
      "\n",
      "n_iter: 7410/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.050, critic: 0.107, entropy: -0.419, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.723\n",
      "\n",
      "n_iter: 7420/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.038, critic: 0.108, entropy: -0.418, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.720\n",
      "\n",
      "n_iter: 7430/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.001, critic: 0.123, entropy: -0.425, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.696\n",
      "\n",
      "n_iter: 7440/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.041, critic: 0.166, entropy: -0.469, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.687\n",
      "\n",
      "n_iter: 7450/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.042, critic: 0.099, entropy: -0.440, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.719\n",
      "\n",
      "n_iter: 7460/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.011, critic: 0.142, entropy: -0.442, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.708\n",
      "\n",
      "n_iter: 7470/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.176, critic: 0.229, entropy: -0.512, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.636\n",
      "\n",
      "n_iter: 7480/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.001, critic: 0.109, entropy: -0.443, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.709\n",
      "\n",
      "n_iter: 7490/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.012, critic: 0.126, entropy: -0.447, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.701\n",
      "\n",
      "n_iter: 7500/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.078, critic: 0.155, entropy: -0.439, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.678\n",
      "\n",
      "n_iter: 7510/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.038, critic: 0.085, entropy: -0.410, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.723\n",
      "\n",
      "n_iter: 7520/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.036, critic: 0.100, entropy: -0.452, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.713\n",
      "\n",
      "n_iter: 7530/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.064, critic: 0.085, entropy: -0.415, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.728\n",
      "\n",
      "n_iter: 7540/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.079, critic: 0.178, entropy: -0.429, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.679\n",
      "\n",
      "n_iter: 7550/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.015, critic: 0.117, entropy: -0.394, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.710\n",
      "\n",
      "n_iter: 7560/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.068, critic: 0.164, entropy: -0.456, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.682\n",
      "\n",
      "n_iter: 7570/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.053, critic: 0.142, entropy: -0.435, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.692\n",
      "\n",
      "n_iter: 7580/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.028, critic: 0.101, entropy: -0.430, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.712\n",
      "\n",
      "n_iter: 7590/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.008, critic: 0.125, entropy: -0.429, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.701\n",
      "\n",
      "n_iter: 7600/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.007, critic: 0.141, entropy: -0.420, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.704\n",
      "\n",
      "n_iter: 7610/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.058, critic: 0.090, entropy: -0.414, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.725\n",
      "\n",
      "n_iter: 7620/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.040, critic: 0.103, entropy: -0.386, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.721\n",
      "\n",
      "n_iter: 7630/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.045, critic: 0.095, entropy: -0.395, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.723\n",
      "\n",
      "n_iter: 7640/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.053, critic: 0.083, entropy: -0.414, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.728\n",
      "\n",
      "n_iter: 7650/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.084, critic: 0.169, entropy: -0.441, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.681\n",
      "\n",
      "n_iter: 7660/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.012, critic: 0.113, entropy: -0.430, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.712\n",
      "\n",
      "n_iter: 7670/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.020, critic: 0.125, entropy: -0.442, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.710\n",
      "\n",
      "n_iter: 7680/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.013, critic: 0.103, entropy: -0.435, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.714\n",
      "\n",
      "n_iter: 7690/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.167, critic: 0.226, entropy: -0.437, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.652\n",
      "\n",
      "n_iter: 7700/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.007, critic: 0.122, entropy: -0.420, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.708\n",
      "\n",
      "n_iter: 7710/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.135, critic: 0.229, entropy: -0.462, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.655\n",
      "\n",
      "n_iter: 7720/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.066, critic: 0.092, entropy: -0.402, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.726\n",
      "\n",
      "n_iter: 7730/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.014, critic: 0.139, entropy: -0.421, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.706\n",
      "\n",
      "n_iter: 7740/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.128, critic: 0.199, entropy: -0.459, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.659\n",
      "\n",
      "n_iter: 7750/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.029, critic: 0.113, entropy: -0.396, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.723\n",
      "\n",
      "n_iter: 7760/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.046, critic: 0.090, entropy: -0.411, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.722\n",
      "\n",
      "n_iter: 7770/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.009, critic: 0.130, entropy: -0.374, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.707\n",
      "\n",
      "n_iter: 7780/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.118, critic: 0.222, entropy: -0.468, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.663\n",
      "\n",
      "n_iter: 7790/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.004, critic: 0.127, entropy: -0.401, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.697\n",
      "\n",
      "n_iter: 7800/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.077, critic: 0.178, entropy: -0.425, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.684\n",
      "\n",
      "n_iter: 7810/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.009, critic: 0.147, entropy: -0.422, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.700\n",
      "\n",
      "n_iter: 7820/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.039, critic: 0.158, entropy: -0.404, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.694\n",
      "\n",
      "n_iter: 7830/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.000, critic: 0.112, entropy: -0.424, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.709\n",
      "\n",
      "n_iter: 7840/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.045, critic: 0.095, entropy: -0.420, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.723\n",
      "\n",
      "n_iter: 7850/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.029, critic: 0.114, entropy: -0.412, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.716\n",
      "\n",
      "n_iter: 7860/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.036, critic: 0.098, entropy: -0.392, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.720\n",
      "\n",
      "n_iter: 7870/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.008, critic: 0.117, entropy: -0.399, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.707\n",
      "\n",
      "n_iter: 7880/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.052, critic: 0.148, entropy: -0.419, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.697\n",
      "\n",
      "n_iter: 7890/8000, grad norm: 0.003. Training block: full\n",
      "actor: 0.225, critic: 0.253, entropy: -0.459, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.634\n",
      "\n",
      "n_iter: 7900/8000, grad norm: 0.002. Training block: full\n",
      "actor: 0.079, critic: 0.176, entropy: -0.429, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.682\n",
      "\n",
      "n_iter: 7910/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.001, critic: 0.124, entropy: -0.417, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.708\n",
      "\n",
      "n_iter: 7920/8000, grad norm: 0.004. Training block: full\n",
      "actor: 0.200, critic: 0.244, entropy: -0.440, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.646\n",
      "\n",
      "n_iter: 7930/8000, grad norm: 0.001. Training block: full\n",
      "actor: 0.014, critic: 0.124, entropy: -0.409, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.707\n",
      "\n",
      "n_iter: 7940/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.073, critic: 0.083, entropy: -0.372, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.731\n",
      "\n",
      "n_iter: 7950/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.061, critic: 0.096, entropy: -0.383, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.726\n",
      "\n",
      "n_iter: 7960/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.059, critic: 0.089, entropy: -0.393, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.725\n",
      "\n",
      "n_iter: 7970/8000, grad norm: 0.002. Training block: full\n",
      "actor: -0.001, critic: 0.135, entropy: -0.418, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.702\n",
      "\n",
      "n_iter: 7980/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.069, critic: 0.085, entropy: -0.359, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.733\n",
      "\n",
      "n_iter: 7990/8000, grad norm: 0.001. Training block: full\n",
      "actor: -0.058, critic: 0.085, entropy: -0.372, ae: 0.000, lstm: 0.000\n",
      "Average reward: 0.731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "progress_ac = train(\n",
    "    agent = agent_ac, \n",
    "    num_iterations = [8000], \n",
    "    iter_per_batch = [2], \n",
    "    blocks = [['full']]\n",
    ")\n",
    "\n",
    "filename = 'stats_ac_low_entr.json'\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(progress_ac, f, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "682e1727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter: 0/2000, grad norm: 0.016. Training block: ae\n",
      "actor: -0.754, critic: 0.433, entropy: -2.170, ae: 1.335, lstm: 0.000\n",
      "Average reward: 0.338\n",
      "\n",
      "n_iter: 10/2000, grad norm: 0.010. Training block: ae\n",
      "actor: -0.768, critic: 0.442, entropy: -2.194, ae: 1.213, lstm: 0.000\n",
      "Average reward: 0.342\n",
      "\n",
      "n_iter: 20/2000, grad norm: 0.012. Training block: ae\n",
      "actor: -0.687, critic: 0.407, entropy: -2.207, ae: 1.123, lstm: 0.000\n",
      "Average reward: 0.332\n",
      "\n",
      "n_iter: 30/2000, grad norm: 0.008. Training block: ae\n",
      "actor: -0.600, critic: 0.349, entropy: -2.206, ae: 1.009, lstm: 0.000\n",
      "Average reward: 0.313\n",
      "\n",
      "n_iter: 40/2000, grad norm: 0.007. Training block: ae\n",
      "actor: -0.774, critic: 0.445, entropy: -2.193, ae: 0.956, lstm: 0.000\n",
      "Average reward: 0.350\n",
      "\n",
      "n_iter: 50/2000, grad norm: 0.005. Training block: ae\n",
      "actor: -0.785, critic: 0.453, entropy: -2.196, ae: 0.884, lstm: 0.000\n",
      "Average reward: 0.351\n",
      "\n",
      "n_iter: 60/2000, grad norm: 0.007. Training block: ae\n",
      "actor: -0.668, critic: 0.377, entropy: -2.188, ae: 0.838, lstm: 0.000\n",
      "Average reward: 0.326\n",
      "\n",
      "n_iter: 70/2000, grad norm: 0.005. Training block: ae\n",
      "actor: -0.734, critic: 0.422, entropy: -2.195, ae: 0.816, lstm: 0.000\n",
      "Average reward: 0.337\n",
      "\n",
      "n_iter: 80/2000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.750, critic: 0.433, entropy: -2.198, ae: 0.776, lstm: 0.000\n",
      "Average reward: 0.339\n",
      "\n",
      "n_iter: 90/2000, grad norm: 0.006. Training block: ae\n",
      "actor: -0.648, critic: 0.379, entropy: -2.209, ae: 0.748, lstm: 0.000\n",
      "Average reward: 0.336\n",
      "\n",
      "n_iter: 100/2000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.775, critic: 0.447, entropy: -2.201, ae: 0.705, lstm: 0.000\n",
      "Average reward: 0.351\n",
      "\n",
      "n_iter: 110/2000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.775, critic: 0.441, entropy: -2.206, ae: 0.677, lstm: 0.000\n",
      "Average reward: 0.352\n",
      "\n",
      "n_iter: 120/2000, grad norm: 0.006. Training block: ae\n",
      "actor: -0.622, critic: 0.354, entropy: -2.200, ae: 0.640, lstm: 0.000\n",
      "Average reward: 0.317\n",
      "\n",
      "n_iter: 130/2000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.786, critic: 0.447, entropy: -2.207, ae: 0.614, lstm: 0.000\n",
      "Average reward: 0.351\n",
      "\n",
      "n_iter: 140/2000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.748, critic: 0.429, entropy: -2.205, ae: 0.571, lstm: 0.000\n",
      "Average reward: 0.344\n",
      "\n",
      "n_iter: 150/2000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.677, critic: 0.393, entropy: -2.211, ae: 0.559, lstm: 0.000\n",
      "Average reward: 0.326\n",
      "\n",
      "n_iter: 160/2000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.693, critic: 0.401, entropy: -2.209, ae: 0.558, lstm: 0.000\n",
      "Average reward: 0.338\n",
      "\n",
      "n_iter: 170/2000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.726, critic: 0.407, entropy: -2.211, ae: 0.544, lstm: 0.000\n",
      "Average reward: 0.337\n",
      "\n",
      "n_iter: 180/2000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.713, critic: 0.416, entropy: -2.209, ae: 0.518, lstm: 0.000\n",
      "Average reward: 0.338\n",
      "\n",
      "n_iter: 190/2000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.790, critic: 0.457, entropy: -2.207, ae: 0.482, lstm: 0.000\n",
      "Average reward: 0.354\n",
      "\n",
      "n_iter: 200/2000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.771, critic: 0.440, entropy: -2.215, ae: 0.477, lstm: 0.000\n",
      "Average reward: 0.347\n",
      "\n",
      "n_iter: 210/2000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.731, critic: 0.423, entropy: -2.200, ae: 0.455, lstm: 0.000\n",
      "Average reward: 0.337\n",
      "\n",
      "n_iter: 220/2000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.742, critic: 0.425, entropy: -2.213, ae: 0.442, lstm: 0.000\n",
      "Average reward: 0.340\n",
      "\n",
      "n_iter: 230/2000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.680, critic: 0.389, entropy: -2.214, ae: 0.435, lstm: 0.000\n",
      "Average reward: 0.332\n",
      "\n",
      "n_iter: 240/2000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.764, critic: 0.434, entropy: -2.206, ae: 0.413, lstm: 0.000\n",
      "Average reward: 0.344\n",
      "\n",
      "n_iter: 250/2000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.795, critic: 0.456, entropy: -2.206, ae: 0.392, lstm: 0.000\n",
      "Average reward: 0.356\n",
      "\n",
      "n_iter: 260/2000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.709, critic: 0.402, entropy: -2.223, ae: 0.397, lstm: 0.000\n",
      "Average reward: 0.337\n",
      "\n",
      "n_iter: 270/2000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.771, critic: 0.439, entropy: -2.216, ae: 0.381, lstm: 0.000\n",
      "Average reward: 0.349\n",
      "\n",
      "n_iter: 280/2000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.588, critic: 0.335, entropy: -2.223, ae: 0.379, lstm: 0.000\n",
      "Average reward: 0.304\n",
      "\n",
      "n_iter: 290/2000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.661, critic: 0.373, entropy: -2.220, ae: 0.357, lstm: 0.000\n",
      "Average reward: 0.324\n",
      "\n",
      "n_iter: 300/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.707, critic: 0.402, entropy: -2.206, ae: 0.347, lstm: 0.000\n",
      "Average reward: 0.346\n",
      "\n",
      "n_iter: 310/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.736, critic: 0.428, entropy: -2.206, ae: 0.345, lstm: 0.000\n",
      "Average reward: 0.344\n",
      "\n",
      "n_iter: 320/2000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.767, critic: 0.434, entropy: -2.215, ae: 0.332, lstm: 0.000\n",
      "Average reward: 0.346\n",
      "\n",
      "n_iter: 330/2000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.680, critic: 0.388, entropy: -2.214, ae: 0.326, lstm: 0.000\n",
      "Average reward: 0.335\n",
      "\n",
      "n_iter: 340/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.768, critic: 0.431, entropy: -2.208, ae: 0.315, lstm: 0.000\n",
      "Average reward: 0.344\n",
      "\n",
      "n_iter: 350/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.771, critic: 0.438, entropy: -2.211, ae: 0.311, lstm: 0.000\n",
      "Average reward: 0.349\n",
      "\n",
      "n_iter: 360/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.585, critic: 0.320, entropy: -2.210, ae: 0.294, lstm: 0.000\n",
      "Average reward: 0.292\n",
      "\n",
      "n_iter: 370/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.743, critic: 0.425, entropy: -2.211, ae: 0.292, lstm: 0.000\n",
      "Average reward: 0.347\n",
      "\n",
      "n_iter: 380/2000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.745, critic: 0.423, entropy: -2.217, ae: 0.285, lstm: 0.000\n",
      "Average reward: 0.350\n",
      "\n",
      "n_iter: 390/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.792, critic: 0.451, entropy: -2.211, ae: 0.282, lstm: 0.000\n",
      "Average reward: 0.355\n",
      "\n",
      "n_iter: 400/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.762, critic: 0.436, entropy: -2.208, ae: 0.273, lstm: 0.000\n",
      "Average reward: 0.358\n",
      "\n",
      "n_iter: 410/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.785, critic: 0.450, entropy: -2.207, ae: 0.269, lstm: 0.000\n",
      "Average reward: 0.348\n",
      "\n",
      "n_iter: 420/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.751, critic: 0.427, entropy: -2.216, ae: 0.265, lstm: 0.000\n",
      "Average reward: 0.343\n",
      "\n",
      "n_iter: 430/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.691, critic: 0.388, entropy: -2.210, ae: 0.263, lstm: 0.000\n",
      "Average reward: 0.327\n",
      "\n",
      "n_iter: 440/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.766, critic: 0.436, entropy: -2.215, ae: 0.249, lstm: 0.000\n",
      "Average reward: 0.350\n",
      "\n",
      "n_iter: 450/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.721, critic: 0.407, entropy: -2.213, ae: 0.250, lstm: 0.000\n",
      "Average reward: 0.339\n",
      "\n",
      "n_iter: 460/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.763, critic: 0.435, entropy: -2.211, ae: 0.257, lstm: 0.000\n",
      "Average reward: 0.346\n",
      "\n",
      "n_iter: 470/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.740, critic: 0.414, entropy: -2.204, ae: 0.238, lstm: 0.000\n",
      "Average reward: 0.341\n",
      "\n",
      "n_iter: 480/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.797, critic: 0.453, entropy: -2.210, ae: 0.223, lstm: 0.000\n",
      "Average reward: 0.359\n",
      "\n",
      "n_iter: 490/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.763, critic: 0.430, entropy: -2.205, ae: 0.218, lstm: 0.000\n",
      "Average reward: 0.352\n",
      "\n",
      "n_iter: 500/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.754, critic: 0.426, entropy: -2.209, ae: 0.219, lstm: 0.000\n",
      "Average reward: 0.340\n",
      "\n",
      "n_iter: 510/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.606, critic: 0.332, entropy: -2.205, ae: 0.213, lstm: 0.000\n",
      "Average reward: 0.303\n",
      "\n",
      "n_iter: 520/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.698, critic: 0.393, entropy: -2.207, ae: 0.207, lstm: 0.000\n",
      "Average reward: 0.340\n",
      "\n",
      "n_iter: 530/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.738, critic: 0.422, entropy: -2.205, ae: 0.209, lstm: 0.000\n",
      "Average reward: 0.340\n",
      "\n",
      "n_iter: 540/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.626, critic: 0.361, entropy: -2.208, ae: 0.204, lstm: 0.000\n",
      "Average reward: 0.310\n",
      "\n",
      "n_iter: 550/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.800, critic: 0.458, entropy: -2.211, ae: 0.200, lstm: 0.000\n",
      "Average reward: 0.358\n",
      "\n",
      "n_iter: 560/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.772, critic: 0.439, entropy: -2.207, ae: 0.194, lstm: 0.000\n",
      "Average reward: 0.349\n",
      "\n",
      "n_iter: 570/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.762, critic: 0.432, entropy: -2.210, ae: 0.190, lstm: 0.000\n",
      "Average reward: 0.347\n",
      "\n",
      "n_iter: 580/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.730, critic: 0.407, entropy: -2.207, ae: 0.184, lstm: 0.000\n",
      "Average reward: 0.336\n",
      "\n",
      "n_iter: 590/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.787, critic: 0.449, entropy: -2.204, ae: 0.179, lstm: 0.000\n",
      "Average reward: 0.348\n",
      "\n",
      "n_iter: 600/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.785, critic: 0.446, entropy: -2.209, ae: 0.182, lstm: 0.000\n",
      "Average reward: 0.351\n",
      "\n",
      "n_iter: 610/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.767, critic: 0.439, entropy: -2.206, ae: 0.173, lstm: 0.000\n",
      "Average reward: 0.353\n",
      "\n",
      "n_iter: 620/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.780, critic: 0.443, entropy: -2.208, ae: 0.168, lstm: 0.000\n",
      "Average reward: 0.351\n",
      "\n",
      "n_iter: 630/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.696, critic: 0.394, entropy: -2.212, ae: 0.175, lstm: 0.000\n",
      "Average reward: 0.331\n",
      "\n",
      "n_iter: 640/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.675, critic: 0.373, entropy: -2.201, ae: 0.174, lstm: 0.000\n",
      "Average reward: 0.321\n",
      "\n",
      "n_iter: 650/2000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.634, critic: 0.370, entropy: -2.206, ae: 0.161, lstm: 0.000\n",
      "Average reward: 0.327\n",
      "\n",
      "n_iter: 660/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.788, critic: 0.452, entropy: -2.209, ae: 0.159, lstm: 0.000\n",
      "Average reward: 0.358\n",
      "\n",
      "n_iter: 670/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.765, critic: 0.439, entropy: -2.209, ae: 0.164, lstm: 0.000\n",
      "Average reward: 0.347\n",
      "\n",
      "n_iter: 680/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.757, critic: 0.423, entropy: -2.208, ae: 0.157, lstm: 0.000\n",
      "Average reward: 0.338\n",
      "\n",
      "n_iter: 690/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.683, critic: 0.380, entropy: -2.206, ae: 0.147, lstm: 0.000\n",
      "Average reward: 0.327\n",
      "\n",
      "n_iter: 700/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.800, critic: 0.454, entropy: -2.206, ae: 0.150, lstm: 0.000\n",
      "Average reward: 0.359\n",
      "\n",
      "n_iter: 710/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.774, critic: 0.438, entropy: -2.203, ae: 0.150, lstm: 0.000\n",
      "Average reward: 0.344\n",
      "\n",
      "n_iter: 720/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.713, critic: 0.405, entropy: -2.203, ae: 0.149, lstm: 0.000\n",
      "Average reward: 0.331\n",
      "\n",
      "n_iter: 730/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.803, critic: 0.460, entropy: -2.211, ae: 0.147, lstm: 0.000\n",
      "Average reward: 0.357\n",
      "\n",
      "n_iter: 740/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.760, critic: 0.436, entropy: -2.205, ae: 0.146, lstm: 0.000\n",
      "Average reward: 0.348\n",
      "\n",
      "n_iter: 750/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.730, critic: 0.411, entropy: -2.214, ae: 0.144, lstm: 0.000\n",
      "Average reward: 0.342\n",
      "\n",
      "n_iter: 760/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.794, critic: 0.452, entropy: -2.207, ae: 0.143, lstm: 0.000\n",
      "Average reward: 0.353\n",
      "\n",
      "n_iter: 770/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.677, critic: 0.387, entropy: -2.216, ae: 0.143, lstm: 0.000\n",
      "Average reward: 0.326\n",
      "\n",
      "n_iter: 780/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.787, critic: 0.445, entropy: -2.209, ae: 0.143, lstm: 0.000\n",
      "Average reward: 0.348\n",
      "\n",
      "n_iter: 790/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.776, critic: 0.443, entropy: -2.204, ae: 0.142, lstm: 0.000\n",
      "Average reward: 0.348\n",
      "\n",
      "n_iter: 800/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.702, critic: 0.400, entropy: -2.207, ae: 0.141, lstm: 0.000\n",
      "Average reward: 0.326\n",
      "\n",
      "n_iter: 810/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.670, critic: 0.384, entropy: -2.200, ae: 0.143, lstm: 0.000\n",
      "Average reward: 0.336\n",
      "\n",
      "n_iter: 820/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.790, critic: 0.451, entropy: -2.210, ae: 0.137, lstm: 0.000\n",
      "Average reward: 0.353\n",
      "\n",
      "n_iter: 830/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.779, critic: 0.439, entropy: -2.206, ae: 0.138, lstm: 0.000\n",
      "Average reward: 0.352\n",
      "\n",
      "n_iter: 840/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.735, critic: 0.418, entropy: -2.209, ae: 0.132, lstm: 0.000\n",
      "Average reward: 0.342\n",
      "\n",
      "n_iter: 850/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.759, critic: 0.434, entropy: -2.208, ae: 0.132, lstm: 0.000\n",
      "Average reward: 0.346\n",
      "\n",
      "n_iter: 860/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.751, critic: 0.423, entropy: -2.207, ae: 0.131, lstm: 0.000\n",
      "Average reward: 0.333\n",
      "\n",
      "n_iter: 870/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.638, critic: 0.351, entropy: -2.209, ae: 0.125, lstm: 0.000\n",
      "Average reward: 0.317\n",
      "\n",
      "n_iter: 880/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.794, critic: 0.454, entropy: -2.209, ae: 0.130, lstm: 0.000\n",
      "Average reward: 0.359\n",
      "\n",
      "n_iter: 890/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.797, critic: 0.461, entropy: -2.203, ae: 0.131, lstm: 0.000\n",
      "Average reward: 0.359\n",
      "\n",
      "n_iter: 900/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.779, critic: 0.443, entropy: -2.206, ae: 0.131, lstm: 0.000\n",
      "Average reward: 0.349\n",
      "\n",
      "n_iter: 910/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.710, critic: 0.400, entropy: -2.208, ae: 0.130, lstm: 0.000\n",
      "Average reward: 0.331\n",
      "\n",
      "n_iter: 920/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.756, critic: 0.430, entropy: -2.205, ae: 0.129, lstm: 0.000\n",
      "Average reward: 0.344\n",
      "\n",
      "n_iter: 930/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.782, critic: 0.451, entropy: -2.208, ae: 0.133, lstm: 0.000\n",
      "Average reward: 0.348\n",
      "\n",
      "n_iter: 940/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.747, critic: 0.429, entropy: -2.203, ae: 0.130, lstm: 0.000\n",
      "Average reward: 0.343\n",
      "\n",
      "n_iter: 950/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.796, critic: 0.454, entropy: -2.201, ae: 0.126, lstm: 0.000\n",
      "Average reward: 0.356\n",
      "\n",
      "n_iter: 960/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.711, critic: 0.404, entropy: -2.199, ae: 0.126, lstm: 0.000\n",
      "Average reward: 0.337\n",
      "\n",
      "n_iter: 970/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.693, critic: 0.401, entropy: -2.211, ae: 0.123, lstm: 0.000\n",
      "Average reward: 0.335\n",
      "\n",
      "n_iter: 980/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.711, critic: 0.404, entropy: -2.199, ae: 0.127, lstm: 0.000\n",
      "Average reward: 0.336\n",
      "\n",
      "n_iter: 990/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.769, critic: 0.443, entropy: -2.205, ae: 0.127, lstm: 0.000\n",
      "Average reward: 0.352\n",
      "\n",
      "n_iter: 1000/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.762, critic: 0.432, entropy: -2.205, ae: 0.125, lstm: 0.000\n",
      "Average reward: 0.346\n",
      "\n",
      "n_iter: 1010/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.728, critic: 0.416, entropy: -2.211, ae: 0.125, lstm: 0.000\n",
      "Average reward: 0.339\n",
      "\n",
      "n_iter: 1020/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.660, critic: 0.387, entropy: -2.199, ae: 0.125, lstm: 0.000\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 1030/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.745, critic: 0.425, entropy: -2.204, ae: 0.121, lstm: 0.000\n",
      "Average reward: 0.336\n",
      "\n",
      "n_iter: 1040/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.732, critic: 0.427, entropy: -2.207, ae: 0.123, lstm: 0.000\n",
      "Average reward: 0.348\n",
      "\n",
      "n_iter: 1050/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.723, critic: 0.413, entropy: -2.197, ae: 0.118, lstm: 0.000\n",
      "Average reward: 0.334\n",
      "\n",
      "n_iter: 1060/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.761, critic: 0.436, entropy: -2.199, ae: 0.123, lstm: 0.000\n",
      "Average reward: 0.348\n",
      "\n",
      "n_iter: 1070/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.761, critic: 0.440, entropy: -2.206, ae: 0.121, lstm: 0.000\n",
      "Average reward: 0.343\n",
      "\n",
      "n_iter: 1080/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.709, critic: 0.399, entropy: -2.204, ae: 0.120, lstm: 0.000\n",
      "Average reward: 0.328\n",
      "\n",
      "n_iter: 1090/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.738, critic: 0.423, entropy: -2.201, ae: 0.118, lstm: 0.000\n",
      "Average reward: 0.335\n",
      "\n",
      "n_iter: 1100/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.713, critic: 0.407, entropy: -2.217, ae: 0.119, lstm: 0.000\n",
      "Average reward: 0.338\n",
      "\n",
      "n_iter: 1110/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.668, critic: 0.395, entropy: -2.195, ae: 0.117, lstm: 0.000\n",
      "Average reward: 0.334\n",
      "\n",
      "n_iter: 1120/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.788, critic: 0.453, entropy: -2.206, ae: 0.113, lstm: 0.000\n",
      "Average reward: 0.353\n",
      "\n",
      "n_iter: 1130/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.734, critic: 0.420, entropy: -2.196, ae: 0.118, lstm: 0.000\n",
      "Average reward: 0.342\n",
      "\n",
      "n_iter: 1140/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.711, critic: 0.406, entropy: -2.205, ae: 0.117, lstm: 0.000\n",
      "Average reward: 0.335\n",
      "\n",
      "n_iter: 1150/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.790, critic: 0.450, entropy: -2.206, ae: 0.115, lstm: 0.000\n",
      "Average reward: 0.348\n",
      "\n",
      "n_iter: 1160/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.726, critic: 0.412, entropy: -2.211, ae: 0.111, lstm: 0.000\n",
      "Average reward: 0.334\n",
      "\n",
      "n_iter: 1170/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.781, critic: 0.446, entropy: -2.208, ae: 0.115, lstm: 0.000\n",
      "Average reward: 0.349\n",
      "\n",
      "n_iter: 1180/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.800, critic: 0.462, entropy: -2.206, ae: 0.113, lstm: 0.000\n",
      "Average reward: 0.357\n",
      "\n",
      "n_iter: 1190/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.702, critic: 0.405, entropy: -2.198, ae: 0.112, lstm: 0.000\n",
      "Average reward: 0.335\n",
      "\n",
      "n_iter: 1200/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.754, critic: 0.434, entropy: -2.203, ae: 0.113, lstm: 0.000\n",
      "Average reward: 0.341\n",
      "\n",
      "n_iter: 1210/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.745, critic: 0.431, entropy: -2.207, ae: 0.111, lstm: 0.000\n",
      "Average reward: 0.344\n",
      "\n",
      "n_iter: 1220/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.745, critic: 0.432, entropy: -2.198, ae: 0.109, lstm: 0.000\n",
      "Average reward: 0.343\n",
      "\n",
      "n_iter: 1230/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.797, critic: 0.459, entropy: -2.206, ae: 0.113, lstm: 0.000\n",
      "Average reward: 0.356\n",
      "\n",
      "n_iter: 1240/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.792, critic: 0.455, entropy: -2.208, ae: 0.114, lstm: 0.000\n",
      "Average reward: 0.353\n",
      "\n",
      "n_iter: 1250/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.754, critic: 0.440, entropy: -2.200, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.349\n",
      "\n",
      "n_iter: 1260/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.746, critic: 0.429, entropy: -2.192, ae: 0.109, lstm: 0.000\n",
      "Average reward: 0.348\n",
      "\n",
      "n_iter: 1270/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.807, critic: 0.466, entropy: -2.206, ae: 0.111, lstm: 0.000\n",
      "Average reward: 0.357\n",
      "\n",
      "n_iter: 1280/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.694, critic: 0.398, entropy: -2.211, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.337\n",
      "\n",
      "n_iter: 1290/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.799, critic: 0.461, entropy: -2.204, ae: 0.110, lstm: 0.000\n",
      "Average reward: 0.355\n",
      "\n",
      "n_iter: 1300/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.797, critic: 0.456, entropy: -2.195, ae: 0.110, lstm: 0.000\n",
      "Average reward: 0.355\n",
      "\n",
      "n_iter: 1310/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.701, critic: 0.390, entropy: -2.189, ae: 0.112, lstm: 0.000\n",
      "Average reward: 0.334\n",
      "\n",
      "n_iter: 1320/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.708, critic: 0.407, entropy: -2.203, ae: 0.108, lstm: 0.000\n",
      "Average reward: 0.342\n",
      "\n",
      "n_iter: 1330/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.793, critic: 0.459, entropy: -2.204, ae: 0.109, lstm: 0.000\n",
      "Average reward: 0.351\n",
      "\n",
      "n_iter: 1340/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.773, critic: 0.439, entropy: -2.206, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.345\n",
      "\n",
      "n_iter: 1350/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.788, critic: 0.460, entropy: -2.193, ae: 0.109, lstm: 0.000\n",
      "Average reward: 0.360\n",
      "\n",
      "n_iter: 1360/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.742, critic: 0.433, entropy: -2.206, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.357\n",
      "\n",
      "n_iter: 1370/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.755, critic: 0.434, entropy: -2.210, ae: 0.111, lstm: 0.000\n",
      "Average reward: 0.349\n",
      "\n",
      "n_iter: 1380/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.790, critic: 0.457, entropy: -2.209, ae: 0.108, lstm: 0.000\n",
      "Average reward: 0.351\n",
      "\n",
      "n_iter: 1390/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.614, critic: 0.354, entropy: -2.198, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.313\n",
      "\n",
      "n_iter: 1400/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.737, critic: 0.436, entropy: -2.208, ae: 0.108, lstm: 0.000\n",
      "Average reward: 0.346\n",
      "\n",
      "n_iter: 1410/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.751, critic: 0.433, entropy: -2.204, ae: 0.109, lstm: 0.000\n",
      "Average reward: 0.343\n",
      "\n",
      "n_iter: 1420/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.741, critic: 0.423, entropy: -2.201, ae: 0.110, lstm: 0.000\n",
      "Average reward: 0.342\n",
      "\n",
      "n_iter: 1430/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.729, critic: 0.427, entropy: -2.195, ae: 0.112, lstm: 0.000\n",
      "Average reward: 0.345\n",
      "\n",
      "n_iter: 1440/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.752, critic: 0.432, entropy: -2.201, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.346\n",
      "\n",
      "n_iter: 1450/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.798, critic: 0.463, entropy: -2.194, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.354\n",
      "\n",
      "n_iter: 1460/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.790, critic: 0.456, entropy: -2.200, ae: 0.109, lstm: 0.000\n",
      "Average reward: 0.352\n",
      "\n",
      "n_iter: 1470/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.779, critic: 0.449, entropy: -2.202, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.344\n",
      "\n",
      "n_iter: 1480/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.734, critic: 0.423, entropy: -2.202, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.335\n",
      "\n",
      "n_iter: 1490/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.704, critic: 0.405, entropy: -2.194, ae: 0.108, lstm: 0.000\n",
      "Average reward: 0.338\n",
      "\n",
      "n_iter: 1500/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.715, critic: 0.415, entropy: -2.202, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.343\n",
      "\n",
      "n_iter: 1510/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.756, critic: 0.437, entropy: -2.195, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.343\n",
      "\n",
      "n_iter: 1520/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.774, critic: 0.445, entropy: -2.199, ae: 0.109, lstm: 0.000\n",
      "Average reward: 0.345\n",
      "\n",
      "n_iter: 1530/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.767, critic: 0.447, entropy: -2.200, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.351\n",
      "\n",
      "n_iter: 1540/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.795, critic: 0.462, entropy: -2.199, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.354\n",
      "\n",
      "n_iter: 1550/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.738, critic: 0.425, entropy: -2.198, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.342\n",
      "\n",
      "n_iter: 1560/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.655, critic: 0.377, entropy: -2.199, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.329\n",
      "\n",
      "n_iter: 1570/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.726, critic: 0.419, entropy: -2.195, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.345\n",
      "\n",
      "n_iter: 1580/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.722, critic: 0.417, entropy: -2.191, ae: 0.109, lstm: 0.000\n",
      "Average reward: 0.342\n",
      "\n",
      "n_iter: 1590/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.698, critic: 0.412, entropy: -2.189, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.340\n",
      "\n",
      "n_iter: 1600/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.765, critic: 0.440, entropy: -2.200, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.343\n",
      "\n",
      "n_iter: 1610/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.759, critic: 0.438, entropy: -2.198, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.348\n",
      "\n",
      "n_iter: 1620/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.733, critic: 0.425, entropy: -2.195, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.338\n",
      "\n",
      "n_iter: 1630/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.706, critic: 0.406, entropy: -2.205, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.335\n",
      "\n",
      "n_iter: 1640/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.777, critic: 0.446, entropy: -2.202, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.354\n",
      "\n",
      "n_iter: 1650/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.806, critic: 0.470, entropy: -2.198, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.362\n",
      "\n",
      "n_iter: 1660/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.691, critic: 0.400, entropy: -2.206, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.327\n",
      "\n",
      "n_iter: 1670/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.666, critic: 0.388, entropy: -2.202, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.326\n",
      "\n",
      "n_iter: 1680/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.775, critic: 0.452, entropy: -2.198, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.354\n",
      "\n",
      "n_iter: 1690/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.771, critic: 0.452, entropy: -2.202, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.347\n",
      "\n",
      "n_iter: 1700/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.784, critic: 0.454, entropy: -2.201, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.353\n",
      "\n",
      "n_iter: 1710/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.596, critic: 0.329, entropy: -2.203, ae: 0.109, lstm: 0.000\n",
      "Average reward: 0.295\n",
      "\n",
      "n_iter: 1720/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.798, critic: 0.461, entropy: -2.199, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.355\n",
      "\n",
      "n_iter: 1730/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.760, critic: 0.436, entropy: -2.201, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.350\n",
      "\n",
      "n_iter: 1740/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.680, critic: 0.387, entropy: -2.204, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.328\n",
      "\n",
      "n_iter: 1750/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.608, critic: 0.346, entropy: -2.199, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.305\n",
      "\n",
      "n_iter: 1760/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.783, critic: 0.453, entropy: -2.197, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.347\n",
      "\n",
      "n_iter: 1770/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.664, critic: 0.383, entropy: -2.206, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 1780/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.753, critic: 0.438, entropy: -2.199, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.346\n",
      "\n",
      "n_iter: 1790/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.789, critic: 0.461, entropy: -2.202, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.355\n",
      "\n",
      "n_iter: 1800/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.765, critic: 0.444, entropy: -2.199, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.349\n",
      "\n",
      "n_iter: 1810/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.803, critic: 0.466, entropy: -2.201, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.358\n",
      "\n",
      "n_iter: 1820/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.762, critic: 0.445, entropy: -2.198, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.345\n",
      "\n",
      "n_iter: 1830/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.684, critic: 0.410, entropy: -2.217, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.338\n",
      "\n",
      "n_iter: 1840/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.703, critic: 0.406, entropy: -2.199, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.341\n",
      "\n",
      "n_iter: 1850/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.753, critic: 0.435, entropy: -2.202, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.343\n",
      "\n",
      "n_iter: 1860/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.684, critic: 0.388, entropy: -2.207, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.329\n",
      "\n",
      "n_iter: 1870/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.756, critic: 0.435, entropy: -2.201, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.344\n",
      "\n",
      "n_iter: 1880/2000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.768, critic: 0.446, entropy: -2.207, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.342\n",
      "\n",
      "n_iter: 1890/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.762, critic: 0.444, entropy: -2.206, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.343\n",
      "\n",
      "n_iter: 1900/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.698, critic: 0.401, entropy: -2.200, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.336\n",
      "\n",
      "n_iter: 1910/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.779, critic: 0.449, entropy: -2.199, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.348\n",
      "\n",
      "n_iter: 1920/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.781, critic: 0.455, entropy: -2.200, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.353\n",
      "\n",
      "n_iter: 1930/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.630, critic: 0.363, entropy: -2.199, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.322\n",
      "\n",
      "n_iter: 1940/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.797, critic: 0.465, entropy: -2.203, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.357\n",
      "\n",
      "n_iter: 1950/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.649, critic: 0.370, entropy: -2.193, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.327\n",
      "\n",
      "n_iter: 1960/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.730, critic: 0.416, entropy: -2.201, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.334\n",
      "\n",
      "n_iter: 1970/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.727, critic: 0.425, entropy: -2.201, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.337\n",
      "\n",
      "n_iter: 1980/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.739, critic: 0.431, entropy: -2.211, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.349\n",
      "\n",
      "n_iter: 1990/2000, grad norm: 0.000. Training block: ae\n",
      "actor: -0.720, critic: 0.406, entropy: -2.199, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.331\n",
      "\n",
      "n_iter: 0/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.805, critic: 0.469, entropy: -2.202, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.356\n",
      "\n",
      "n_iter: 10/2000, grad norm: 0.015. Training block: actor\n",
      "actor: -0.744, critic: 0.426, entropy: -2.205, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.353\n",
      "\n",
      "n_iter: 20/2000, grad norm: 0.015. Training block: actor\n",
      "actor: -0.648, critic: 0.366, entropy: -2.207, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.328\n",
      "\n",
      "n_iter: 30/2000, grad norm: 0.015. Training block: critic\n",
      "actor: -0.762, critic: 0.418, entropy: -2.207, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.353\n",
      "\n",
      "n_iter: 40/2000, grad norm: 0.012. Training block: actor\n",
      "actor: -0.738, critic: 0.397, entropy: -2.202, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.346\n",
      "\n",
      "n_iter: 50/2000, grad norm: 0.016. Training block: critic\n",
      "actor: -0.762, critic: 0.418, entropy: -2.210, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.367\n",
      "\n",
      "n_iter: 60/2000, grad norm: 0.012. Training block: critic\n",
      "actor: -0.762, critic: 0.414, entropy: -2.211, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.367\n",
      "\n",
      "n_iter: 70/2000, grad norm: 0.012. Training block: actor\n",
      "actor: -0.688, critic: 0.365, entropy: -2.201, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.345\n",
      "\n",
      "n_iter: 80/2000, grad norm: 0.014. Training block: critic\n",
      "actor: -0.698, critic: 0.374, entropy: -2.211, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.354\n",
      "\n",
      "n_iter: 90/2000, grad norm: 0.012. Training block: critic\n",
      "actor: -0.747, critic: 0.400, entropy: -2.220, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.370\n",
      "\n",
      "n_iter: 100/2000, grad norm: 0.011. Training block: critic\n",
      "actor: -0.762, critic: 0.408, entropy: -2.218, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.377\n",
      "\n",
      "n_iter: 110/2000, grad norm: 0.014. Training block: critic\n",
      "actor: -0.686, critic: 0.356, entropy: -2.221, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.356\n",
      "\n",
      "n_iter: 120/2000, grad norm: 0.013. Training block: critic\n",
      "actor: -0.708, critic: 0.373, entropy: -2.221, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.360\n",
      "\n",
      "n_iter: 130/2000, grad norm: 0.011. Training block: actor\n",
      "actor: -0.669, critic: 0.353, entropy: -2.226, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.362\n",
      "\n",
      "n_iter: 140/2000, grad norm: 0.013. Training block: critic\n",
      "actor: -0.706, critic: 0.371, entropy: -2.235, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.375\n",
      "\n",
      "n_iter: 150/2000, grad norm: 0.012. Training block: actor\n",
      "actor: -0.687, critic: 0.359, entropy: -2.224, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.368\n",
      "\n",
      "n_iter: 160/2000, grad norm: 0.012. Training block: critic\n",
      "actor: -0.698, critic: 0.368, entropy: -2.228, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.375\n",
      "\n",
      "n_iter: 170/2000, grad norm: 0.014. Training block: critic\n",
      "actor: -0.661, critic: 0.345, entropy: -2.242, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.363\n",
      "\n",
      "n_iter: 180/2000, grad norm: 0.012. Training block: critic\n",
      "actor: -0.685, critic: 0.362, entropy: -2.237, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.373\n",
      "\n",
      "n_iter: 190/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.735, critic: 0.383, entropy: -2.243, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.380\n",
      "\n",
      "n_iter: 200/2000, grad norm: 0.011. Training block: actor\n",
      "actor: -0.545, critic: 0.279, entropy: -2.248, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.335\n",
      "\n",
      "n_iter: 210/2000, grad norm: 0.012. Training block: critic\n",
      "actor: -0.669, critic: 0.351, entropy: -2.247, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.373\n",
      "\n",
      "n_iter: 220/2000, grad norm: 0.011. Training block: actor\n",
      "actor: -0.672, critic: 0.356, entropy: -2.247, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.382\n",
      "\n",
      "n_iter: 230/2000, grad norm: 0.011. Training block: actor\n",
      "actor: -0.730, critic: 0.376, entropy: -2.244, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.387\n",
      "\n",
      "n_iter: 240/2000, grad norm: 0.012. Training block: actor\n",
      "actor: -0.685, critic: 0.357, entropy: -2.247, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.380\n",
      "\n",
      "n_iter: 250/2000, grad norm: 0.011. Training block: critic\n",
      "actor: -0.572, critic: 0.300, entropy: -2.248, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.355\n",
      "\n",
      "n_iter: 260/2000, grad norm: 0.011. Training block: actor\n",
      "actor: -0.637, critic: 0.335, entropy: -2.248, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.371\n",
      "\n",
      "n_iter: 270/2000, grad norm: 0.011. Training block: critic\n",
      "actor: -0.701, critic: 0.366, entropy: -2.246, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.392\n",
      "\n",
      "n_iter: 280/2000, grad norm: 0.012. Training block: critic\n",
      "actor: -0.683, critic: 0.356, entropy: -2.239, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.393\n",
      "\n",
      "n_iter: 290/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.677, critic: 0.348, entropy: -2.246, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.389\n",
      "\n",
      "n_iter: 300/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.652, critic: 0.340, entropy: -2.241, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.381\n",
      "\n",
      "n_iter: 310/2000, grad norm: 0.011. Training block: critic\n",
      "actor: -0.689, critic: 0.353, entropy: -2.241, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.392\n",
      "\n",
      "n_iter: 320/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.670, critic: 0.345, entropy: -2.246, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.388\n",
      "\n",
      "n_iter: 330/2000, grad norm: 0.012. Training block: critic\n",
      "actor: -0.668, critic: 0.337, entropy: -2.251, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.387\n",
      "\n",
      "n_iter: 340/2000, grad norm: 0.011. Training block: actor\n",
      "actor: -0.582, critic: 0.298, entropy: -2.246, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.367\n",
      "\n",
      "n_iter: 350/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.688, critic: 0.349, entropy: -2.249, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.398\n",
      "\n",
      "n_iter: 360/2000, grad norm: 0.012. Training block: actor\n",
      "actor: -0.549, critic: 0.288, entropy: -2.244, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.365\n",
      "\n",
      "n_iter: 370/2000, grad norm: 0.013. Training block: critic\n",
      "actor: -0.658, critic: 0.331, entropy: -2.244, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.391\n",
      "\n",
      "n_iter: 380/2000, grad norm: 0.011. Training block: actor\n",
      "actor: -0.559, critic: 0.284, entropy: -2.245, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.370\n",
      "\n",
      "n_iter: 390/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.690, critic: 0.352, entropy: -2.239, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.405\n",
      "\n",
      "n_iter: 400/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.647, critic: 0.326, entropy: -2.242, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.394\n",
      "\n",
      "n_iter: 410/2000, grad norm: 0.011. Training block: actor\n",
      "actor: -0.683, critic: 0.344, entropy: -2.243, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.405\n",
      "\n",
      "n_iter: 420/2000, grad norm: 0.013. Training block: critic\n",
      "actor: -0.568, critic: 0.284, entropy: -2.237, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.373\n",
      "\n",
      "n_iter: 430/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.533, critic: 0.277, entropy: -2.246, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.372\n",
      "\n",
      "n_iter: 440/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.655, critic: 0.329, entropy: -2.240, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.400\n",
      "\n",
      "n_iter: 450/2000, grad norm: 0.011. Training block: actor\n",
      "actor: -0.658, critic: 0.323, entropy: -2.244, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.401\n",
      "\n",
      "n_iter: 460/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.606, critic: 0.294, entropy: -2.250, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.389\n",
      "\n",
      "n_iter: 470/2000, grad norm: 0.013. Training block: critic\n",
      "actor: -0.470, critic: 0.253, entropy: -2.245, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.358\n",
      "\n",
      "n_iter: 480/2000, grad norm: 0.011. Training block: critic\n",
      "actor: -0.656, critic: 0.324, entropy: -2.245, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.402\n",
      "\n",
      "n_iter: 490/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.602, critic: 0.306, entropy: -2.248, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.395\n",
      "\n",
      "n_iter: 500/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.608, critic: 0.309, entropy: -2.252, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.406\n",
      "\n",
      "n_iter: 510/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.634, critic: 0.308, entropy: -2.248, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.400\n",
      "\n",
      "n_iter: 520/2000, grad norm: 0.011. Training block: actor\n",
      "actor: -0.575, critic: 0.299, entropy: -2.251, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.395\n",
      "\n",
      "n_iter: 530/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.639, critic: 0.312, entropy: -2.248, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.407\n",
      "\n",
      "n_iter: 540/2000, grad norm: 0.011. Training block: critic\n",
      "actor: -0.644, critic: 0.317, entropy: -2.244, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.411\n",
      "\n",
      "n_iter: 550/2000, grad norm: 0.011. Training block: actor\n",
      "actor: -0.553, critic: 0.290, entropy: -2.245, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.398\n",
      "\n",
      "n_iter: 560/2000, grad norm: 0.011. Training block: critic\n",
      "actor: -0.646, critic: 0.312, entropy: -2.243, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.413\n",
      "\n",
      "n_iter: 570/2000, grad norm: 0.011. Training block: critic\n",
      "actor: -0.521, critic: 0.259, entropy: -2.246, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.381\n",
      "\n",
      "n_iter: 580/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.597, critic: 0.292, entropy: -2.242, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.402\n",
      "\n",
      "n_iter: 590/2000, grad norm: 0.011. Training block: critic\n",
      "actor: -0.597, critic: 0.290, entropy: -2.243, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.401\n",
      "\n",
      "n_iter: 600/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.483, critic: 0.245, entropy: -2.240, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.378\n",
      "\n",
      "n_iter: 610/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.608, critic: 0.291, entropy: -2.246, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.407\n",
      "\n",
      "n_iter: 620/2000, grad norm: 0.012. Training block: critic\n",
      "actor: -0.611, critic: 0.295, entropy: -2.244, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.415\n",
      "\n",
      "n_iter: 630/2000, grad norm: 0.011. Training block: actor\n",
      "actor: -0.586, critic: 0.284, entropy: -2.234, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.403\n",
      "\n",
      "n_iter: 640/2000, grad norm: 0.011. Training block: critic\n",
      "actor: -0.497, critic: 0.244, entropy: -2.242, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.378\n",
      "\n",
      "n_iter: 650/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.492, critic: 0.257, entropy: -2.247, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.399\n",
      "\n",
      "n_iter: 660/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.596, critic: 0.290, entropy: -2.238, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.415\n",
      "\n",
      "n_iter: 670/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.508, critic: 0.260, entropy: -2.239, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.400\n",
      "\n",
      "n_iter: 680/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.471, critic: 0.240, entropy: -2.236, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.386\n",
      "\n",
      "n_iter: 690/2000, grad norm: 0.011. Training block: actor\n",
      "actor: -0.543, critic: 0.272, entropy: -2.224, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.411\n",
      "\n",
      "n_iter: 700/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.606, critic: 0.290, entropy: -2.228, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.423\n",
      "\n",
      "n_iter: 710/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.547, critic: 0.273, entropy: -2.222, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.412\n",
      "\n",
      "n_iter: 720/2000, grad norm: 0.011. Training block: critic\n",
      "actor: -0.573, critic: 0.273, entropy: -2.230, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.416\n",
      "\n",
      "n_iter: 730/2000, grad norm: 0.011. Training block: critic\n",
      "actor: -0.605, critic: 0.295, entropy: -2.227, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.429\n",
      "\n",
      "n_iter: 740/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.609, critic: 0.292, entropy: -2.224, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.430\n",
      "\n",
      "n_iter: 750/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.541, critic: 0.266, entropy: -2.228, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.413\n",
      "\n",
      "n_iter: 760/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.505, critic: 0.251, entropy: -2.228, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.406\n",
      "\n",
      "n_iter: 770/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.542, critic: 0.269, entropy: -2.225, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.418\n",
      "\n",
      "n_iter: 780/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.597, critic: 0.293, entropy: -2.222, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.434\n",
      "\n",
      "n_iter: 790/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.548, critic: 0.264, entropy: -2.233, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.418\n",
      "\n",
      "n_iter: 800/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.585, critic: 0.278, entropy: -2.226, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.427\n",
      "\n",
      "n_iter: 810/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.551, critic: 0.269, entropy: -2.229, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.422\n",
      "\n",
      "n_iter: 820/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.404, critic: 0.209, entropy: -2.217, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.374\n",
      "\n",
      "n_iter: 830/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.538, critic: 0.265, entropy: -2.219, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.422\n",
      "\n",
      "n_iter: 840/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.441, critic: 0.236, entropy: -2.226, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.394\n",
      "\n",
      "n_iter: 850/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.588, critic: 0.278, entropy: -2.222, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.434\n",
      "\n",
      "n_iter: 860/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.515, critic: 0.251, entropy: -2.225, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.414\n",
      "\n",
      "n_iter: 870/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.413, critic: 0.227, entropy: -2.220, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.398\n",
      "\n",
      "n_iter: 880/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.533, critic: 0.252, entropy: -2.226, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.419\n",
      "\n",
      "n_iter: 890/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.586, critic: 0.279, entropy: -2.224, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.442\n",
      "\n",
      "n_iter: 900/2000, grad norm: 0.011. Training block: actor\n",
      "actor: -0.514, critic: 0.253, entropy: -2.220, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.420\n",
      "\n",
      "n_iter: 910/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.572, critic: 0.273, entropy: -2.219, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.438\n",
      "\n",
      "n_iter: 920/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.563, critic: 0.266, entropy: -2.217, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.436\n",
      "\n",
      "n_iter: 930/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.517, critic: 0.244, entropy: -2.221, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.421\n",
      "\n",
      "n_iter: 940/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.559, critic: 0.268, entropy: -2.225, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.438\n",
      "\n",
      "n_iter: 950/2000, grad norm: 0.011. Training block: critic\n",
      "actor: -0.457, critic: 0.239, entropy: -2.220, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.416\n",
      "\n",
      "n_iter: 960/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.350, critic: 0.198, entropy: -2.228, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.379\n",
      "\n",
      "n_iter: 970/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.534, critic: 0.252, entropy: -2.218, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.432\n",
      "\n",
      "n_iter: 980/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.549, critic: 0.258, entropy: -2.214, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.438\n",
      "\n",
      "n_iter: 990/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.368, critic: 0.201, entropy: -2.216, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.387\n",
      "\n",
      "n_iter: 1000/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.543, critic: 0.255, entropy: -2.221, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.441\n",
      "\n",
      "n_iter: 1010/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.490, critic: 0.246, entropy: -2.218, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.432\n",
      "\n",
      "n_iter: 1020/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.515, critic: 0.250, entropy: -2.220, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.434\n",
      "\n",
      "n_iter: 1030/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.519, critic: 0.250, entropy: -2.227, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.437\n",
      "\n",
      "n_iter: 1040/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.521, critic: 0.251, entropy: -2.209, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.440\n",
      "\n",
      "n_iter: 1050/2000, grad norm: 0.008. Training block: actor\n",
      "actor: -0.545, critic: 0.258, entropy: -2.215, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.448\n",
      "\n",
      "n_iter: 1060/2000, grad norm: 0.011. Training block: critic\n",
      "actor: -0.511, critic: 0.244, entropy: -2.208, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.440\n",
      "\n",
      "n_iter: 1070/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.475, critic: 0.231, entropy: -2.206, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.428\n",
      "\n",
      "n_iter: 1080/2000, grad norm: 0.012. Training block: critic\n",
      "actor: -0.529, critic: 0.249, entropy: -2.214, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.447\n",
      "\n",
      "n_iter: 1090/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.387, critic: 0.210, entropy: -2.215, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.405\n",
      "\n",
      "n_iter: 1100/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.517, critic: 0.242, entropy: -2.207, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.441\n",
      "\n",
      "n_iter: 1110/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.374, critic: 0.212, entropy: -2.219, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.416\n",
      "\n",
      "n_iter: 1120/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.495, critic: 0.234, entropy: -2.205, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.441\n",
      "\n",
      "n_iter: 1130/2000, grad norm: 0.008. Training block: actor\n",
      "actor: -0.526, critic: 0.251, entropy: -2.192, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.453\n",
      "\n",
      "n_iter: 1140/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.516, critic: 0.239, entropy: -2.204, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.449\n",
      "\n",
      "n_iter: 1150/2000, grad norm: 0.011. Training block: critic\n",
      "actor: -0.490, critic: 0.235, entropy: -2.199, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.442\n",
      "\n",
      "n_iter: 1160/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.477, critic: 0.229, entropy: -2.212, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.442\n",
      "\n",
      "n_iter: 1170/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.509, critic: 0.239, entropy: -2.200, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.450\n",
      "\n",
      "n_iter: 1180/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.478, critic: 0.228, entropy: -2.195, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.437\n",
      "\n",
      "n_iter: 1190/2000, grad norm: 0.011. Training block: critic\n",
      "actor: -0.484, critic: 0.230, entropy: -2.200, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.442\n",
      "\n",
      "n_iter: 1200/2000, grad norm: 0.008. Training block: actor\n",
      "actor: -0.492, critic: 0.228, entropy: -2.205, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.447\n",
      "\n",
      "n_iter: 1210/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.474, critic: 0.237, entropy: -2.195, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.451\n",
      "\n",
      "n_iter: 1220/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.504, critic: 0.234, entropy: -2.193, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.457\n",
      "\n",
      "n_iter: 1230/2000, grad norm: 0.008. Training block: actor\n",
      "actor: -0.493, critic: 0.230, entropy: -2.196, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.453\n",
      "\n",
      "n_iter: 1240/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.476, critic: 0.231, entropy: -2.199, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.450\n",
      "\n",
      "n_iter: 1250/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.472, critic: 0.227, entropy: -2.186, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.452\n",
      "\n",
      "n_iter: 1260/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.421, critic: 0.214, entropy: -2.195, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.437\n",
      "\n",
      "n_iter: 1270/2000, grad norm: 0.008. Training block: actor\n",
      "actor: -0.479, critic: 0.230, entropy: -2.187, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.455\n",
      "\n",
      "n_iter: 1280/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.375, critic: 0.210, entropy: -2.185, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.427\n",
      "\n",
      "n_iter: 1290/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.442, critic: 0.215, entropy: -2.193, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.443\n",
      "\n",
      "n_iter: 1300/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.465, critic: 0.230, entropy: -2.193, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.457\n",
      "\n",
      "n_iter: 1310/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.486, critic: 0.234, entropy: -2.190, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.464\n",
      "\n",
      "n_iter: 1320/2000, grad norm: 0.011. Training block: critic\n",
      "actor: -0.478, critic: 0.227, entropy: -2.189, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.458\n",
      "\n",
      "n_iter: 1330/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.480, critic: 0.227, entropy: -2.189, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.461\n",
      "\n",
      "n_iter: 1340/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.448, critic: 0.219, entropy: -2.198, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.451\n",
      "\n",
      "n_iter: 1350/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.472, critic: 0.227, entropy: -2.187, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.460\n",
      "\n",
      "n_iter: 1360/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.380, critic: 0.207, entropy: -2.199, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.435\n",
      "\n",
      "n_iter: 1370/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.412, critic: 0.214, entropy: -2.189, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.452\n",
      "\n",
      "n_iter: 1380/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.408, critic: 0.206, entropy: -2.193, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.441\n",
      "\n",
      "n_iter: 1390/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.434, critic: 0.207, entropy: -2.200, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.449\n",
      "\n",
      "n_iter: 1400/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.387, critic: 0.206, entropy: -2.194, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.438\n",
      "\n",
      "n_iter: 1410/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.451, critic: 0.216, entropy: -2.192, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.460\n",
      "\n",
      "n_iter: 1420/2000, grad norm: 0.008. Training block: actor\n",
      "actor: -0.350, critic: 0.199, entropy: -2.191, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.429\n",
      "\n",
      "n_iter: 1430/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.430, critic: 0.208, entropy: -2.192, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.456\n",
      "\n",
      "n_iter: 1440/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.455, critic: 0.214, entropy: -2.190, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.469\n",
      "\n",
      "n_iter: 1450/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.431, critic: 0.211, entropy: -2.195, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.458\n",
      "\n",
      "n_iter: 1460/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.456, critic: 0.221, entropy: -2.188, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.472\n",
      "\n",
      "n_iter: 1470/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.398, critic: 0.210, entropy: -2.189, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.450\n",
      "\n",
      "n_iter: 1480/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.353, critic: 0.200, entropy: -2.184, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.437\n",
      "\n",
      "n_iter: 1490/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.402, critic: 0.201, entropy: -2.192, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.453\n",
      "\n",
      "n_iter: 1500/2000, grad norm: 0.010. Training block: actor\n",
      "actor: -0.266, critic: 0.188, entropy: -2.185, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.417\n",
      "\n",
      "n_iter: 1510/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.273, critic: 0.196, entropy: -2.190, ae: 0.108, lstm: 0.000\n",
      "Average reward: 0.424\n",
      "\n",
      "n_iter: 1520/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.423, critic: 0.200, entropy: -2.192, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.462\n",
      "\n",
      "n_iter: 1530/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.399, critic: 0.207, entropy: -2.183, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.463\n",
      "\n",
      "n_iter: 1540/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.388, critic: 0.202, entropy: -2.183, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.459\n",
      "\n",
      "n_iter: 1550/2000, grad norm: 0.008. Training block: actor\n",
      "actor: -0.423, critic: 0.205, entropy: -2.184, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.467\n",
      "\n",
      "n_iter: 1560/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.346, critic: 0.192, entropy: -2.191, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.440\n",
      "\n",
      "n_iter: 1570/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.404, critic: 0.203, entropy: -2.186, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.460\n",
      "\n",
      "n_iter: 1580/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.382, critic: 0.201, entropy: -2.186, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.461\n",
      "\n",
      "n_iter: 1590/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.396, critic: 0.197, entropy: -2.186, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.461\n",
      "\n",
      "n_iter: 1600/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.233, critic: 0.186, entropy: -2.198, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.420\n",
      "\n",
      "n_iter: 1610/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.244, critic: 0.177, entropy: -2.191, ae: 0.107, lstm: 0.000\n",
      "Average reward: 0.415\n",
      "\n",
      "n_iter: 1620/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.304, critic: 0.186, entropy: -2.186, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.443\n",
      "\n",
      "n_iter: 1630/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.408, critic: 0.202, entropy: -2.190, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.475\n",
      "\n",
      "n_iter: 1640/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.388, critic: 0.192, entropy: -2.185, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.466\n",
      "\n",
      "n_iter: 1650/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.363, critic: 0.199, entropy: -2.187, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.463\n",
      "\n",
      "n_iter: 1660/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.330, critic: 0.193, entropy: -2.189, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.455\n",
      "\n",
      "n_iter: 1670/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.401, critic: 0.204, entropy: -2.187, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.477\n",
      "\n",
      "n_iter: 1680/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.360, critic: 0.184, entropy: -2.191, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.457\n",
      "\n",
      "n_iter: 1690/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.373, critic: 0.187, entropy: -2.189, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.462\n",
      "\n",
      "n_iter: 1700/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.375, critic: 0.189, entropy: -2.189, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.466\n",
      "\n",
      "n_iter: 1710/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.282, critic: 0.187, entropy: -2.190, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.447\n",
      "\n",
      "n_iter: 1720/2000, grad norm: 0.008. Training block: actor\n",
      "actor: -0.383, critic: 0.191, entropy: -2.186, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.472\n",
      "\n",
      "n_iter: 1730/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.388, critic: 0.192, entropy: -2.182, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.475\n",
      "\n",
      "n_iter: 1740/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.369, critic: 0.188, entropy: -2.185, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.470\n",
      "\n",
      "n_iter: 1750/2000, grad norm: 0.008. Training block: actor\n",
      "actor: -0.387, critic: 0.194, entropy: -2.181, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.482\n",
      "\n",
      "n_iter: 1760/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.190, critic: 0.181, entropy: -2.185, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.418\n",
      "\n",
      "n_iter: 1770/2000, grad norm: 0.008. Training block: actor\n",
      "actor: -0.367, critic: 0.189, entropy: -2.181, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.473\n",
      "\n",
      "n_iter: 1780/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.319, critic: 0.185, entropy: -2.180, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.463\n",
      "\n",
      "n_iter: 1790/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.256, critic: 0.196, entropy: -2.190, ae: 0.109, lstm: 0.000\n",
      "Average reward: 0.448\n",
      "\n",
      "n_iter: 1800/2000, grad norm: 0.008. Training block: actor\n",
      "actor: -0.335, critic: 0.189, entropy: -2.182, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.470\n",
      "\n",
      "n_iter: 1810/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.321, critic: 0.182, entropy: -2.177, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.464\n",
      "\n",
      "n_iter: 1820/2000, grad norm: 0.008. Training block: actor\n",
      "actor: -0.255, critic: 0.189, entropy: -2.177, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.448\n",
      "\n",
      "n_iter: 1830/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.246, critic: 0.184, entropy: -2.177, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.443\n",
      "\n",
      "n_iter: 1840/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.324, critic: 0.184, entropy: -2.176, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.466\n",
      "\n",
      "n_iter: 1850/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.339, critic: 0.186, entropy: -2.181, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.476\n",
      "\n",
      "n_iter: 1860/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.347, critic: 0.188, entropy: -2.179, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.479\n",
      "\n",
      "n_iter: 1870/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.201, critic: 0.195, entropy: -2.174, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.444\n",
      "\n",
      "n_iter: 1880/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.322, critic: 0.182, entropy: -2.193, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.471\n",
      "\n",
      "n_iter: 1890/2000, grad norm: 0.008. Training block: actor\n",
      "actor: -0.274, critic: 0.182, entropy: -2.181, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.457\n",
      "\n",
      "n_iter: 1900/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.288, critic: 0.177, entropy: -2.178, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.461\n",
      "\n",
      "n_iter: 1910/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.334, critic: 0.186, entropy: -2.182, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.482\n",
      "\n",
      "n_iter: 1920/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.251, critic: 0.177, entropy: -2.187, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.452\n",
      "\n",
      "n_iter: 1930/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.289, critic: 0.186, entropy: -2.181, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.470\n",
      "\n",
      "n_iter: 1940/2000, grad norm: 0.009. Training block: critic\n",
      "actor: -0.344, critic: 0.187, entropy: -2.175, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.493\n",
      "\n",
      "n_iter: 1950/2000, grad norm: 0.008. Training block: actor\n",
      "actor: -0.196, critic: 0.174, entropy: -2.183, ae: 0.109, lstm: 0.000\n",
      "Average reward: 0.429\n",
      "\n",
      "n_iter: 1960/2000, grad norm: 0.008. Training block: actor\n",
      "actor: -0.290, critic: 0.178, entropy: -2.187, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.468\n",
      "\n",
      "n_iter: 1970/2000, grad norm: 0.010. Training block: critic\n",
      "actor: -0.274, critic: 0.170, entropy: -2.181, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.463\n",
      "\n",
      "n_iter: 1980/2000, grad norm: 0.009. Training block: actor\n",
      "actor: -0.286, critic: 0.177, entropy: -2.183, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.470\n",
      "\n",
      "n_iter: 1990/2000, grad norm: 0.008. Training block: actor\n",
      "actor: -0.284, critic: 0.178, entropy: -2.177, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.474\n",
      "\n",
      "n_iter: 0/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.232, critic: 0.177, entropy: -2.175, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.453\n",
      "\n",
      "n_iter: 10/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.259, critic: 0.173, entropy: -2.179, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.465\n",
      "\n",
      "n_iter: 20/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.157, critic: 0.184, entropy: -2.165, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.445\n",
      "\n",
      "n_iter: 30/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.191, critic: 0.173, entropy: -2.169, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.444\n",
      "\n",
      "n_iter: 40/6000, grad norm: 0.002. Training block: full\n",
      "actor: -0.253, critic: 0.179, entropy: -2.160, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.468\n",
      "\n",
      "n_iter: 50/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.155, critic: 0.171, entropy: -2.160, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.438\n",
      "\n",
      "n_iter: 60/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.268, critic: 0.163, entropy: -2.158, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.472\n",
      "\n",
      "n_iter: 70/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.215, critic: 0.175, entropy: -2.158, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.458\n",
      "\n",
      "n_iter: 80/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.265, critic: 0.168, entropy: -2.164, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.479\n",
      "\n",
      "n_iter: 90/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.229, critic: 0.159, entropy: -2.163, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.466\n",
      "\n",
      "n_iter: 100/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.268, critic: 0.160, entropy: -2.160, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.484\n",
      "\n",
      "n_iter: 110/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.178, critic: 0.168, entropy: -2.170, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.455\n",
      "\n",
      "n_iter: 120/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.279, critic: 0.164, entropy: -2.163, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.492\n",
      "\n",
      "n_iter: 130/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.220, critic: 0.165, entropy: -2.167, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.477\n",
      "\n",
      "n_iter: 140/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.254, critic: 0.168, entropy: -2.156, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.491\n",
      "\n",
      "n_iter: 150/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.287, critic: 0.170, entropy: -2.145, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 160/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.168, critic: 0.170, entropy: -2.149, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.469\n",
      "\n",
      "n_iter: 170/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.136, critic: 0.183, entropy: -2.163, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.458\n",
      "\n",
      "n_iter: 180/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.183, critic: 0.183, entropy: -2.135, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.481\n",
      "\n",
      "n_iter: 190/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.150, critic: 0.170, entropy: -2.152, ae: 0.105, lstm: 0.000\n",
      "Average reward: 0.463\n",
      "\n",
      "n_iter: 200/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.228, critic: 0.161, entropy: -2.147, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.494\n",
      "\n",
      "n_iter: 210/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.247, critic: 0.161, entropy: -2.151, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.500\n",
      "\n",
      "n_iter: 220/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.143, critic: 0.172, entropy: -2.147, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.466\n",
      "\n",
      "n_iter: 230/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.227, critic: 0.162, entropy: -2.146, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.492\n",
      "\n",
      "n_iter: 240/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.253, critic: 0.154, entropy: -2.132, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.506\n",
      "\n",
      "n_iter: 250/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.203, critic: 0.165, entropy: -2.135, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.489\n",
      "\n",
      "n_iter: 260/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.216, critic: 0.162, entropy: -2.136, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.500\n",
      "\n",
      "n_iter: 270/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.253, critic: 0.154, entropy: -2.128, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.511\n",
      "\n",
      "n_iter: 280/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.097, critic: 0.191, entropy: -2.123, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.472\n",
      "\n",
      "n_iter: 290/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.199, critic: 0.154, entropy: -2.127, ae: 0.106, lstm: 0.000\n",
      "Average reward: 0.489\n",
      "\n",
      "n_iter: 300/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.221, critic: 0.153, entropy: -2.120, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 310/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.199, critic: 0.144, entropy: -2.129, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.494\n",
      "\n",
      "n_iter: 320/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.188, critic: 0.152, entropy: -2.125, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.494\n",
      "\n",
      "n_iter: 330/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.219, critic: 0.145, entropy: -2.099, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.508\n",
      "\n",
      "n_iter: 340/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.194, critic: 0.147, entropy: -2.124, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.498\n",
      "\n",
      "n_iter: 350/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.231, critic: 0.145, entropy: -2.121, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.516\n",
      "\n",
      "n_iter: 360/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.200, critic: 0.148, entropy: -2.128, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.508\n",
      "\n",
      "n_iter: 370/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.097, critic: 0.165, entropy: -2.126, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.475\n",
      "\n",
      "n_iter: 380/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.179, critic: 0.148, entropy: -2.119, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.503\n",
      "\n",
      "n_iter: 390/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.126, critic: 0.146, entropy: -2.124, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.481\n",
      "\n",
      "n_iter: 400/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.123, critic: 0.140, entropy: -2.140, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.479\n",
      "\n",
      "n_iter: 410/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.155, critic: 0.141, entropy: -2.126, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.503\n",
      "\n",
      "n_iter: 420/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.033, critic: 0.176, entropy: -2.115, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.449\n",
      "\n",
      "n_iter: 430/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.099, critic: 0.144, entropy: -2.121, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.480\n",
      "\n",
      "n_iter: 440/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.172, critic: 0.150, entropy: -2.107, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.511\n",
      "\n",
      "n_iter: 450/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.168, critic: 0.129, entropy: -2.107, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.505\n",
      "\n",
      "n_iter: 460/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.124, critic: 0.149, entropy: -2.118, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.498\n",
      "\n",
      "n_iter: 470/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.187, critic: 0.133, entropy: -2.100, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.519\n",
      "\n",
      "n_iter: 480/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.034, critic: 0.183, entropy: -2.097, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.480\n",
      "\n",
      "n_iter: 490/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.117, critic: 0.147, entropy: -2.100, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.497\n",
      "\n",
      "n_iter: 500/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.184, critic: 0.126, entropy: -2.099, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.524\n",
      "\n",
      "n_iter: 510/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.173, critic: 0.125, entropy: -2.091, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.526\n",
      "\n",
      "n_iter: 520/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.121, critic: 0.146, entropy: -2.092, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.507\n",
      "\n",
      "n_iter: 530/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.099, critic: 0.154, entropy: -2.099, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.508\n",
      "\n",
      "n_iter: 540/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.035, critic: 0.185, entropy: -2.096, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.485\n",
      "\n",
      "n_iter: 550/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.164, critic: 0.130, entropy: -2.090, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.522\n",
      "\n",
      "n_iter: 560/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.177, critic: 0.120, entropy: -2.086, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.527\n",
      "\n",
      "n_iter: 570/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.144, critic: 0.131, entropy: -2.096, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.518\n",
      "\n",
      "n_iter: 580/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.136, critic: 0.129, entropy: -2.087, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 590/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.087, critic: 0.144, entropy: -2.093, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.502\n",
      "\n",
      "n_iter: 600/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.076, critic: 0.156, entropy: -2.071, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.501\n",
      "\n",
      "n_iter: 610/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.157, critic: 0.131, entropy: -2.078, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.527\n",
      "\n",
      "n_iter: 620/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.148, critic: 0.117, entropy: -2.091, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.518\n",
      "\n",
      "n_iter: 630/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.067, critic: 0.150, entropy: -2.096, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.493\n",
      "\n",
      "n_iter: 640/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.104, critic: 0.141, entropy: -2.077, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 650/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.095, critic: 0.137, entropy: -2.089, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.509\n",
      "\n",
      "n_iter: 660/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.148, critic: 0.120, entropy: -2.089, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.525\n",
      "\n",
      "n_iter: 670/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.148, critic: 0.119, entropy: -2.081, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.527\n",
      "\n",
      "n_iter: 680/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.145, critic: 0.114, entropy: -2.094, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.523\n",
      "\n",
      "n_iter: 690/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.088, critic: 0.149, entropy: -2.088, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.513\n",
      "\n",
      "n_iter: 700/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.088, critic: 0.132, entropy: -2.087, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.511\n",
      "\n",
      "n_iter: 710/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.128, critic: 0.110, entropy: -2.095, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.522\n",
      "\n",
      "n_iter: 720/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.104, critic: 0.126, entropy: -2.090, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.515\n",
      "\n",
      "n_iter: 730/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.102, critic: 0.130, entropy: -2.076, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.518\n",
      "\n",
      "n_iter: 740/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.077, critic: 0.141, entropy: -2.083, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 750/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.132, critic: 0.113, entropy: -2.088, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.525\n",
      "\n",
      "n_iter: 760/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.066, critic: 0.127, entropy: -2.081, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.508\n",
      "\n",
      "n_iter: 770/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.011, critic: 0.161, entropy: -2.082, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.495\n",
      "\n",
      "n_iter: 780/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.140, critic: 0.108, entropy: -2.077, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.536\n",
      "\n",
      "n_iter: 790/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.123, critic: 0.110, entropy: -2.083, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.530\n",
      "\n",
      "n_iter: 800/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.145, critic: 0.112, entropy: -2.064, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.543\n",
      "\n",
      "n_iter: 810/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.006, critic: 0.161, entropy: -2.081, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.488\n",
      "\n",
      "n_iter: 820/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.106, critic: 0.115, entropy: -2.078, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.527\n",
      "\n",
      "n_iter: 830/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.017, critic: 0.160, entropy: -2.091, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.502\n",
      "\n",
      "n_iter: 840/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.111, critic: 0.116, entropy: -2.080, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.533\n",
      "\n",
      "n_iter: 850/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.102, critic: 0.116, entropy: -2.073, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.526\n",
      "\n",
      "n_iter: 860/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.094, critic: 0.120, entropy: -2.065, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.522\n",
      "\n",
      "n_iter: 870/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.104, critic: 0.102, entropy: -2.071, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.530\n",
      "\n",
      "n_iter: 880/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.098, critic: 0.117, entropy: -2.074, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.530\n",
      "\n",
      "n_iter: 890/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.095, critic: 0.111, entropy: -2.077, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.528\n",
      "\n",
      "n_iter: 900/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.049, critic: 0.135, entropy: -2.074, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.515\n",
      "\n",
      "n_iter: 910/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.081, critic: 0.124, entropy: -2.066, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.524\n",
      "\n",
      "n_iter: 920/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.116, critic: 0.097, entropy: -2.079, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.533\n",
      "\n",
      "n_iter: 930/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.100, critic: 0.108, entropy: -2.072, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.530\n",
      "\n",
      "n_iter: 940/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.090, critic: 0.105, entropy: -2.069, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.530\n",
      "\n",
      "n_iter: 950/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.047, critic: 0.126, entropy: -2.075, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.518\n",
      "\n",
      "n_iter: 960/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.033, critic: 0.140, entropy: -2.072, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.517\n",
      "\n",
      "n_iter: 970/6000, grad norm: 0.001. Training block: full\n",
      "actor: 0.061, critic: 0.180, entropy: -2.061, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.481\n",
      "\n",
      "n_iter: 980/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.115, critic: 0.101, entropy: -2.072, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.540\n",
      "\n",
      "n_iter: 990/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.059, critic: 0.123, entropy: -2.073, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.529\n",
      "\n",
      "n_iter: 1000/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.092, critic: 0.109, entropy: -2.058, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.536\n",
      "\n",
      "n_iter: 1010/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.070, critic: 0.119, entropy: -2.069, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.519\n",
      "\n",
      "n_iter: 1020/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.136, critic: 0.102, entropy: -2.063, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.555\n",
      "\n",
      "n_iter: 1030/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.064, critic: 0.105, entropy: -2.067, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.525\n",
      "\n",
      "n_iter: 1040/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.060, critic: 0.117, entropy: -2.061, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.519\n",
      "\n",
      "n_iter: 1050/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.009, critic: 0.154, entropy: -2.069, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.502\n",
      "\n",
      "n_iter: 1060/6000, grad norm: 0.001. Training block: full\n",
      "actor: -0.000, critic: 0.154, entropy: -2.081, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.494\n",
      "\n",
      "n_iter: 1070/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.086, critic: 0.110, entropy: -2.066, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.526\n",
      "\n",
      "n_iter: 1080/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.111, critic: 0.094, entropy: -2.058, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.543\n",
      "\n",
      "n_iter: 1090/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.112, critic: 0.108, entropy: -2.059, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.544\n",
      "\n",
      "n_iter: 1100/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.098, critic: 0.108, entropy: -2.060, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.536\n",
      "\n",
      "n_iter: 1110/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.058, critic: 0.120, entropy: -2.070, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.521\n",
      "\n",
      "n_iter: 1120/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.106, critic: 0.096, entropy: -2.062, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.540\n",
      "\n",
      "n_iter: 1130/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.073, critic: 0.103, entropy: -2.068, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.535\n",
      "\n",
      "n_iter: 1140/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.069, critic: 0.093, entropy: -2.068, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.535\n",
      "\n",
      "n_iter: 1150/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.091, critic: 0.095, entropy: -2.065, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.542\n",
      "\n",
      "n_iter: 1160/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.045, critic: 0.113, entropy: -2.068, ae: 0.104, lstm: 0.000\n",
      "Average reward: 0.521\n",
      "\n",
      "n_iter: 1170/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.037, critic: 0.124, entropy: -2.055, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.526\n",
      "\n",
      "n_iter: 1180/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.028, critic: 0.111, entropy: -2.061, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.519\n",
      "\n",
      "n_iter: 1190/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.119, critic: 0.093, entropy: -2.063, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.554\n",
      "\n",
      "n_iter: 1200/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.071, critic: 0.118, entropy: -2.050, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.537\n",
      "\n",
      "n_iter: 1210/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.072, critic: 0.110, entropy: -2.064, ae: 0.102, lstm: 0.000\n",
      "Average reward: 0.536\n",
      "\n",
      "n_iter: 1220/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.072, critic: 0.106, entropy: -2.062, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.542\n",
      "\n",
      "n_iter: 1230/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.094, critic: 0.093, entropy: -2.055, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.554\n",
      "\n",
      "n_iter: 1240/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.025, critic: 0.154, entropy: -2.061, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.505\n",
      "\n",
      "n_iter: 1250/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.046, critic: 0.104, entropy: -2.062, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.531\n",
      "\n",
      "n_iter: 1260/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.069, critic: 0.096, entropy: -2.051, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.546\n",
      "\n",
      "n_iter: 1270/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.078, critic: 0.096, entropy: -2.060, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.548\n",
      "\n",
      "n_iter: 1280/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.083, critic: 0.098, entropy: -2.052, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.545\n",
      "\n",
      "n_iter: 1290/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.048, critic: 0.103, entropy: -2.041, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.539\n",
      "\n",
      "n_iter: 1300/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.033, critic: 0.116, entropy: -2.051, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.535\n",
      "\n",
      "n_iter: 1310/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.066, critic: 0.104, entropy: -2.043, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.545\n",
      "\n",
      "n_iter: 1320/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.043, critic: 0.110, entropy: -2.053, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.533\n",
      "\n",
      "n_iter: 1330/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.023, critic: 0.107, entropy: -2.058, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.530\n",
      "\n",
      "n_iter: 1340/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.081, critic: 0.089, entropy: -2.056, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.549\n",
      "\n",
      "n_iter: 1350/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.014, critic: 0.138, entropy: -2.058, ae: 0.101, lstm: 0.000\n",
      "Average reward: 0.516\n",
      "\n",
      "n_iter: 1360/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.023, critic: 0.117, entropy: -2.055, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.525\n",
      "\n",
      "n_iter: 1370/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.020, critic: 0.110, entropy: -2.054, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.532\n",
      "\n",
      "n_iter: 1380/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.033, critic: 0.104, entropy: -2.059, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.534\n",
      "\n",
      "n_iter: 1390/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.058, critic: 0.093, entropy: -2.048, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.543\n",
      "\n",
      "n_iter: 1400/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.040, critic: 0.160, entropy: -2.048, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 1410/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.059, critic: 0.088, entropy: -2.057, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.542\n",
      "\n",
      "n_iter: 1420/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.049, critic: 0.110, entropy: -2.046, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.545\n",
      "\n",
      "n_iter: 1430/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.014, critic: 0.126, entropy: -2.059, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.522\n",
      "\n",
      "n_iter: 1440/6000, grad norm: 0.001. Training block: full\n",
      "actor: 0.061, critic: 0.176, entropy: -2.053, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.509\n",
      "\n",
      "n_iter: 1450/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.068, critic: 0.087, entropy: -2.055, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.550\n",
      "\n",
      "n_iter: 1460/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.048, critic: 0.165, entropy: -2.051, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.521\n",
      "\n",
      "n_iter: 1470/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.053, critic: 0.095, entropy: -2.048, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.546\n",
      "\n",
      "n_iter: 1480/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.059, critic: 0.153, entropy: -2.034, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.511\n",
      "\n",
      "n_iter: 1490/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.065, critic: 0.093, entropy: -2.049, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.553\n",
      "\n",
      "n_iter: 1500/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.057, critic: 0.087, entropy: -2.051, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.554\n",
      "\n",
      "n_iter: 1510/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.065, critic: 0.092, entropy: -2.039, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.554\n",
      "\n",
      "n_iter: 1520/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.027, critic: 0.096, entropy: -2.039, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.547\n",
      "\n",
      "n_iter: 1530/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.009, critic: 0.110, entropy: -2.032, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.533\n",
      "\n",
      "n_iter: 1540/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.000, critic: 0.123, entropy: -2.048, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.532\n",
      "\n",
      "n_iter: 1550/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.016, critic: 0.098, entropy: -2.045, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.535\n",
      "\n",
      "n_iter: 1560/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.025, critic: 0.095, entropy: -2.027, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.544\n",
      "\n",
      "n_iter: 1570/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.030, critic: 0.135, entropy: -2.042, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.524\n",
      "\n",
      "n_iter: 1580/6000, grad norm: 0.001. Training block: full\n",
      "actor: 0.086, critic: 0.172, entropy: -2.039, ae: 0.103, lstm: 0.000\n",
      "Average reward: 0.500\n",
      "\n",
      "n_iter: 1590/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.069, critic: 0.090, entropy: -2.037, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.562\n",
      "\n",
      "n_iter: 1600/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.054, critic: 0.091, entropy: -2.030, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 1610/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.013, critic: 0.111, entropy: -2.021, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.544\n",
      "\n",
      "n_iter: 1620/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.016, critic: 0.111, entropy: -2.034, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.545\n",
      "\n",
      "n_iter: 1630/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.034, critic: 0.109, entropy: -2.027, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.549\n",
      "\n",
      "n_iter: 1640/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.058, critic: 0.099, entropy: -2.022, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.558\n",
      "\n",
      "n_iter: 1650/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.094, critic: 0.177, entropy: -2.028, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 1660/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.051, critic: 0.087, entropy: -2.032, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 1670/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.038, critic: 0.091, entropy: -2.033, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 1680/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.039, critic: 0.153, entropy: -2.026, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.532\n",
      "\n",
      "n_iter: 1690/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.014, critic: 0.116, entropy: -2.030, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.536\n",
      "\n",
      "n_iter: 1700/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.027, critic: 0.097, entropy: -2.025, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.555\n",
      "\n",
      "n_iter: 1710/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.058, critic: 0.141, entropy: -2.034, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.518\n",
      "\n",
      "n_iter: 1720/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.020, critic: 0.122, entropy: -2.040, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.531\n",
      "\n",
      "n_iter: 1730/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.052, critic: 0.089, entropy: -2.040, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.555\n",
      "\n",
      "n_iter: 1740/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.034, critic: 0.101, entropy: -2.037, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.552\n",
      "\n",
      "n_iter: 1750/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.075, critic: 0.160, entropy: -2.024, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 1760/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.045, critic: 0.093, entropy: -2.036, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 1770/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.041, critic: 0.098, entropy: -2.035, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 1780/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.018, critic: 0.122, entropy: -2.037, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.537\n",
      "\n",
      "n_iter: 1790/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.042, critic: 0.098, entropy: -2.034, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 1800/6000, grad norm: 0.001. Training block: full\n",
      "actor: 0.136, critic: 0.180, entropy: -2.036, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.492\n",
      "\n",
      "n_iter: 1810/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.076, critic: 0.164, entropy: -2.037, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.510\n",
      "\n",
      "n_iter: 1820/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.028, critic: 0.144, entropy: -2.033, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.527\n",
      "\n",
      "n_iter: 1830/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.074, critic: 0.088, entropy: -2.028, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 1840/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.056, critic: 0.086, entropy: -2.034, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.557\n",
      "\n",
      "n_iter: 1850/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.006, critic: 0.110, entropy: -2.021, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.537\n",
      "\n",
      "n_iter: 1860/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.094, critic: 0.184, entropy: -2.021, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.502\n",
      "\n",
      "n_iter: 1870/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.021, critic: 0.154, entropy: -2.033, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.537\n",
      "\n",
      "n_iter: 1880/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.053, critic: 0.095, entropy: -2.022, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.558\n",
      "\n",
      "n_iter: 1890/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.049, critic: 0.094, entropy: -2.021, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.560\n",
      "\n",
      "n_iter: 1900/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.029, critic: 0.100, entropy: -2.024, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.551\n",
      "\n",
      "n_iter: 1910/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.060, critic: 0.091, entropy: -2.021, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.560\n",
      "\n",
      "n_iter: 1920/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.030, critic: 0.098, entropy: -2.016, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.552\n",
      "\n",
      "n_iter: 1930/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.040, critic: 0.099, entropy: -2.030, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.558\n",
      "\n",
      "n_iter: 1940/6000, grad norm: 0.001. Training block: full\n",
      "actor: 0.116, critic: 0.193, entropy: -2.018, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.500\n",
      "\n",
      "n_iter: 1950/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.005, critic: 0.116, entropy: -2.017, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.552\n",
      "\n",
      "n_iter: 1960/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.040, critic: 0.083, entropy: -2.023, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.557\n",
      "\n",
      "n_iter: 1970/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.014, critic: 0.123, entropy: -2.024, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.538\n",
      "\n",
      "n_iter: 1980/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.045, critic: 0.089, entropy: -2.027, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.559\n",
      "\n",
      "n_iter: 1990/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.049, critic: 0.092, entropy: -2.026, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.559\n",
      "\n",
      "n_iter: 2000/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.001, critic: 0.108, entropy: -2.026, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.545\n",
      "\n",
      "n_iter: 2010/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.047, critic: 0.100, entropy: -2.018, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.563\n",
      "\n",
      "n_iter: 2020/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.046, critic: 0.095, entropy: -2.013, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.563\n",
      "\n",
      "n_iter: 2030/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.068, critic: 0.087, entropy: -2.003, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.571\n",
      "\n",
      "n_iter: 2040/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.018, critic: 0.112, entropy: -2.017, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.554\n",
      "\n",
      "n_iter: 2050/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.048, critic: 0.088, entropy: -2.024, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.558\n",
      "\n",
      "n_iter: 2060/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.027, critic: 0.108, entropy: -2.024, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 2070/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.052, critic: 0.087, entropy: -2.018, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.567\n",
      "\n",
      "n_iter: 2080/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.042, critic: 0.149, entropy: -1.996, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.537\n",
      "\n",
      "n_iter: 2090/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.046, critic: 0.125, entropy: -2.021, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.528\n",
      "\n",
      "n_iter: 2100/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.010, critic: 0.115, entropy: -2.026, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.540\n",
      "\n",
      "n_iter: 2110/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.022, critic: 0.129, entropy: -2.015, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.540\n",
      "\n",
      "n_iter: 2120/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.022, critic: 0.095, entropy: -2.014, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.555\n",
      "\n",
      "n_iter: 2130/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.039, critic: 0.082, entropy: -2.021, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.557\n",
      "\n",
      "n_iter: 2140/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.046, critic: 0.092, entropy: -2.013, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.565\n",
      "\n",
      "n_iter: 2150/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.023, critic: 0.101, entropy: -2.012, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.552\n",
      "\n",
      "n_iter: 2160/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.048, critic: 0.096, entropy: -2.016, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.563\n",
      "\n",
      "n_iter: 2170/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.037, critic: 0.088, entropy: -2.013, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.559\n",
      "\n",
      "n_iter: 2180/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.039, critic: 0.084, entropy: -2.015, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.561\n",
      "\n",
      "n_iter: 2190/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.045, critic: 0.143, entropy: -2.019, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.533\n",
      "\n",
      "n_iter: 2200/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.036, critic: 0.094, entropy: -2.014, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.560\n",
      "\n",
      "n_iter: 2210/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.043, critic: 0.091, entropy: -2.027, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.563\n",
      "\n",
      "n_iter: 2220/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.037, critic: 0.099, entropy: -2.020, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.560\n",
      "\n",
      "n_iter: 2230/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.047, critic: 0.086, entropy: -2.012, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 2240/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.028, critic: 0.092, entropy: -2.012, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.555\n",
      "\n",
      "n_iter: 2250/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.033, critic: 0.139, entropy: -2.025, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.531\n",
      "\n",
      "n_iter: 2260/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.032, critic: 0.128, entropy: -2.025, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.529\n",
      "\n",
      "n_iter: 2270/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.015, critic: 0.131, entropy: -2.009, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.538\n",
      "\n",
      "n_iter: 2280/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.065, critic: 0.165, entropy: -2.012, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.523\n",
      "\n",
      "n_iter: 2290/6000, grad norm: 0.001. Training block: full\n",
      "actor: 0.100, critic: 0.191, entropy: -2.017, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 2300/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.057, critic: 0.092, entropy: -2.013, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.573\n",
      "\n",
      "n_iter: 2310/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.063, critic: 0.095, entropy: -2.015, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.569\n",
      "\n",
      "n_iter: 2320/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.130, critic: 0.188, entropy: -2.020, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 2330/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.032, critic: 0.095, entropy: -2.011, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 2340/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.030, critic: 0.095, entropy: -2.010, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.561\n",
      "\n",
      "n_iter: 2350/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.056, critic: 0.083, entropy: -2.017, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.567\n",
      "\n",
      "n_iter: 2360/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.028, critic: 0.093, entropy: -2.009, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.559\n",
      "\n",
      "n_iter: 2370/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.029, critic: 0.104, entropy: -2.018, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.560\n",
      "\n",
      "n_iter: 2380/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.104, critic: 0.169, entropy: -1.999, ae: 0.094, lstm: 0.000\n",
      "Average reward: 0.519\n",
      "\n",
      "n_iter: 2390/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.045, critic: 0.138, entropy: -2.024, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.526\n",
      "\n",
      "n_iter: 2400/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.019, critic: 0.137, entropy: -2.013, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.546\n",
      "\n",
      "n_iter: 2410/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.001, critic: 0.108, entropy: -2.020, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.549\n",
      "\n",
      "n_iter: 2420/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.083, critic: 0.183, entropy: -2.016, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.517\n",
      "\n",
      "n_iter: 2430/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.023, critic: 0.101, entropy: -2.017, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.557\n",
      "\n",
      "n_iter: 2440/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.029, critic: 0.103, entropy: -2.019, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 2450/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.046, critic: 0.090, entropy: -2.008, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.569\n",
      "\n",
      "n_iter: 2460/6000, grad norm: 0.001. Training block: full\n",
      "actor: 0.132, critic: 0.193, entropy: -2.003, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.503\n",
      "\n",
      "n_iter: 2470/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.013, critic: 0.099, entropy: -2.010, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.554\n",
      "\n",
      "n_iter: 2480/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.070, critic: 0.088, entropy: -2.002, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.579\n",
      "\n",
      "n_iter: 2490/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.053, critic: 0.151, entropy: -2.001, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.529\n",
      "\n",
      "n_iter: 2500/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.032, critic: 0.131, entropy: -2.012, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.541\n",
      "\n",
      "n_iter: 2510/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.058, critic: 0.153, entropy: -2.020, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.526\n",
      "\n",
      "n_iter: 2520/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.002, critic: 0.111, entropy: -2.018, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.545\n",
      "\n",
      "n_iter: 2530/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.041, critic: 0.103, entropy: -2.011, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.561\n",
      "\n",
      "n_iter: 2540/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.018, critic: 0.111, entropy: -2.007, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.552\n",
      "\n",
      "n_iter: 2550/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.062, critic: 0.162, entropy: -2.014, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.530\n",
      "\n",
      "n_iter: 2560/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.105, critic: 0.190, entropy: -2.010, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.510\n",
      "\n",
      "n_iter: 2570/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.029, critic: 0.086, entropy: -2.015, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.553\n",
      "\n",
      "n_iter: 2580/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.044, critic: 0.089, entropy: -2.018, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.564\n",
      "\n",
      "n_iter: 2590/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.036, critic: 0.146, entropy: -2.011, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.543\n",
      "\n",
      "n_iter: 2600/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.019, critic: 0.103, entropy: -2.009, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.554\n",
      "\n",
      "n_iter: 2610/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.008, critic: 0.117, entropy: -2.018, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.542\n",
      "\n",
      "n_iter: 2620/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.000, critic: 0.122, entropy: -2.017, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.547\n",
      "\n",
      "n_iter: 2630/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.047, critic: 0.097, entropy: -2.014, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.559\n",
      "\n",
      "n_iter: 2640/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.031, critic: 0.099, entropy: -2.016, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 2650/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.069, critic: 0.152, entropy: -2.028, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.522\n",
      "\n",
      "n_iter: 2660/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.057, critic: 0.095, entropy: -2.012, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.565\n",
      "\n",
      "n_iter: 2670/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.060, critic: 0.161, entropy: -2.020, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.533\n",
      "\n",
      "n_iter: 2680/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.012, critic: 0.101, entropy: -2.022, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.554\n",
      "\n",
      "n_iter: 2690/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.026, critic: 0.143, entropy: -2.017, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.541\n",
      "\n",
      "n_iter: 2700/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.033, critic: 0.104, entropy: -2.013, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.554\n",
      "\n",
      "n_iter: 2710/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.052, critic: 0.096, entropy: -2.024, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 2720/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.006, critic: 0.124, entropy: -2.008, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.547\n",
      "\n",
      "n_iter: 2730/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.045, critic: 0.099, entropy: -2.008, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.563\n",
      "\n",
      "n_iter: 2740/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.057, critic: 0.085, entropy: -2.027, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.561\n",
      "\n",
      "n_iter: 2750/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.056, critic: 0.094, entropy: -2.011, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 2760/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.116, critic: 0.188, entropy: -2.004, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.517\n",
      "\n",
      "n_iter: 2770/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.054, critic: 0.081, entropy: -2.017, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.570\n",
      "\n",
      "n_iter: 2780/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.022, critic: 0.094, entropy: -2.010, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.560\n",
      "\n",
      "n_iter: 2790/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.067, critic: 0.085, entropy: -2.009, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.574\n",
      "\n",
      "n_iter: 2800/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.119, critic: 0.188, entropy: -2.017, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.505\n",
      "\n",
      "n_iter: 2810/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.090, critic: 0.194, entropy: -2.007, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.519\n",
      "\n",
      "n_iter: 2820/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.058, critic: 0.085, entropy: -2.020, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.569\n",
      "\n",
      "n_iter: 2830/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.015, critic: 0.102, entropy: -2.019, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.552\n",
      "\n",
      "n_iter: 2840/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.000, critic: 0.120, entropy: -2.007, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.547\n",
      "\n",
      "n_iter: 2850/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.049, critic: 0.093, entropy: -2.020, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.565\n",
      "\n",
      "n_iter: 2860/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.006, critic: 0.131, entropy: -2.013, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.551\n",
      "\n",
      "n_iter: 2870/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.059, critic: 0.084, entropy: -2.018, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.568\n",
      "\n",
      "n_iter: 2880/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.014, critic: 0.123, entropy: -2.017, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 2890/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.026, critic: 0.105, entropy: -2.011, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 2900/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.004, critic: 0.112, entropy: -2.010, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.544\n",
      "\n",
      "n_iter: 2910/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.122, critic: 0.192, entropy: -2.022, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.506\n",
      "\n",
      "n_iter: 2920/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.025, critic: 0.105, entropy: -2.000, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.558\n",
      "\n",
      "n_iter: 2930/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.060, critic: 0.083, entropy: -2.007, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.573\n",
      "\n",
      "n_iter: 2940/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.023, critic: 0.109, entropy: -2.006, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.561\n",
      "\n",
      "n_iter: 2950/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.049, critic: 0.151, entropy: -2.009, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.532\n",
      "\n",
      "n_iter: 2960/6000, grad norm: 0.001. Training block: full\n",
      "actor: 0.111, critic: 0.194, entropy: -2.012, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.502\n",
      "\n",
      "n_iter: 2970/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.016, critic: 0.128, entropy: -2.009, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.545\n",
      "\n",
      "n_iter: 2980/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.060, critic: 0.087, entropy: -2.012, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.568\n",
      "\n",
      "n_iter: 2990/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.050, critic: 0.103, entropy: -2.020, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 3000/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.019, critic: 0.141, entropy: -2.012, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.543\n",
      "\n",
      "n_iter: 3010/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.005, critic: 0.129, entropy: -2.022, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.546\n",
      "\n",
      "n_iter: 3020/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.015, critic: 0.137, entropy: -2.024, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.541\n",
      "\n",
      "n_iter: 3030/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.033, critic: 0.099, entropy: -2.016, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.562\n",
      "\n",
      "n_iter: 3040/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.035, critic: 0.090, entropy: -2.016, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.555\n",
      "\n",
      "n_iter: 3050/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.035, critic: 0.102, entropy: -2.007, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.562\n",
      "\n",
      "n_iter: 3060/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.008, critic: 0.129, entropy: -2.009, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.549\n",
      "\n",
      "n_iter: 3070/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.017, critic: 0.095, entropy: -2.015, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 3080/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.015, critic: 0.095, entropy: -2.021, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.554\n",
      "\n",
      "n_iter: 3090/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.068, critic: 0.145, entropy: -2.035, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.515\n",
      "\n",
      "n_iter: 3100/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.032, critic: 0.087, entropy: -2.014, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.559\n",
      "\n",
      "n_iter: 3110/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.037, critic: 0.091, entropy: -2.010, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.562\n",
      "\n",
      "n_iter: 3120/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.053, critic: 0.141, entropy: -2.019, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.529\n",
      "\n",
      "n_iter: 3130/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.042, critic: 0.090, entropy: -2.013, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 3140/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.037, critic: 0.092, entropy: -2.013, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.562\n",
      "\n",
      "n_iter: 3150/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.012, critic: 0.110, entropy: -2.015, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.553\n",
      "\n",
      "n_iter: 3160/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.040, critic: 0.082, entropy: -2.022, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.563\n",
      "\n",
      "n_iter: 3170/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.040, critic: 0.091, entropy: -2.023, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.563\n",
      "\n",
      "n_iter: 3180/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.054, critic: 0.086, entropy: -2.016, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 3190/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.005, critic: 0.116, entropy: -2.020, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.546\n",
      "\n",
      "n_iter: 3200/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.032, critic: 0.090, entropy: -2.009, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.559\n",
      "\n",
      "n_iter: 3210/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.039, critic: 0.089, entropy: -2.012, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.562\n",
      "\n",
      "n_iter: 3220/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.061, critic: 0.082, entropy: -2.011, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.572\n",
      "\n",
      "n_iter: 3230/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.040, critic: 0.083, entropy: -2.010, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 3240/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.060, critic: 0.095, entropy: -2.002, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.569\n",
      "\n",
      "n_iter: 3250/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.023, critic: 0.104, entropy: -2.018, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.559\n",
      "\n",
      "n_iter: 3260/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.056, critic: 0.080, entropy: -2.018, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 3270/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.033, critic: 0.100, entropy: -2.013, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.558\n",
      "\n",
      "n_iter: 3280/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.021, critic: 0.109, entropy: -2.010, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.557\n",
      "\n",
      "n_iter: 3290/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.005, critic: 0.120, entropy: -2.009, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.551\n",
      "\n",
      "n_iter: 3300/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.018, critic: 0.132, entropy: -2.004, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.545\n",
      "\n",
      "n_iter: 3310/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.066, critic: 0.081, entropy: -2.015, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.573\n",
      "\n",
      "n_iter: 3320/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.067, critic: 0.081, entropy: -2.022, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.570\n",
      "\n",
      "n_iter: 3330/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.052, critic: 0.093, entropy: -2.014, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.561\n",
      "\n",
      "n_iter: 3340/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.068, critic: 0.085, entropy: -2.000, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.572\n",
      "\n",
      "n_iter: 3350/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.056, critic: 0.087, entropy: -2.014, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.568\n",
      "\n",
      "n_iter: 3360/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.037, critic: 0.092, entropy: -2.009, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.562\n",
      "\n",
      "n_iter: 3370/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.016, critic: 0.132, entropy: -2.026, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.546\n",
      "\n",
      "n_iter: 3380/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.022, critic: 0.103, entropy: -2.012, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.553\n",
      "\n",
      "n_iter: 3390/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.068, critic: 0.085, entropy: -2.007, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.572\n",
      "\n",
      "n_iter: 3400/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.026, critic: 0.107, entropy: -2.012, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.559\n",
      "\n",
      "n_iter: 3410/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.040, critic: 0.147, entropy: -2.012, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.534\n",
      "\n",
      "n_iter: 3420/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.057, critic: 0.164, entropy: -2.000, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.531\n",
      "\n",
      "n_iter: 3430/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.020, critic: 0.106, entropy: -2.011, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.563\n",
      "\n",
      "n_iter: 3440/6000, grad norm: 0.001. Training block: full\n",
      "actor: 0.143, critic: 0.187, entropy: -2.012, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.505\n",
      "\n",
      "n_iter: 3450/6000, grad norm: 0.001. Training block: full\n",
      "actor: 0.103, critic: 0.174, entropy: -2.012, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.516\n",
      "\n",
      "n_iter: 3460/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.039, critic: 0.086, entropy: -2.012, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.565\n",
      "\n",
      "n_iter: 3470/6000, grad norm: 0.001. Training block: full\n",
      "actor: 0.138, critic: 0.199, entropy: -2.007, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 3480/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.026, critic: 0.099, entropy: -2.027, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.561\n",
      "\n",
      "n_iter: 3490/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.034, critic: 0.092, entropy: -2.022, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.563\n",
      "\n",
      "n_iter: 3500/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.036, critic: 0.092, entropy: -2.008, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.562\n",
      "\n",
      "n_iter: 3510/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.021, critic: 0.108, entropy: -2.013, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 3520/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.029, critic: 0.099, entropy: -2.020, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.558\n",
      "\n",
      "n_iter: 3530/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.027, critic: 0.090, entropy: -2.019, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.555\n",
      "\n",
      "n_iter: 3540/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.023, critic: 0.097, entropy: -2.016, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.561\n",
      "\n",
      "n_iter: 3550/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.022, critic: 0.107, entropy: -2.011, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.562\n",
      "\n",
      "n_iter: 3560/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.014, critic: 0.097, entropy: -2.023, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.557\n",
      "\n",
      "n_iter: 3570/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.009, critic: 0.113, entropy: -2.011, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 3580/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.008, critic: 0.117, entropy: -1.996, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.551\n",
      "\n",
      "n_iter: 3590/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.027, critic: 0.128, entropy: -2.005, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.547\n",
      "\n",
      "n_iter: 3600/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.016, critic: 0.135, entropy: -2.015, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.548\n",
      "\n",
      "n_iter: 3610/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.037, critic: 0.088, entropy: -2.010, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.564\n",
      "\n",
      "n_iter: 3620/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.012, critic: 0.102, entropy: -2.020, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.555\n",
      "\n",
      "n_iter: 3630/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.032, critic: 0.090, entropy: -2.005, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.567\n",
      "\n",
      "n_iter: 3640/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.043, critic: 0.082, entropy: -2.010, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.567\n",
      "\n",
      "n_iter: 3650/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.045, critic: 0.088, entropy: -2.002, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.568\n",
      "\n",
      "n_iter: 3660/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.110, critic: 0.181, entropy: -2.004, ae: 0.094, lstm: 0.000\n",
      "Average reward: 0.518\n",
      "\n",
      "n_iter: 3670/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.064, critic: 0.153, entropy: -2.013, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.530\n",
      "\n",
      "n_iter: 3680/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.048, critic: 0.087, entropy: -2.015, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.574\n",
      "\n",
      "n_iter: 3690/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.033, critic: 0.093, entropy: -2.008, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.563\n",
      "\n",
      "n_iter: 3700/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.028, critic: 0.131, entropy: -2.013, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.547\n",
      "\n",
      "n_iter: 3710/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.046, critic: 0.088, entropy: -2.004, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.572\n",
      "\n",
      "n_iter: 3720/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.079, critic: 0.164, entropy: -2.000, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.525\n",
      "\n",
      "n_iter: 3730/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.046, critic: 0.083, entropy: -2.001, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.569\n",
      "\n",
      "n_iter: 3740/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.037, critic: 0.132, entropy: -2.016, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.540\n",
      "\n",
      "n_iter: 3750/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.084, critic: 0.175, entropy: -2.005, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.527\n",
      "\n",
      "n_iter: 3760/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.012, critic: 0.116, entropy: -1.998, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.560\n",
      "\n",
      "n_iter: 3770/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.051, critic: 0.088, entropy: -2.023, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.568\n",
      "\n",
      "n_iter: 3780/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.076, critic: 0.148, entropy: -2.011, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.525\n",
      "\n",
      "n_iter: 3790/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.029, critic: 0.098, entropy: -2.005, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.564\n",
      "\n",
      "n_iter: 3800/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.062, critic: 0.086, entropy: -2.004, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.576\n",
      "\n",
      "n_iter: 3810/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.028, critic: 0.101, entropy: -2.005, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 3820/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.052, critic: 0.080, entropy: -2.007, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.575\n",
      "\n",
      "n_iter: 3830/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.019, critic: 0.111, entropy: -2.002, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.563\n",
      "\n",
      "n_iter: 3840/6000, grad norm: 0.001. Training block: full\n",
      "actor: 0.094, critic: 0.180, entropy: -2.006, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.527\n",
      "\n",
      "n_iter: 3850/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.038, critic: 0.082, entropy: -2.010, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 3860/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.010, critic: 0.128, entropy: -2.007, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.553\n",
      "\n",
      "n_iter: 3870/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.048, critic: 0.137, entropy: -2.010, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.541\n",
      "\n",
      "n_iter: 3880/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.025, critic: 0.097, entropy: -2.008, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.565\n",
      "\n",
      "n_iter: 3890/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.025, critic: 0.094, entropy: -2.015, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.563\n",
      "\n",
      "n_iter: 3900/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.020, critic: 0.097, entropy: -2.016, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.562\n",
      "\n",
      "n_iter: 3910/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.089, critic: 0.163, entropy: -2.011, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.524\n",
      "\n",
      "n_iter: 3920/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.040, critic: 0.086, entropy: -1.994, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.568\n",
      "\n",
      "n_iter: 3930/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.004, critic: 0.127, entropy: -1.986, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.559\n",
      "\n",
      "n_iter: 3940/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.043, critic: 0.082, entropy: -1.995, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.578\n",
      "\n",
      "n_iter: 3950/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.107, critic: 0.176, entropy: -2.005, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.525\n",
      "\n",
      "n_iter: 3960/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.067, critic: 0.154, entropy: -2.001, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.542\n",
      "\n",
      "n_iter: 3970/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.020, critic: 0.080, entropy: -2.018, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.565\n",
      "\n",
      "n_iter: 3980/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.090, critic: 0.180, entropy: -2.009, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.526\n",
      "\n",
      "n_iter: 3990/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.023, critic: 0.129, entropy: -2.008, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.549\n",
      "\n",
      "n_iter: 4000/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.020, critic: 0.102, entropy: -2.010, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.565\n",
      "\n",
      "n_iter: 4010/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.046, critic: 0.082, entropy: -2.014, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.573\n",
      "\n",
      "n_iter: 4020/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.030, critic: 0.092, entropy: -1.998, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.570\n",
      "\n",
      "n_iter: 4030/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.081, critic: 0.172, entropy: -2.013, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.530\n",
      "\n",
      "n_iter: 4040/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.046, critic: 0.084, entropy: -2.011, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.576\n",
      "\n",
      "n_iter: 4050/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.021, critic: 0.099, entropy: -2.008, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.563\n",
      "\n",
      "n_iter: 4060/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.096, critic: 0.181, entropy: -2.009, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.525\n",
      "\n",
      "n_iter: 4070/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.017, critic: 0.100, entropy: -2.002, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.564\n",
      "\n",
      "n_iter: 4080/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.130, critic: 0.201, entropy: -2.013, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.510\n",
      "\n",
      "n_iter: 4090/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.053, critic: 0.136, entropy: -2.013, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.540\n",
      "\n",
      "n_iter: 4100/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.067, critic: 0.087, entropy: -2.001, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.581\n",
      "\n",
      "n_iter: 4110/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.028, critic: 0.128, entropy: -2.003, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.542\n",
      "\n",
      "n_iter: 4120/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.010, critic: 0.119, entropy: -2.004, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.551\n",
      "\n",
      "n_iter: 4130/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.064, critic: 0.170, entropy: -2.001, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.532\n",
      "\n",
      "n_iter: 4140/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.037, critic: 0.151, entropy: -1.983, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.544\n",
      "\n",
      "n_iter: 4150/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.055, critic: 0.080, entropy: -2.001, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.574\n",
      "\n",
      "n_iter: 4160/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.006, critic: 0.123, entropy: -1.998, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.551\n",
      "\n",
      "n_iter: 4170/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.052, critic: 0.082, entropy: -2.000, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.570\n",
      "\n",
      "n_iter: 4180/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.062, critic: 0.081, entropy: -2.000, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.575\n",
      "\n",
      "n_iter: 4190/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.064, critic: 0.150, entropy: -2.001, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.533\n",
      "\n",
      "n_iter: 4200/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.038, critic: 0.086, entropy: -2.002, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.574\n",
      "\n",
      "n_iter: 4210/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.040, critic: 0.144, entropy: -1.997, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.547\n",
      "\n",
      "n_iter: 4220/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.053, critic: 0.095, entropy: -1.994, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.575\n",
      "\n",
      "n_iter: 4230/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.054, critic: 0.088, entropy: -2.002, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.576\n",
      "\n",
      "n_iter: 4240/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.002, critic: 0.115, entropy: -2.001, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.560\n",
      "\n",
      "n_iter: 4250/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.024, critic: 0.129, entropy: -2.003, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.549\n",
      "\n",
      "n_iter: 4260/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.034, critic: 0.133, entropy: -1.997, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.547\n",
      "\n",
      "n_iter: 4270/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.020, critic: 0.139, entropy: -1.993, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.550\n",
      "\n",
      "n_iter: 4280/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.013, critic: 0.123, entropy: -1.997, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.552\n",
      "\n",
      "n_iter: 4290/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.060, critic: 0.155, entropy: -2.004, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.540\n",
      "\n",
      "n_iter: 4300/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.033, critic: 0.100, entropy: -2.023, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.564\n",
      "\n",
      "n_iter: 4310/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.020, critic: 0.108, entropy: -2.000, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.560\n",
      "\n",
      "n_iter: 4320/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.008, critic: 0.110, entropy: -2.009, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.557\n",
      "\n",
      "n_iter: 4330/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.023, critic: 0.092, entropy: -2.009, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.562\n",
      "\n",
      "n_iter: 4340/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.041, critic: 0.085, entropy: -2.016, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.565\n",
      "\n",
      "n_iter: 4350/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.044, critic: 0.092, entropy: -2.007, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.568\n",
      "\n",
      "n_iter: 4360/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.034, critic: 0.099, entropy: -1.999, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.568\n",
      "\n",
      "n_iter: 4370/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.018, critic: 0.134, entropy: -1.995, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.554\n",
      "\n",
      "n_iter: 4380/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.051, critic: 0.090, entropy: -1.996, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.573\n",
      "\n",
      "n_iter: 4390/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.132, critic: 0.186, entropy: -2.003, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.507\n",
      "\n",
      "n_iter: 4400/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.019, critic: 0.099, entropy: -1.998, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 4410/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.038, critic: 0.092, entropy: -2.004, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.568\n",
      "\n",
      "n_iter: 4420/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.013, critic: 0.115, entropy: -1.995, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.560\n",
      "\n",
      "n_iter: 4430/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.018, critic: 0.105, entropy: -2.004, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 4440/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.049, critic: 0.085, entropy: -2.007, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.569\n",
      "\n",
      "n_iter: 4450/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.031, critic: 0.097, entropy: -2.008, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 4460/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.068, critic: 0.084, entropy: -2.002, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.584\n",
      "\n",
      "n_iter: 4470/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.093, critic: 0.182, entropy: -2.001, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.535\n",
      "\n",
      "n_iter: 4480/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.007, critic: 0.105, entropy: -2.011, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.558\n",
      "\n",
      "n_iter: 4490/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.033, critic: 0.120, entropy: -2.009, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.542\n",
      "\n",
      "n_iter: 4500/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.060, critic: 0.086, entropy: -2.003, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.575\n",
      "\n",
      "n_iter: 4510/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.072, critic: 0.080, entropy: -2.004, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.580\n",
      "\n",
      "n_iter: 4520/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.047, critic: 0.090, entropy: -2.005, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.568\n",
      "\n",
      "n_iter: 4530/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.033, critic: 0.098, entropy: -2.007, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.564\n",
      "\n",
      "n_iter: 4540/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.041, critic: 0.134, entropy: -2.005, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.540\n",
      "\n",
      "n_iter: 4550/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.060, critic: 0.085, entropy: -2.006, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.574\n",
      "\n",
      "n_iter: 4560/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.010, critic: 0.114, entropy: -2.013, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.549\n",
      "\n",
      "n_iter: 4570/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.046, critic: 0.088, entropy: -2.004, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.570\n",
      "\n",
      "n_iter: 4580/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.035, critic: 0.145, entropy: -2.003, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.544\n",
      "\n",
      "n_iter: 4590/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.040, critic: 0.101, entropy: -2.006, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.567\n",
      "\n",
      "n_iter: 4600/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.132, critic: 0.188, entropy: -2.008, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.507\n",
      "\n",
      "n_iter: 4610/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.010, critic: 0.124, entropy: -1.999, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.553\n",
      "\n",
      "n_iter: 4620/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.043, critic: 0.098, entropy: -2.004, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 4630/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.056, critic: 0.155, entropy: -2.004, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.533\n",
      "\n",
      "n_iter: 4640/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.028, critic: 0.089, entropy: -2.003, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 4650/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.026, critic: 0.095, entropy: -2.000, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.570\n",
      "\n",
      "n_iter: 4660/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.084, critic: 0.160, entropy: -2.006, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.525\n",
      "\n",
      "n_iter: 4670/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.004, critic: 0.117, entropy: -2.004, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.550\n",
      "\n",
      "n_iter: 4680/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.012, critic: 0.111, entropy: -1.993, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.561\n",
      "\n",
      "n_iter: 4690/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.069, critic: 0.081, entropy: -2.006, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.573\n",
      "\n",
      "n_iter: 4700/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.019, critic: 0.120, entropy: -1.994, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.548\n",
      "\n",
      "n_iter: 4710/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.039, critic: 0.090, entropy: -1.999, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.575\n",
      "\n",
      "n_iter: 4720/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.046, critic: 0.083, entropy: -1.988, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.573\n",
      "\n",
      "n_iter: 4730/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.006, critic: 0.122, entropy: -2.004, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.562\n",
      "\n",
      "n_iter: 4740/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.005, critic: 0.103, entropy: -2.000, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.557\n",
      "\n",
      "n_iter: 4750/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.032, critic: 0.143, entropy: -2.008, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.546\n",
      "\n",
      "n_iter: 4760/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.043, critic: 0.091, entropy: -2.004, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.571\n",
      "\n",
      "n_iter: 4770/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.013, critic: 0.116, entropy: -2.007, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.558\n",
      "\n",
      "n_iter: 4780/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.026, critic: 0.137, entropy: -2.007, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.545\n",
      "\n",
      "n_iter: 4790/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.059, critic: 0.089, entropy: -1.997, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.575\n",
      "\n",
      "n_iter: 4800/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.023, critic: 0.095, entropy: -2.013, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.567\n",
      "\n",
      "n_iter: 4810/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.015, critic: 0.105, entropy: -1.998, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.563\n",
      "\n",
      "n_iter: 4820/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.051, critic: 0.092, entropy: -2.006, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.570\n",
      "\n",
      "n_iter: 4830/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.084, critic: 0.165, entropy: -2.009, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.530\n",
      "\n",
      "n_iter: 4840/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.041, critic: 0.153, entropy: -2.005, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.545\n",
      "\n",
      "n_iter: 4850/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.036, critic: 0.142, entropy: -1.995, ae: 0.094, lstm: 0.000\n",
      "Average reward: 0.550\n",
      "\n",
      "n_iter: 4860/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.054, critic: 0.100, entropy: -2.002, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.578\n",
      "\n",
      "n_iter: 4870/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.027, critic: 0.101, entropy: -2.004, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 4880/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.059, critic: 0.088, entropy: -1.999, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.578\n",
      "\n",
      "n_iter: 4890/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.049, critic: 0.087, entropy: -1.999, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.571\n",
      "\n",
      "n_iter: 4900/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.026, critic: 0.092, entropy: -1.998, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.562\n",
      "\n",
      "n_iter: 4910/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.021, critic: 0.098, entropy: -1.997, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.568\n",
      "\n",
      "n_iter: 4920/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.034, critic: 0.091, entropy: -1.999, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.572\n",
      "\n",
      "n_iter: 4930/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.031, critic: 0.107, entropy: -1.987, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.578\n",
      "\n",
      "n_iter: 4940/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.052, critic: 0.087, entropy: -1.996, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.581\n",
      "\n",
      "n_iter: 4950/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.059, critic: 0.081, entropy: -1.996, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.580\n",
      "\n",
      "n_iter: 4960/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.051, critic: 0.083, entropy: -2.000, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.578\n",
      "\n",
      "n_iter: 4970/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.014, critic: 0.095, entropy: -1.992, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.565\n",
      "\n",
      "n_iter: 4980/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.018, critic: 0.113, entropy: -1.989, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 4990/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.038, critic: 0.136, entropy: -2.002, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.546\n",
      "\n",
      "n_iter: 5000/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.037, critic: 0.095, entropy: -2.003, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.571\n",
      "\n",
      "n_iter: 5010/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.013, critic: 0.135, entropy: -1.994, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.551\n",
      "\n",
      "n_iter: 5020/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.079, critic: 0.162, entropy: -1.993, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.536\n",
      "\n",
      "n_iter: 5030/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.005, critic: 0.112, entropy: -1.995, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.550\n",
      "\n",
      "n_iter: 5040/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.036, critic: 0.098, entropy: -1.997, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.567\n",
      "\n",
      "n_iter: 5050/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.013, critic: 0.093, entropy: -1.999, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.564\n",
      "\n",
      "n_iter: 5060/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.029, critic: 0.103, entropy: -2.003, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 5070/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.062, critic: 0.079, entropy: -1.994, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.581\n",
      "\n",
      "n_iter: 5080/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.093, critic: 0.170, entropy: -1.987, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.532\n",
      "\n",
      "n_iter: 5090/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.017, critic: 0.103, entropy: -1.988, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.565\n",
      "\n",
      "n_iter: 5100/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.049, critic: 0.080, entropy: -1.987, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.577\n",
      "\n",
      "n_iter: 5110/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.101, critic: 0.161, entropy: -1.989, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.521\n",
      "\n",
      "n_iter: 5120/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.068, critic: 0.158, entropy: -1.997, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.536\n",
      "\n",
      "n_iter: 5130/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.023, critic: 0.095, entropy: -1.996, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.568\n",
      "\n",
      "n_iter: 5140/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.085, critic: 0.165, entropy: -1.993, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.528\n",
      "\n",
      "n_iter: 5150/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.023, critic: 0.121, entropy: -1.992, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.552\n",
      "\n",
      "n_iter: 5160/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.047, critic: 0.096, entropy: -1.987, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.575\n",
      "\n",
      "n_iter: 5170/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.036, critic: 0.114, entropy: -1.996, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.572\n",
      "\n",
      "n_iter: 5180/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.020, critic: 0.099, entropy: -2.003, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.562\n",
      "\n",
      "n_iter: 5190/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.051, critic: 0.084, entropy: -1.997, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.572\n",
      "\n",
      "n_iter: 5200/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.058, critic: 0.081, entropy: -1.993, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.583\n",
      "\n",
      "n_iter: 5210/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.034, critic: 0.086, entropy: -1.991, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.577\n",
      "\n",
      "n_iter: 5220/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.058, critic: 0.082, entropy: -1.990, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.577\n",
      "\n",
      "n_iter: 5230/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.003, critic: 0.111, entropy: -2.006, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.559\n",
      "\n",
      "n_iter: 5240/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.027, critic: 0.092, entropy: -2.006, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.570\n",
      "\n",
      "n_iter: 5250/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.064, critic: 0.161, entropy: -1.997, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.542\n",
      "\n",
      "n_iter: 5260/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.060, critic: 0.141, entropy: -1.997, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.543\n",
      "\n",
      "n_iter: 5270/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.020, critic: 0.113, entropy: -1.998, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.561\n",
      "\n",
      "n_iter: 5280/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.018, critic: 0.114, entropy: -1.994, ae: 0.100, lstm: 0.000\n",
      "Average reward: 0.549\n",
      "\n",
      "n_iter: 5290/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.033, critic: 0.134, entropy: -2.002, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.550\n",
      "\n",
      "n_iter: 5300/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.050, critic: 0.096, entropy: -1.999, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.575\n",
      "\n",
      "n_iter: 5310/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.006, critic: 0.113, entropy: -1.998, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.551\n",
      "\n",
      "n_iter: 5320/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.041, critic: 0.124, entropy: -1.994, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.539\n",
      "\n",
      "n_iter: 5330/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.048, critic: 0.092, entropy: -1.997, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.577\n",
      "\n",
      "n_iter: 5340/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.069, critic: 0.085, entropy: -1.999, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.586\n",
      "\n",
      "n_iter: 5350/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.045, critic: 0.086, entropy: -1.995, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.575\n",
      "\n",
      "n_iter: 5360/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.042, critic: 0.132, entropy: -1.997, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.554\n",
      "\n",
      "n_iter: 5370/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.045, critic: 0.141, entropy: -1.997, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.543\n",
      "\n",
      "n_iter: 5380/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.122, critic: 0.191, entropy: -2.010, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.510\n",
      "\n",
      "n_iter: 5390/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.095, critic: 0.186, entropy: -1.999, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.517\n",
      "\n",
      "n_iter: 5400/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.063, critic: 0.147, entropy: -1.996, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.535\n",
      "\n",
      "n_iter: 5410/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.071, critic: 0.083, entropy: -1.994, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.586\n",
      "\n",
      "n_iter: 5420/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.029, critic: 0.137, entropy: -1.991, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.551\n",
      "\n",
      "n_iter: 5430/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.058, critic: 0.088, entropy: -1.996, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.577\n",
      "\n",
      "n_iter: 5440/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.072, critic: 0.083, entropy: -1.999, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.581\n",
      "\n",
      "n_iter: 5450/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.021, critic: 0.097, entropy: -1.997, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.564\n",
      "\n",
      "n_iter: 5460/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.005, critic: 0.109, entropy: -1.994, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.561\n",
      "\n",
      "n_iter: 5470/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.015, critic: 0.088, entropy: -1.996, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.561\n",
      "\n",
      "n_iter: 5480/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.005, critic: 0.128, entropy: -1.982, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.555\n",
      "\n",
      "n_iter: 5490/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.049, critic: 0.090, entropy: -1.996, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.571\n",
      "\n",
      "n_iter: 5500/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.050, critic: 0.090, entropy: -1.999, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.576\n",
      "\n",
      "n_iter: 5510/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.023, critic: 0.096, entropy: -1.998, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.567\n",
      "\n",
      "n_iter: 5520/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.007, critic: 0.109, entropy: -2.001, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.558\n",
      "\n",
      "n_iter: 5530/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.082, critic: 0.150, entropy: -1.990, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.530\n",
      "\n",
      "n_iter: 5540/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.017, critic: 0.121, entropy: -1.991, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.568\n",
      "\n",
      "n_iter: 5550/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.060, critic: 0.083, entropy: -2.009, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.577\n",
      "\n",
      "n_iter: 5560/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.017, critic: 0.113, entropy: -2.001, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 5570/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.058, critic: 0.090, entropy: -1.996, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.580\n",
      "\n",
      "n_iter: 5580/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.128, critic: 0.191, entropy: -1.995, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.513\n",
      "\n",
      "n_iter: 5590/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.027, critic: 0.102, entropy: -2.005, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.566\n",
      "\n",
      "n_iter: 5600/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.042, critic: 0.100, entropy: -2.001, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.568\n",
      "\n",
      "n_iter: 5610/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.115, critic: 0.192, entropy: -2.004, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.517\n",
      "\n",
      "n_iter: 5620/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.031, critic: 0.109, entropy: -1.998, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.569\n",
      "\n",
      "n_iter: 5630/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.003, critic: 0.104, entropy: -1.987, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 5640/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.073, critic: 0.083, entropy: -1.988, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.581\n",
      "\n",
      "n_iter: 5650/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.035, critic: 0.146, entropy: -1.996, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.547\n",
      "\n",
      "n_iter: 5660/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.064, critic: 0.095, entropy: -2.000, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.580\n",
      "\n",
      "n_iter: 5670/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.033, critic: 0.110, entropy: -1.997, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.570\n",
      "\n",
      "n_iter: 5680/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.070, critic: 0.087, entropy: -1.990, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.583\n",
      "\n",
      "n_iter: 5690/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.027, critic: 0.095, entropy: -1.984, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.570\n",
      "\n",
      "n_iter: 5700/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.022, critic: 0.109, entropy: -1.985, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.565\n",
      "\n",
      "n_iter: 5710/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.024, critic: 0.101, entropy: -1.987, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.572\n",
      "\n",
      "n_iter: 5720/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.063, critic: 0.154, entropy: -1.992, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.537\n",
      "\n",
      "n_iter: 5730/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.013, critic: 0.130, entropy: -2.002, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.553\n",
      "\n",
      "n_iter: 5740/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.070, critic: 0.082, entropy: -1.997, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.581\n",
      "\n",
      "n_iter: 5750/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.025, critic: 0.147, entropy: -1.995, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.550\n",
      "\n",
      "n_iter: 5760/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.069, critic: 0.164, entropy: -2.001, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.534\n",
      "\n",
      "n_iter: 5770/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.025, critic: 0.121, entropy: -2.001, ae: 0.095, lstm: 0.000\n",
      "Average reward: 0.568\n",
      "\n",
      "n_iter: 5780/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.001, critic: 0.134, entropy: -1.996, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.553\n",
      "\n",
      "n_iter: 5790/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.006, critic: 0.124, entropy: -2.002, ae: 0.099, lstm: 0.000\n",
      "Average reward: 0.557\n",
      "\n",
      "n_iter: 5800/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.065, critic: 0.087, entropy: -1.991, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.585\n",
      "\n",
      "n_iter: 5810/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.018, critic: 0.118, entropy: -1.989, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.556\n",
      "\n",
      "n_iter: 5820/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.044, critic: 0.083, entropy: -1.990, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.576\n",
      "\n",
      "n_iter: 5830/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.052, critic: 0.084, entropy: -1.982, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.582\n",
      "\n",
      "n_iter: 5840/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.003, critic: 0.109, entropy: -1.985, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.564\n",
      "\n",
      "n_iter: 5850/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.049, critic: 0.087, entropy: -1.982, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.580\n",
      "\n",
      "n_iter: 5860/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.019, critic: 0.109, entropy: -1.982, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.575\n",
      "\n",
      "n_iter: 5870/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.000, critic: 0.109, entropy: -1.988, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.562\n",
      "\n",
      "n_iter: 5880/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.053, critic: 0.079, entropy: -1.986, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.581\n",
      "\n",
      "n_iter: 5890/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.020, critic: 0.125, entropy: -1.987, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.555\n",
      "\n",
      "n_iter: 5900/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.062, critic: 0.087, entropy: -1.988, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.581\n",
      "\n",
      "n_iter: 5910/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.030, critic: 0.090, entropy: -1.996, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.568\n",
      "\n",
      "n_iter: 5920/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.062, critic: 0.085, entropy: -1.992, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.581\n",
      "\n",
      "n_iter: 5930/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.050, critic: 0.086, entropy: -1.991, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.581\n",
      "\n",
      "n_iter: 5940/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.056, critic: 0.084, entropy: -1.995, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.577\n",
      "\n",
      "n_iter: 5950/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.037, critic: 0.093, entropy: -1.984, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.576\n",
      "\n",
      "n_iter: 5960/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.038, critic: 0.095, entropy: -1.990, ae: 0.097, lstm: 0.000\n",
      "Average reward: 0.574\n",
      "\n",
      "n_iter: 5970/6000, grad norm: 0.000. Training block: full\n",
      "actor: -0.059, critic: 0.083, entropy: -1.993, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.580\n",
      "\n",
      "n_iter: 5980/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.009, critic: 0.118, entropy: -1.988, ae: 0.096, lstm: 0.000\n",
      "Average reward: 0.557\n",
      "\n",
      "n_iter: 5990/6000, grad norm: 0.000. Training block: full\n",
      "actor: 0.056, critic: 0.154, entropy: -1.991, ae: 0.098, lstm: 0.000\n",
      "Average reward: 0.546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "progress_ae = train(\n",
    "    agent = agent_ae, \n",
    "    num_iterations = [2000, 2000, 6000], \n",
    "    iter_per_batch = [1, 2, 2], \n",
    "    blocks = [['ae'], ['actor', 'critic'], ['full']]\n",
    ")\n",
    "\n",
    "filename = 'stats_ae.json'\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(progress_ae, f, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600809ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter: 0/1000, grad norm: 0.012. Training block: ae\n",
      "actor: -0.125, critic: 0.157, entropy: -2.049, ae: 1.270, lstm: 1.362\n",
      "Average reward: 0.325\n",
      "\n",
      "n_iter: 10/1000, grad norm: 0.010. Training block: ae\n",
      "actor: -0.137, critic: 0.209, entropy: -2.077, ae: 1.107, lstm: 1.356\n",
      "Average reward: 0.332\n",
      "\n",
      "n_iter: 20/1000, grad norm: 0.008. Training block: ae\n",
      "actor: -0.098, critic: 0.176, entropy: -2.077, ae: 1.003, lstm: 1.401\n",
      "Average reward: 0.330\n",
      "\n",
      "n_iter: 30/1000, grad norm: 0.006. Training block: ae\n",
      "actor: -0.132, critic: 0.166, entropy: -2.066, ae: 0.925, lstm: 1.417\n",
      "Average reward: 0.336\n",
      "\n",
      "n_iter: 40/1000, grad norm: 0.005. Training block: ae\n",
      "actor: -0.096, critic: 0.171, entropy: -2.061, ae: 0.870, lstm: 1.442\n",
      "Average reward: 0.324\n",
      "\n",
      "n_iter: 50/1000, grad norm: 0.006. Training block: ae\n",
      "actor: -0.080, critic: 0.184, entropy: -2.063, ae: 0.826, lstm: 1.443\n",
      "Average reward: 0.317\n",
      "\n",
      "n_iter: 60/1000, grad norm: 0.005. Training block: ae\n",
      "actor: -0.114, critic: 0.161, entropy: -2.066, ae: 0.783, lstm: 1.461\n",
      "Average reward: 0.326\n",
      "\n",
      "n_iter: 70/1000, grad norm: 0.006. Training block: ae\n",
      "actor: -0.108, critic: 0.164, entropy: -2.077, ae: 0.734, lstm: 1.507\n",
      "Average reward: 0.324\n",
      "\n",
      "n_iter: 80/1000, grad norm: 0.005. Training block: ae\n",
      "actor: -0.096, critic: 0.166, entropy: -2.077, ae: 0.692, lstm: 1.516\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 90/1000, grad norm: 0.005. Training block: ae\n",
      "actor: -0.106, critic: 0.174, entropy: -2.067, ae: 0.673, lstm: 1.533\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 100/1000, grad norm: 0.005. Training block: ae\n",
      "actor: -0.122, critic: 0.169, entropy: -2.084, ae: 0.636, lstm: 1.525\n",
      "Average reward: 0.324\n",
      "\n",
      "n_iter: 110/1000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.092, critic: 0.180, entropy: -2.076, ae: 0.611, lstm: 1.535\n",
      "Average reward: 0.314\n",
      "\n",
      "n_iter: 120/1000, grad norm: 0.005. Training block: ae\n",
      "actor: -0.032, critic: 0.162, entropy: -2.078, ae: 0.568, lstm: 1.565\n",
      "Average reward: 0.300\n",
      "\n",
      "n_iter: 130/1000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.082, critic: 0.171, entropy: -2.082, ae: 0.565, lstm: 1.547\n",
      "Average reward: 0.304\n",
      "\n",
      "n_iter: 140/1000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.111, critic: 0.149, entropy: -2.081, ae: 0.536, lstm: 1.570\n",
      "Average reward: 0.319\n",
      "\n",
      "n_iter: 150/1000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.092, critic: 0.191, entropy: -2.077, ae: 0.522, lstm: 1.583\n",
      "Average reward: 0.312\n",
      "\n",
      "n_iter: 160/1000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.083, critic: 0.157, entropy: -2.079, ae: 0.503, lstm: 1.559\n",
      "Average reward: 0.303\n",
      "\n",
      "n_iter: 170/1000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.094, critic: 0.159, entropy: -2.069, ae: 0.488, lstm: 1.593\n",
      "Average reward: 0.307\n",
      "\n",
      "n_iter: 180/1000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.105, critic: 0.173, entropy: -2.076, ae: 0.468, lstm: 1.598\n",
      "Average reward: 0.310\n",
      "\n",
      "n_iter: 190/1000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.091, critic: 0.175, entropy: -2.067, ae: 0.453, lstm: 1.662\n",
      "Average reward: 0.309\n",
      "\n",
      "n_iter: 200/1000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.133, critic: 0.167, entropy: -2.081, ae: 0.435, lstm: 1.637\n",
      "Average reward: 0.325\n",
      "\n",
      "n_iter: 210/1000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.089, critic: 0.152, entropy: -2.075, ae: 0.419, lstm: 1.611\n",
      "Average reward: 0.302\n",
      "\n",
      "n_iter: 220/1000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.098, critic: 0.159, entropy: -2.068, ae: 0.406, lstm: 1.639\n",
      "Average reward: 0.308\n",
      "\n",
      "n_iter: 230/1000, grad norm: 0.005. Training block: ae\n",
      "actor: -0.067, critic: 0.180, entropy: -2.075, ae: 0.390, lstm: 1.646\n",
      "Average reward: 0.304\n",
      "\n",
      "n_iter: 240/1000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.106, critic: 0.157, entropy: -2.070, ae: 0.382, lstm: 1.652\n",
      "Average reward: 0.310\n",
      "\n",
      "n_iter: 250/1000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.116, critic: 0.166, entropy: -2.075, ae: 0.375, lstm: 1.673\n",
      "Average reward: 0.319\n",
      "\n",
      "n_iter: 260/1000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.069, critic: 0.153, entropy: -2.061, ae: 0.354, lstm: 1.675\n",
      "Average reward: 0.301\n",
      "\n",
      "n_iter: 270/1000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.117, critic: 0.162, entropy: -2.074, ae: 0.346, lstm: 1.690\n",
      "Average reward: 0.326\n",
      "\n",
      "n_iter: 280/1000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.090, critic: 0.140, entropy: -2.072, ae: 0.337, lstm: 1.672\n",
      "Average reward: 0.309\n",
      "\n",
      "n_iter: 290/1000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.059, critic: 0.152, entropy: -2.081, ae: 0.333, lstm: 1.673\n",
      "Average reward: 0.300\n",
      "\n",
      "n_iter: 300/1000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.102, critic: 0.161, entropy: -2.067, ae: 0.318, lstm: 1.674\n",
      "Average reward: 0.315\n",
      "\n",
      "n_iter: 310/1000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.084, critic: 0.166, entropy: -2.069, ae: 0.303, lstm: 1.707\n",
      "Average reward: 0.311\n",
      "\n",
      "n_iter: 320/1000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.069, critic: 0.165, entropy: -2.069, ae: 0.301, lstm: 1.694\n",
      "Average reward: 0.299\n",
      "\n",
      "n_iter: 330/1000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.111, critic: 0.150, entropy: -2.072, ae: 0.288, lstm: 1.708\n",
      "Average reward: 0.312\n",
      "\n",
      "n_iter: 340/1000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.088, critic: 0.166, entropy: -2.069, ae: 0.286, lstm: 1.684\n",
      "Average reward: 0.306\n",
      "\n",
      "n_iter: 350/1000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.078, critic: 0.142, entropy: -2.064, ae: 0.273, lstm: 1.713\n",
      "Average reward: 0.300\n",
      "\n",
      "n_iter: 360/1000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.074, critic: 0.178, entropy: -2.066, ae: 0.270, lstm: 1.706\n",
      "Average reward: 0.311\n",
      "\n",
      "n_iter: 370/1000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.075, critic: 0.148, entropy: -2.069, ae: 0.258, lstm: 1.707\n",
      "Average reward: 0.302\n",
      "\n",
      "n_iter: 380/1000, grad norm: 0.004. Training block: ae\n",
      "actor: -0.033, critic: 0.170, entropy: -2.058, ae: 0.261, lstm: 1.747\n",
      "Average reward: 0.290\n",
      "\n",
      "n_iter: 390/1000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.092, critic: 0.167, entropy: -2.065, ae: 0.254, lstm: 1.740\n",
      "Average reward: 0.314\n",
      "\n",
      "n_iter: 400/1000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.098, critic: 0.151, entropy: -2.070, ae: 0.247, lstm: 1.729\n",
      "Average reward: 0.309\n",
      "\n",
      "n_iter: 410/1000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.097, critic: 0.151, entropy: -2.072, ae: 0.229, lstm: 1.744\n",
      "Average reward: 0.310\n",
      "\n",
      "n_iter: 420/1000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.068, critic: 0.149, entropy: -2.068, ae: 0.225, lstm: 1.773\n",
      "Average reward: 0.302\n",
      "\n",
      "n_iter: 430/1000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.083, critic: 0.161, entropy: -2.065, ae: 0.219, lstm: 1.757\n",
      "Average reward: 0.306\n",
      "\n",
      "n_iter: 440/1000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.067, critic: 0.170, entropy: -2.065, ae: 0.225, lstm: 1.766\n",
      "Average reward: 0.306\n",
      "\n",
      "n_iter: 450/1000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.082, critic: 0.160, entropy: -2.065, ae: 0.217, lstm: 1.790\n",
      "Average reward: 0.304\n",
      "\n",
      "n_iter: 460/1000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.121, critic: 0.168, entropy: -2.067, ae: 0.205, lstm: 1.773\n",
      "Average reward: 0.328\n",
      "\n",
      "n_iter: 470/1000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.096, critic: 0.160, entropy: -2.063, ae: 0.203, lstm: 1.762\n",
      "Average reward: 0.315\n",
      "\n",
      "n_iter: 480/1000, grad norm: 0.003. Training block: ae\n",
      "actor: -0.023, critic: 0.164, entropy: -2.062, ae: 0.197, lstm: 1.809\n",
      "Average reward: 0.289\n",
      "\n",
      "n_iter: 490/1000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.029, critic: 0.146, entropy: -2.061, ae: 0.185, lstm: 1.822\n",
      "Average reward: 0.290\n",
      "\n",
      "n_iter: 500/1000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.098, critic: 0.159, entropy: -2.066, ae: 0.191, lstm: 1.782\n",
      "Average reward: 0.311\n",
      "\n",
      "n_iter: 510/1000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.018, critic: 0.170, entropy: -2.065, ae: 0.178, lstm: 1.814\n",
      "Average reward: 0.291\n",
      "\n",
      "n_iter: 520/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.095, critic: 0.154, entropy: -2.062, ae: 0.183, lstm: 1.773\n",
      "Average reward: 0.315\n",
      "\n",
      "n_iter: 530/1000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.066, critic: 0.169, entropy: -2.074, ae: 0.179, lstm: 1.782\n",
      "Average reward: 0.307\n",
      "\n",
      "n_iter: 540/1000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.011, critic: 0.145, entropy: -2.066, ae: 0.184, lstm: 1.830\n",
      "Average reward: 0.288\n",
      "\n",
      "n_iter: 550/1000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.076, critic: 0.151, entropy: -2.057, ae: 0.169, lstm: 1.807\n",
      "Average reward: 0.297\n",
      "\n",
      "n_iter: 560/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.101, critic: 0.144, entropy: -2.069, ae: 0.169, lstm: 1.790\n",
      "Average reward: 0.311\n",
      "\n",
      "n_iter: 570/1000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.077, critic: 0.159, entropy: -2.065, ae: 0.167, lstm: 1.819\n",
      "Average reward: 0.304\n",
      "\n",
      "n_iter: 580/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.051, critic: 0.170, entropy: -2.076, ae: 0.170, lstm: 1.788\n",
      "Average reward: 0.304\n",
      "\n",
      "n_iter: 590/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.088, critic: 0.144, entropy: -2.066, ae: 0.159, lstm: 1.832\n",
      "Average reward: 0.307\n",
      "\n",
      "n_iter: 600/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.127, critic: 0.139, entropy: -2.068, ae: 0.159, lstm: 1.823\n",
      "Average reward: 0.314\n",
      "\n",
      "n_iter: 610/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.083, critic: 0.172, entropy: -2.061, ae: 0.154, lstm: 1.810\n",
      "Average reward: 0.301\n",
      "\n",
      "n_iter: 620/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.115, critic: 0.155, entropy: -2.063, ae: 0.155, lstm: 1.843\n",
      "Average reward: 0.311\n",
      "\n",
      "n_iter: 630/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.096, critic: 0.150, entropy: -2.064, ae: 0.156, lstm: 1.810\n",
      "Average reward: 0.312\n",
      "\n",
      "n_iter: 640/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.129, critic: 0.146, entropy: -2.065, ae: 0.152, lstm: 1.822\n",
      "Average reward: 0.320\n",
      "\n",
      "n_iter: 650/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.109, critic: 0.148, entropy: -2.064, ae: 0.152, lstm: 1.833\n",
      "Average reward: 0.313\n",
      "\n",
      "n_iter: 660/1000, grad norm: 0.002. Training block: ae\n",
      "actor: -0.059, critic: 0.167, entropy: -2.061, ae: 0.155, lstm: 1.853\n",
      "Average reward: 0.302\n",
      "\n",
      "n_iter: 670/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.113, critic: 0.137, entropy: -2.060, ae: 0.143, lstm: 1.811\n",
      "Average reward: 0.310\n",
      "\n",
      "n_iter: 680/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.046, critic: 0.144, entropy: -2.072, ae: 0.147, lstm: 1.822\n",
      "Average reward: 0.286\n",
      "\n",
      "n_iter: 690/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.147, critic: 0.154, entropy: -2.063, ae: 0.146, lstm: 1.819\n",
      "Average reward: 0.324\n",
      "\n",
      "n_iter: 700/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.099, critic: 0.154, entropy: -2.073, ae: 0.140, lstm: 1.836\n",
      "Average reward: 0.307\n",
      "\n",
      "n_iter: 710/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.067, critic: 0.127, entropy: -2.069, ae: 0.137, lstm: 1.829\n",
      "Average reward: 0.294\n",
      "\n",
      "n_iter: 720/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.128, critic: 0.140, entropy: -2.065, ae: 0.139, lstm: 1.840\n",
      "Average reward: 0.320\n",
      "\n",
      "n_iter: 730/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.128, critic: 0.146, entropy: -2.070, ae: 0.136, lstm: 1.841\n",
      "Average reward: 0.323\n",
      "\n",
      "n_iter: 740/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.121, critic: 0.152, entropy: -2.063, ae: 0.133, lstm: 1.844\n",
      "Average reward: 0.319\n",
      "\n",
      "n_iter: 750/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.043, critic: 0.143, entropy: -2.067, ae: 0.136, lstm: 1.846\n",
      "Average reward: 0.286\n",
      "\n",
      "n_iter: 760/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.099, critic: 0.138, entropy: -2.059, ae: 0.137, lstm: 1.837\n",
      "Average reward: 0.303\n",
      "\n",
      "n_iter: 770/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.080, critic: 0.149, entropy: -2.054, ae: 0.127, lstm: 1.898\n",
      "Average reward: 0.302\n",
      "\n",
      "n_iter: 780/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.077, critic: 0.137, entropy: -2.066, ae: 0.137, lstm: 1.861\n",
      "Average reward: 0.290\n",
      "\n",
      "n_iter: 790/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.029, critic: 0.140, entropy: -2.070, ae: 0.128, lstm: 1.850\n",
      "Average reward: 0.285\n",
      "\n",
      "n_iter: 800/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.096, critic: 0.137, entropy: -2.062, ae: 0.131, lstm: 1.856\n",
      "Average reward: 0.310\n",
      "\n",
      "n_iter: 810/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.132, critic: 0.151, entropy: -2.061, ae: 0.131, lstm: 1.837\n",
      "Average reward: 0.317\n",
      "\n",
      "n_iter: 820/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.124, critic: 0.143, entropy: -2.061, ae: 0.128, lstm: 1.846\n",
      "Average reward: 0.312\n",
      "\n",
      "n_iter: 830/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.125, critic: 0.143, entropy: -2.065, ae: 0.126, lstm: 1.858\n",
      "Average reward: 0.314\n",
      "\n",
      "n_iter: 840/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.120, critic: 0.159, entropy: -2.064, ae: 0.127, lstm: 1.862\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 850/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.144, critic: 0.143, entropy: -2.068, ae: 0.129, lstm: 1.849\n",
      "Average reward: 0.320\n",
      "\n",
      "n_iter: 860/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.134, critic: 0.137, entropy: -2.066, ae: 0.125, lstm: 1.875\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 870/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.058, critic: 0.130, entropy: -2.064, ae: 0.127, lstm: 1.847\n",
      "Average reward: 0.301\n",
      "\n",
      "n_iter: 880/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.100, critic: 0.157, entropy: -2.062, ae: 0.123, lstm: 1.861\n",
      "Average reward: 0.306\n",
      "\n",
      "n_iter: 890/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.139, critic: 0.150, entropy: -2.065, ae: 0.123, lstm: 1.854\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 900/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.154, critic: 0.154, entropy: -2.074, ae: 0.125, lstm: 1.857\n",
      "Average reward: 0.326\n",
      "\n",
      "n_iter: 910/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.110, critic: 0.144, entropy: -2.064, ae: 0.122, lstm: 1.872\n",
      "Average reward: 0.305\n",
      "\n",
      "n_iter: 920/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.086, critic: 0.124, entropy: -2.061, ae: 0.124, lstm: 1.868\n",
      "Average reward: 0.293\n",
      "\n",
      "n_iter: 930/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.117, critic: 0.145, entropy: -2.057, ae: 0.120, lstm: 1.892\n",
      "Average reward: 0.309\n",
      "\n",
      "n_iter: 940/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.075, critic: 0.138, entropy: -2.074, ae: 0.125, lstm: 1.888\n",
      "Average reward: 0.292\n",
      "\n",
      "n_iter: 950/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.125, critic: 0.149, entropy: -2.060, ae: 0.121, lstm: 1.860\n",
      "Average reward: 0.315\n",
      "\n",
      "n_iter: 960/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.042, critic: 0.147, entropy: -2.058, ae: 0.122, lstm: 1.900\n",
      "Average reward: 0.283\n",
      "\n",
      "n_iter: 970/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.142, critic: 0.140, entropy: -2.064, ae: 0.118, lstm: 1.876\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 980/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.087, critic: 0.137, entropy: -2.063, ae: 0.118, lstm: 1.879\n",
      "Average reward: 0.293\n",
      "\n",
      "n_iter: 990/1000, grad norm: 0.001. Training block: ae\n",
      "actor: -0.133, critic: 0.145, entropy: -2.073, ae: 0.122, lstm: 1.865\n",
      "Average reward: 0.320\n",
      "\n",
      "n_iter: 0/2000, grad norm: 0.011. Training block: lstm\n",
      "actor: -0.111, critic: 0.138, entropy: -2.062, ae: 0.120, lstm: 1.887\n",
      "Average reward: 0.306\n",
      "\n",
      "n_iter: 10/2000, grad norm: 0.007. Training block: lstm\n",
      "actor: -0.145, critic: 0.143, entropy: -2.061, ae: 0.117, lstm: 1.782\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 20/2000, grad norm: 0.007. Training block: lstm\n",
      "actor: -0.107, critic: 0.151, entropy: -2.067, ae: 0.121, lstm: 1.718\n",
      "Average reward: 0.307\n",
      "\n",
      "n_iter: 30/2000, grad norm: 0.005. Training block: lstm\n",
      "actor: -0.149, critic: 0.147, entropy: -2.065, ae: 0.119, lstm: 1.655\n",
      "Average reward: 0.321\n",
      "\n",
      "n_iter: 40/2000, grad norm: 0.005. Training block: lstm\n",
      "actor: -0.123, critic: 0.143, entropy: -2.074, ae: 0.118, lstm: 1.610\n",
      "Average reward: 0.310\n",
      "\n",
      "n_iter: 50/2000, grad norm: 0.007. Training block: lstm\n",
      "actor: -0.009, critic: 0.150, entropy: -2.042, ae: 0.117, lstm: 1.526\n",
      "Average reward: 0.266\n",
      "\n",
      "n_iter: 60/2000, grad norm: 0.005. Training block: lstm\n",
      "actor: -0.136, critic: 0.142, entropy: -2.069, ae: 0.120, lstm: 1.497\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 70/2000, grad norm: 0.004. Training block: lstm\n",
      "actor: -0.141, critic: 0.157, entropy: -2.073, ae: 0.119, lstm: 1.458\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 80/2000, grad norm: 0.005. Training block: lstm\n",
      "actor: -0.113, critic: 0.166, entropy: -2.060, ae: 0.113, lstm: 1.398\n",
      "Average reward: 0.312\n",
      "\n",
      "n_iter: 90/2000, grad norm: 0.004. Training block: lstm\n",
      "actor: -0.113, critic: 0.145, entropy: -2.071, ae: 0.118, lstm: 1.350\n",
      "Average reward: 0.307\n",
      "\n",
      "n_iter: 100/2000, grad norm: 0.007. Training block: lstm\n",
      "actor: -0.055, critic: 0.153, entropy: -2.079, ae: 0.119, lstm: 1.332\n",
      "Average reward: 0.284\n",
      "\n",
      "n_iter: 110/2000, grad norm: 0.004. Training block: lstm\n",
      "actor: -0.112, critic: 0.139, entropy: -2.075, ae: 0.118, lstm: 1.316\n",
      "Average reward: 0.306\n",
      "\n",
      "n_iter: 120/2000, grad norm: 0.003. Training block: lstm\n",
      "actor: -0.109, critic: 0.146, entropy: -2.075, ae: 0.118, lstm: 1.258\n",
      "Average reward: 0.309\n",
      "\n",
      "n_iter: 130/2000, grad norm: 0.004. Training block: lstm\n",
      "actor: -0.116, critic: 0.153, entropy: -2.082, ae: 0.124, lstm: 1.252\n",
      "Average reward: 0.314\n",
      "\n",
      "n_iter: 140/2000, grad norm: 0.005. Training block: lstm\n",
      "actor: -0.051, critic: 0.133, entropy: -2.065, ae: 0.121, lstm: 1.173\n",
      "Average reward: 0.285\n",
      "\n",
      "n_iter: 150/2000, grad norm: 0.003. Training block: lstm\n",
      "actor: -0.119, critic: 0.160, entropy: -2.077, ae: 0.116, lstm: 1.200\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 160/2000, grad norm: 0.003. Training block: lstm\n",
      "actor: -0.073, critic: 0.149, entropy: -2.076, ae: 0.117, lstm: 1.147\n",
      "Average reward: 0.299\n",
      "\n",
      "n_iter: 170/2000, grad norm: 0.004. Training block: lstm\n",
      "actor: -0.050, critic: 0.153, entropy: -2.067, ae: 0.115, lstm: 1.126\n",
      "Average reward: 0.289\n",
      "\n",
      "n_iter: 180/2000, grad norm: 0.003. Training block: lstm\n",
      "actor: -0.146, critic: 0.156, entropy: -2.064, ae: 0.117, lstm: 1.131\n",
      "Average reward: 0.319\n",
      "\n",
      "n_iter: 190/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.125, critic: 0.144, entropy: -2.079, ae: 0.119, lstm: 1.109\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 200/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.172, critic: 0.143, entropy: -2.063, ae: 0.120, lstm: 1.080\n",
      "Average reward: 0.329\n",
      "\n",
      "n_iter: 210/2000, grad norm: 0.003. Training block: lstm\n",
      "actor: -0.090, critic: 0.145, entropy: -2.054, ae: 0.116, lstm: 1.022\n",
      "Average reward: 0.294\n",
      "\n",
      "n_iter: 220/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.144, critic: 0.135, entropy: -2.083, ae: 0.122, lstm: 1.058\n",
      "Average reward: 0.321\n",
      "\n",
      "n_iter: 230/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.148, critic: 0.149, entropy: -2.077, ae: 0.117, lstm: 1.034\n",
      "Average reward: 0.320\n",
      "\n",
      "n_iter: 240/2000, grad norm: 0.003. Training block: lstm\n",
      "actor: -0.116, critic: 0.158, entropy: -2.074, ae: 0.118, lstm: 1.007\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 250/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.096, critic: 0.153, entropy: -2.071, ae: 0.123, lstm: 0.977\n",
      "Average reward: 0.301\n",
      "\n",
      "n_iter: 260/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.109, critic: 0.142, entropy: -2.079, ae: 0.117, lstm: 0.962\n",
      "Average reward: 0.308\n",
      "\n",
      "n_iter: 270/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.148, critic: 0.146, entropy: -2.067, ae: 0.122, lstm: 0.974\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 280/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.121, critic: 0.146, entropy: -2.073, ae: 0.118, lstm: 0.933\n",
      "Average reward: 0.308\n",
      "\n",
      "n_iter: 290/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.152, critic: 0.149, entropy: -2.066, ae: 0.118, lstm: 0.954\n",
      "Average reward: 0.320\n",
      "\n",
      "n_iter: 300/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.126, critic: 0.143, entropy: -2.069, ae: 0.119, lstm: 0.908\n",
      "Average reward: 0.310\n",
      "\n",
      "n_iter: 310/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.157, critic: 0.153, entropy: -2.067, ae: 0.118, lstm: 0.921\n",
      "Average reward: 0.323\n",
      "\n",
      "n_iter: 320/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.074, critic: 0.151, entropy: -2.073, ae: 0.118, lstm: 0.852\n",
      "Average reward: 0.298\n",
      "\n",
      "n_iter: 330/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.128, critic: 0.162, entropy: -2.068, ae: 0.119, lstm: 0.875\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 340/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.130, critic: 0.150, entropy: -2.076, ae: 0.117, lstm: 0.867\n",
      "Average reward: 0.314\n",
      "\n",
      "n_iter: 350/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.117, critic: 0.148, entropy: -2.075, ae: 0.116, lstm: 0.856\n",
      "Average reward: 0.311\n",
      "\n",
      "n_iter: 360/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.147, critic: 0.155, entropy: -2.074, ae: 0.119, lstm: 0.854\n",
      "Average reward: 0.319\n",
      "\n",
      "n_iter: 370/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.128, critic: 0.147, entropy: -2.083, ae: 0.119, lstm: 0.841\n",
      "Average reward: 0.315\n",
      "\n",
      "n_iter: 380/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.133, critic: 0.154, entropy: -2.076, ae: 0.116, lstm: 0.831\n",
      "Average reward: 0.312\n",
      "\n",
      "n_iter: 390/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.167, critic: 0.156, entropy: -2.074, ae: 0.120, lstm: 0.835\n",
      "Average reward: 0.328\n",
      "\n",
      "n_iter: 400/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.105, critic: 0.161, entropy: -2.078, ae: 0.116, lstm: 0.773\n",
      "Average reward: 0.310\n",
      "\n",
      "n_iter: 410/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.148, critic: 0.144, entropy: -2.078, ae: 0.118, lstm: 0.818\n",
      "Average reward: 0.319\n",
      "\n",
      "n_iter: 420/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.033, critic: 0.158, entropy: -2.078, ae: 0.120, lstm: 0.707\n",
      "Average reward: 0.288\n",
      "\n",
      "n_iter: 430/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.126, critic: 0.138, entropy: -2.079, ae: 0.121, lstm: 0.781\n",
      "Average reward: 0.312\n",
      "\n",
      "n_iter: 440/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.161, critic: 0.153, entropy: -2.074, ae: 0.118, lstm: 0.783\n",
      "Average reward: 0.331\n",
      "\n",
      "n_iter: 450/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.111, critic: 0.150, entropy: -2.076, ae: 0.119, lstm: 0.745\n",
      "Average reward: 0.310\n",
      "\n",
      "n_iter: 460/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.142, critic: 0.156, entropy: -2.065, ae: 0.121, lstm: 0.750\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 470/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.111, critic: 0.145, entropy: -2.074, ae: 0.119, lstm: 0.731\n",
      "Average reward: 0.310\n",
      "\n",
      "n_iter: 480/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.148, critic: 0.154, entropy: -2.076, ae: 0.115, lstm: 0.739\n",
      "Average reward: 0.319\n",
      "\n",
      "n_iter: 490/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.155, critic: 0.151, entropy: -2.083, ae: 0.118, lstm: 0.748\n",
      "Average reward: 0.324\n",
      "\n",
      "n_iter: 500/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.128, critic: 0.157, entropy: -2.087, ae: 0.120, lstm: 0.731\n",
      "Average reward: 0.319\n",
      "\n",
      "n_iter: 510/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.105, critic: 0.144, entropy: -2.086, ae: 0.116, lstm: 0.720\n",
      "Average reward: 0.301\n",
      "\n",
      "n_iter: 520/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.127, critic: 0.153, entropy: -2.081, ae: 0.116, lstm: 0.714\n",
      "Average reward: 0.314\n",
      "\n",
      "n_iter: 530/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.096, critic: 0.152, entropy: -2.087, ae: 0.117, lstm: 0.656\n",
      "Average reward: 0.308\n",
      "\n",
      "n_iter: 540/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.110, critic: 0.150, entropy: -2.093, ae: 0.119, lstm: 0.651\n",
      "Average reward: 0.312\n",
      "\n",
      "n_iter: 550/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.043, critic: 0.151, entropy: -2.082, ae: 0.122, lstm: 0.599\n",
      "Average reward: 0.284\n",
      "\n",
      "n_iter: 560/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.079, critic: 0.151, entropy: -2.083, ae: 0.126, lstm: 0.638\n",
      "Average reward: 0.299\n",
      "\n",
      "n_iter: 570/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.134, critic: 0.144, entropy: -2.097, ae: 0.117, lstm: 0.672\n",
      "Average reward: 0.314\n",
      "\n",
      "n_iter: 580/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.148, critic: 0.139, entropy: -2.091, ae: 0.119, lstm: 0.680\n",
      "Average reward: 0.321\n",
      "\n",
      "n_iter: 590/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.058, critic: 0.150, entropy: -2.097, ae: 0.125, lstm: 0.590\n",
      "Average reward: 0.290\n",
      "\n",
      "n_iter: 600/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.143, critic: 0.146, entropy: -2.091, ae: 0.118, lstm: 0.667\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 610/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.128, critic: 0.155, entropy: -2.090, ae: 0.116, lstm: 0.644\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 620/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.115, critic: 0.174, entropy: -2.102, ae: 0.116, lstm: 0.603\n",
      "Average reward: 0.320\n",
      "\n",
      "n_iter: 630/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.147, critic: 0.156, entropy: -2.089, ae: 0.116, lstm: 0.656\n",
      "Average reward: 0.320\n",
      "\n",
      "n_iter: 640/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.099, critic: 0.156, entropy: -2.089, ae: 0.116, lstm: 0.612\n",
      "Average reward: 0.310\n",
      "\n",
      "n_iter: 650/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.100, critic: 0.131, entropy: -2.098, ae: 0.118, lstm: 0.587\n",
      "Average reward: 0.300\n",
      "\n",
      "n_iter: 660/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.163, critic: 0.148, entropy: -2.087, ae: 0.118, lstm: 0.638\n",
      "Average reward: 0.322\n",
      "\n",
      "n_iter: 670/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.096, critic: 0.146, entropy: -2.090, ae: 0.118, lstm: 0.585\n",
      "Average reward: 0.299\n",
      "\n",
      "n_iter: 680/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.127, critic: 0.160, entropy: -2.098, ae: 0.118, lstm: 0.628\n",
      "Average reward: 0.315\n",
      "\n",
      "n_iter: 690/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.074, critic: 0.143, entropy: -2.113, ae: 0.117, lstm: 0.572\n",
      "Average reward: 0.293\n",
      "\n",
      "n_iter: 700/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.069, critic: 0.166, entropy: -2.097, ae: 0.119, lstm: 0.553\n",
      "Average reward: 0.300\n",
      "\n",
      "n_iter: 710/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.096, critic: 0.148, entropy: -2.099, ae: 0.114, lstm: 0.574\n",
      "Average reward: 0.301\n",
      "\n",
      "n_iter: 720/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.059, critic: 0.150, entropy: -2.087, ae: 0.118, lstm: 0.500\n",
      "Average reward: 0.299\n",
      "\n",
      "n_iter: 730/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.086, critic: 0.146, entropy: -2.097, ae: 0.118, lstm: 0.577\n",
      "Average reward: 0.290\n",
      "\n",
      "n_iter: 740/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.156, critic: 0.145, entropy: -2.099, ae: 0.120, lstm: 0.621\n",
      "Average reward: 0.322\n",
      "\n",
      "n_iter: 750/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.142, critic: 0.149, entropy: -2.099, ae: 0.120, lstm: 0.593\n",
      "Average reward: 0.325\n",
      "\n",
      "n_iter: 760/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.128, critic: 0.141, entropy: -2.093, ae: 0.119, lstm: 0.601\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 770/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.141, critic: 0.157, entropy: -2.096, ae: 0.122, lstm: 0.593\n",
      "Average reward: 0.314\n",
      "\n",
      "n_iter: 780/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.129, critic: 0.165, entropy: -2.100, ae: 0.119, lstm: 0.567\n",
      "Average reward: 0.322\n",
      "\n",
      "n_iter: 790/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.095, critic: 0.155, entropy: -2.101, ae: 0.118, lstm: 0.545\n",
      "Average reward: 0.304\n",
      "\n",
      "n_iter: 800/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.155, critic: 0.149, entropy: -2.100, ae: 0.120, lstm: 0.590\n",
      "Average reward: 0.322\n",
      "\n",
      "n_iter: 810/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.141, critic: 0.159, entropy: -2.097, ae: 0.117, lstm: 0.576\n",
      "Average reward: 0.319\n",
      "\n",
      "n_iter: 820/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.060, critic: 0.159, entropy: -2.097, ae: 0.117, lstm: 0.525\n",
      "Average reward: 0.294\n",
      "\n",
      "n_iter: 830/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.119, critic: 0.156, entropy: -2.091, ae: 0.120, lstm: 0.553\n",
      "Average reward: 0.314\n",
      "\n",
      "n_iter: 840/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.135, critic: 0.151, entropy: -2.103, ae: 0.119, lstm: 0.579\n",
      "Average reward: 0.311\n",
      "\n",
      "n_iter: 850/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.092, critic: 0.152, entropy: -2.106, ae: 0.118, lstm: 0.511\n",
      "Average reward: 0.315\n",
      "\n",
      "n_iter: 860/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.009, critic: 0.155, entropy: -2.112, ae: 0.119, lstm: 0.468\n",
      "Average reward: 0.279\n",
      "\n",
      "n_iter: 870/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.088, critic: 0.181, entropy: -2.091, ae: 0.124, lstm: 0.518\n",
      "Average reward: 0.312\n",
      "\n",
      "n_iter: 880/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.145, critic: 0.154, entropy: -2.091, ae: 0.120, lstm: 0.561\n",
      "Average reward: 0.319\n",
      "\n",
      "n_iter: 890/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.146, critic: 0.158, entropy: -2.087, ae: 0.117, lstm: 0.559\n",
      "Average reward: 0.317\n",
      "\n",
      "n_iter: 900/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.040, critic: 0.146, entropy: -2.114, ae: 0.118, lstm: 0.473\n",
      "Average reward: 0.282\n",
      "\n",
      "n_iter: 910/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.061, critic: 0.155, entropy: -2.091, ae: 0.120, lstm: 0.493\n",
      "Average reward: 0.290\n",
      "\n",
      "n_iter: 920/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.143, critic: 0.146, entropy: -2.095, ae: 0.119, lstm: 0.538\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 930/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.108, critic: 0.155, entropy: -2.110, ae: 0.120, lstm: 0.510\n",
      "Average reward: 0.308\n",
      "\n",
      "n_iter: 940/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.121, critic: 0.143, entropy: -2.094, ae: 0.120, lstm: 0.525\n",
      "Average reward: 0.307\n",
      "\n",
      "n_iter: 950/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.138, critic: 0.163, entropy: -2.085, ae: 0.122, lstm: 0.534\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 960/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.133, critic: 0.158, entropy: -2.101, ae: 0.119, lstm: 0.531\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 970/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.154, critic: 0.135, entropy: -2.094, ae: 0.116, lstm: 0.541\n",
      "Average reward: 0.320\n",
      "\n",
      "n_iter: 980/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: 0.005, critic: 0.159, entropy: -2.088, ae: 0.117, lstm: 0.444\n",
      "Average reward: 0.267\n",
      "\n",
      "n_iter: 990/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.150, critic: 0.142, entropy: -2.093, ae: 0.122, lstm: 0.547\n",
      "Average reward: 0.321\n",
      "\n",
      "n_iter: 1000/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.124, critic: 0.164, entropy: -2.086, ae: 0.118, lstm: 0.515\n",
      "Average reward: 0.310\n",
      "\n",
      "n_iter: 1010/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.167, critic: 0.157, entropy: -2.088, ae: 0.119, lstm: 0.533\n",
      "Average reward: 0.329\n",
      "\n",
      "n_iter: 1020/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.119, critic: 0.144, entropy: -2.094, ae: 0.121, lstm: 0.521\n",
      "Average reward: 0.308\n",
      "\n",
      "n_iter: 1030/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.119, critic: 0.141, entropy: -2.097, ae: 0.119, lstm: 0.516\n",
      "Average reward: 0.312\n",
      "\n",
      "n_iter: 1040/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.143, critic: 0.147, entropy: -2.093, ae: 0.115, lstm: 0.528\n",
      "Average reward: 0.320\n",
      "\n",
      "n_iter: 1050/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.138, critic: 0.150, entropy: -2.093, ae: 0.118, lstm: 0.520\n",
      "Average reward: 0.315\n",
      "\n",
      "n_iter: 1060/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.024, critic: 0.133, entropy: -2.084, ae: 0.118, lstm: 0.423\n",
      "Average reward: 0.267\n",
      "\n",
      "n_iter: 1070/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.080, critic: 0.153, entropy: -2.095, ae: 0.122, lstm: 0.477\n",
      "Average reward: 0.299\n",
      "\n",
      "n_iter: 1080/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.156, critic: 0.153, entropy: -2.089, ae: 0.119, lstm: 0.509\n",
      "Average reward: 0.319\n",
      "\n",
      "n_iter: 1090/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.115, critic: 0.136, entropy: -2.089, ae: 0.119, lstm: 0.467\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 1100/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.154, critic: 0.156, entropy: -2.080, ae: 0.118, lstm: 0.517\n",
      "Average reward: 0.326\n",
      "\n",
      "n_iter: 1110/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.134, critic: 0.149, entropy: -2.086, ae: 0.117, lstm: 0.515\n",
      "Average reward: 0.313\n",
      "\n",
      "n_iter: 1120/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.051, critic: 0.162, entropy: -2.082, ae: 0.121, lstm: 0.428\n",
      "Average reward: 0.291\n",
      "\n",
      "n_iter: 1130/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.034, critic: 0.160, entropy: -2.094, ae: 0.117, lstm: 0.432\n",
      "Average reward: 0.287\n",
      "\n",
      "n_iter: 1140/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.151, critic: 0.146, entropy: -2.091, ae: 0.119, lstm: 0.513\n",
      "Average reward: 0.320\n",
      "\n",
      "n_iter: 1150/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.133, critic: 0.147, entropy: -2.082, ae: 0.119, lstm: 0.501\n",
      "Average reward: 0.314\n",
      "\n",
      "n_iter: 1160/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.145, critic: 0.156, entropy: -2.083, ae: 0.118, lstm: 0.519\n",
      "Average reward: 0.320\n",
      "\n",
      "n_iter: 1170/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.151, critic: 0.171, entropy: -2.083, ae: 0.123, lstm: 0.497\n",
      "Average reward: 0.321\n",
      "\n",
      "n_iter: 1180/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.126, critic: 0.150, entropy: -2.088, ae: 0.115, lstm: 0.498\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 1190/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.158, critic: 0.149, entropy: -2.088, ae: 0.118, lstm: 0.513\n",
      "Average reward: 0.326\n",
      "\n",
      "n_iter: 1200/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.097, critic: 0.155, entropy: -2.083, ae: 0.115, lstm: 0.467\n",
      "Average reward: 0.306\n",
      "\n",
      "n_iter: 1210/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.108, critic: 0.149, entropy: -2.088, ae: 0.118, lstm: 0.426\n",
      "Average reward: 0.310\n",
      "\n",
      "n_iter: 1220/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.148, critic: 0.161, entropy: -2.083, ae: 0.118, lstm: 0.504\n",
      "Average reward: 0.322\n",
      "\n",
      "n_iter: 1230/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.161, critic: 0.151, entropy: -2.086, ae: 0.123, lstm: 0.495\n",
      "Average reward: 0.328\n",
      "\n",
      "n_iter: 1240/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.156, critic: 0.155, entropy: -2.087, ae: 0.120, lstm: 0.499\n",
      "Average reward: 0.327\n",
      "\n",
      "n_iter: 1250/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.078, critic: 0.166, entropy: -2.064, ae: 0.114, lstm: 0.421\n",
      "Average reward: 0.300\n",
      "\n",
      "n_iter: 1260/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.154, critic: 0.152, entropy: -2.087, ae: 0.119, lstm: 0.498\n",
      "Average reward: 0.327\n",
      "\n",
      "n_iter: 1270/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.091, critic: 0.145, entropy: -2.084, ae: 0.115, lstm: 0.451\n",
      "Average reward: 0.296\n",
      "\n",
      "n_iter: 1280/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.096, critic: 0.155, entropy: -2.088, ae: 0.118, lstm: 0.437\n",
      "Average reward: 0.304\n",
      "\n",
      "n_iter: 1290/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.144, critic: 0.146, entropy: -2.078, ae: 0.117, lstm: 0.486\n",
      "Average reward: 0.317\n",
      "\n",
      "n_iter: 1300/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.137, critic: 0.153, entropy: -2.077, ae: 0.118, lstm: 0.483\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 1310/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.108, critic: 0.149, entropy: -2.078, ae: 0.119, lstm: 0.450\n",
      "Average reward: 0.314\n",
      "\n",
      "n_iter: 1320/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.146, critic: 0.153, entropy: -2.082, ae: 0.118, lstm: 0.485\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 1330/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.142, critic: 0.149, entropy: -2.078, ae: 0.125, lstm: 0.481\n",
      "Average reward: 0.325\n",
      "\n",
      "n_iter: 1340/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.031, critic: 0.152, entropy: -2.073, ae: 0.120, lstm: 0.376\n",
      "Average reward: 0.272\n",
      "\n",
      "n_iter: 1350/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.048, critic: 0.144, entropy: -2.072, ae: 0.117, lstm: 0.374\n",
      "Average reward: 0.287\n",
      "\n",
      "n_iter: 1360/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.140, critic: 0.169, entropy: -2.085, ae: 0.120, lstm: 0.454\n",
      "Average reward: 0.329\n",
      "\n",
      "n_iter: 1370/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.136, critic: 0.156, entropy: -2.070, ae: 0.121, lstm: 0.456\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 1380/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.104, critic: 0.158, entropy: -2.078, ae: 0.119, lstm: 0.452\n",
      "Average reward: 0.305\n",
      "\n",
      "n_iter: 1390/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.138, critic: 0.153, entropy: -2.088, ae: 0.118, lstm: 0.480\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 1400/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.119, critic: 0.152, entropy: -2.077, ae: 0.127, lstm: 0.445\n",
      "Average reward: 0.321\n",
      "\n",
      "n_iter: 1410/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.138, critic: 0.155, entropy: -2.083, ae: 0.121, lstm: 0.475\n",
      "Average reward: 0.319\n",
      "\n",
      "n_iter: 1420/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.141, critic: 0.150, entropy: -2.078, ae: 0.118, lstm: 0.476\n",
      "Average reward: 0.317\n",
      "\n",
      "n_iter: 1430/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.141, critic: 0.142, entropy: -2.084, ae: 0.118, lstm: 0.472\n",
      "Average reward: 0.313\n",
      "\n",
      "n_iter: 1440/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.090, critic: 0.155, entropy: -2.081, ae: 0.116, lstm: 0.420\n",
      "Average reward: 0.301\n",
      "\n",
      "n_iter: 1450/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.146, critic: 0.154, entropy: -2.077, ae: 0.117, lstm: 0.464\n",
      "Average reward: 0.323\n",
      "\n",
      "n_iter: 1460/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.119, critic: 0.158, entropy: -2.079, ae: 0.116, lstm: 0.451\n",
      "Average reward: 0.313\n",
      "\n",
      "n_iter: 1470/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.110, critic: 0.133, entropy: -2.074, ae: 0.121, lstm: 0.437\n",
      "Average reward: 0.302\n",
      "\n",
      "n_iter: 1480/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.098, critic: 0.150, entropy: -2.067, ae: 0.121, lstm: 0.426\n",
      "Average reward: 0.299\n",
      "\n",
      "n_iter: 1490/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.045, critic: 0.162, entropy: -2.074, ae: 0.117, lstm: 0.375\n",
      "Average reward: 0.281\n",
      "\n",
      "n_iter: 1500/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.121, critic: 0.148, entropy: -2.084, ae: 0.126, lstm: 0.451\n",
      "Average reward: 0.312\n",
      "\n",
      "n_iter: 1510/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.157, critic: 0.143, entropy: -2.074, ae: 0.118, lstm: 0.448\n",
      "Average reward: 0.325\n",
      "\n",
      "n_iter: 1520/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.161, critic: 0.157, entropy: -2.073, ae: 0.121, lstm: 0.456\n",
      "Average reward: 0.328\n",
      "\n",
      "n_iter: 1530/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.129, critic: 0.150, entropy: -2.073, ae: 0.120, lstm: 0.426\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 1540/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.111, critic: 0.142, entropy: -2.079, ae: 0.121, lstm: 0.438\n",
      "Average reward: 0.301\n",
      "\n",
      "n_iter: 1550/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.030, critic: 0.173, entropy: -2.080, ae: 0.109, lstm: 0.354\n",
      "Average reward: 0.282\n",
      "\n",
      "n_iter: 1560/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.112, critic: 0.146, entropy: -2.078, ae: 0.117, lstm: 0.428\n",
      "Average reward: 0.312\n",
      "\n",
      "n_iter: 1570/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.120, critic: 0.137, entropy: -2.077, ae: 0.123, lstm: 0.429\n",
      "Average reward: 0.315\n",
      "\n",
      "n_iter: 1580/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.118, critic: 0.143, entropy: -2.072, ae: 0.118, lstm: 0.447\n",
      "Average reward: 0.309\n",
      "\n",
      "n_iter: 1590/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.090, critic: 0.145, entropy: -2.081, ae: 0.121, lstm: 0.403\n",
      "Average reward: 0.295\n",
      "\n",
      "n_iter: 1600/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.035, critic: 0.150, entropy: -2.075, ae: 0.124, lstm: 0.365\n",
      "Average reward: 0.277\n",
      "\n",
      "n_iter: 1610/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.107, critic: 0.152, entropy: -2.080, ae: 0.120, lstm: 0.390\n",
      "Average reward: 0.306\n",
      "\n",
      "n_iter: 1620/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.155, critic: 0.157, entropy: -2.078, ae: 0.117, lstm: 0.454\n",
      "Average reward: 0.328\n",
      "\n",
      "n_iter: 1630/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.056, critic: 0.168, entropy: -2.066, ae: 0.113, lstm: 0.359\n",
      "Average reward: 0.290\n",
      "\n",
      "n_iter: 1640/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.095, critic: 0.141, entropy: -2.079, ae: 0.118, lstm: 0.407\n",
      "Average reward: 0.303\n",
      "\n",
      "n_iter: 1650/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.146, critic: 0.138, entropy: -2.077, ae: 0.118, lstm: 0.427\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 1660/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.102, critic: 0.160, entropy: -2.068, ae: 0.119, lstm: 0.408\n",
      "Average reward: 0.302\n",
      "\n",
      "n_iter: 1670/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.063, critic: 0.161, entropy: -2.071, ae: 0.117, lstm: 0.386\n",
      "Average reward: 0.282\n",
      "\n",
      "n_iter: 1680/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.104, critic: 0.157, entropy: -2.072, ae: 0.115, lstm: 0.404\n",
      "Average reward: 0.299\n",
      "\n",
      "n_iter: 1690/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.030, critic: 0.167, entropy: -2.075, ae: 0.112, lstm: 0.343\n",
      "Average reward: 0.278\n",
      "\n",
      "n_iter: 1700/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.142, critic: 0.151, entropy: -2.071, ae: 0.117, lstm: 0.421\n",
      "Average reward: 0.323\n",
      "\n",
      "n_iter: 1710/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.164, critic: 0.142, entropy: -2.072, ae: 0.120, lstm: 0.432\n",
      "Average reward: 0.325\n",
      "\n",
      "n_iter: 1720/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.147, critic: 0.149, entropy: -2.070, ae: 0.117, lstm: 0.418\n",
      "Average reward: 0.322\n",
      "\n",
      "n_iter: 1730/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.073, critic: 0.155, entropy: -2.066, ae: 0.118, lstm: 0.394\n",
      "Average reward: 0.295\n",
      "\n",
      "n_iter: 1740/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.112, critic: 0.152, entropy: -2.069, ae: 0.118, lstm: 0.402\n",
      "Average reward: 0.309\n",
      "\n",
      "n_iter: 1750/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.130, critic: 0.159, entropy: -2.067, ae: 0.111, lstm: 0.399\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 1760/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.133, critic: 0.165, entropy: -2.069, ae: 0.117, lstm: 0.424\n",
      "Average reward: 0.315\n",
      "\n",
      "n_iter: 1770/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.063, critic: 0.144, entropy: -2.089, ae: 0.127, lstm: 0.374\n",
      "Average reward: 0.301\n",
      "\n",
      "n_iter: 1780/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.015, critic: 0.142, entropy: -2.075, ae: 0.119, lstm: 0.334\n",
      "Average reward: 0.270\n",
      "\n",
      "n_iter: 1790/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.033, critic: 0.147, entropy: -2.076, ae: 0.123, lstm: 0.338\n",
      "Average reward: 0.284\n",
      "\n",
      "n_iter: 1800/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.136, critic: 0.142, entropy: -2.070, ae: 0.120, lstm: 0.415\n",
      "Average reward: 0.319\n",
      "\n",
      "n_iter: 1810/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.142, critic: 0.157, entropy: -2.068, ae: 0.120, lstm: 0.402\n",
      "Average reward: 0.325\n",
      "\n",
      "n_iter: 1820/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.153, critic: 0.152, entropy: -2.075, ae: 0.114, lstm: 0.412\n",
      "Average reward: 0.324\n",
      "\n",
      "n_iter: 1830/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.089, critic: 0.148, entropy: -2.070, ae: 0.119, lstm: 0.381\n",
      "Average reward: 0.298\n",
      "\n",
      "n_iter: 1840/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.135, critic: 0.143, entropy: -2.072, ae: 0.119, lstm: 0.404\n",
      "Average reward: 0.317\n",
      "\n",
      "n_iter: 1850/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.123, critic: 0.174, entropy: -2.066, ae: 0.119, lstm: 0.370\n",
      "Average reward: 0.322\n",
      "\n",
      "n_iter: 1860/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.142, critic: 0.153, entropy: -2.071, ae: 0.120, lstm: 0.414\n",
      "Average reward: 0.319\n",
      "\n",
      "n_iter: 1870/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.122, critic: 0.155, entropy: -2.067, ae: 0.118, lstm: 0.397\n",
      "Average reward: 0.314\n",
      "\n",
      "n_iter: 1880/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.146, critic: 0.155, entropy: -2.076, ae: 0.118, lstm: 0.405\n",
      "Average reward: 0.319\n",
      "\n",
      "n_iter: 1890/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.130, critic: 0.140, entropy: -2.074, ae: 0.119, lstm: 0.397\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 1900/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.136, critic: 0.145, entropy: -2.072, ae: 0.122, lstm: 0.407\n",
      "Average reward: 0.314\n",
      "\n",
      "n_iter: 1910/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.137, critic: 0.154, entropy: -2.071, ae: 0.122, lstm: 0.420\n",
      "Average reward: 0.317\n",
      "\n",
      "n_iter: 1920/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.096, critic: 0.148, entropy: -2.071, ae: 0.115, lstm: 0.371\n",
      "Average reward: 0.300\n",
      "\n",
      "n_iter: 1930/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.169, critic: 0.159, entropy: -2.065, ae: 0.121, lstm: 0.414\n",
      "Average reward: 0.328\n",
      "\n",
      "n_iter: 1940/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.144, critic: 0.150, entropy: -2.065, ae: 0.120, lstm: 0.398\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 1950/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.147, critic: 0.148, entropy: -2.067, ae: 0.118, lstm: 0.394\n",
      "Average reward: 0.322\n",
      "\n",
      "n_iter: 1960/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.145, critic: 0.153, entropy: -2.066, ae: 0.118, lstm: 0.396\n",
      "Average reward: 0.313\n",
      "\n",
      "n_iter: 1970/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.157, critic: 0.156, entropy: -2.070, ae: 0.118, lstm: 0.408\n",
      "Average reward: 0.324\n",
      "\n",
      "n_iter: 1980/2000, grad norm: 0.001. Training block: lstm\n",
      "actor: -0.064, critic: 0.147, entropy: -2.067, ae: 0.116, lstm: 0.350\n",
      "Average reward: 0.283\n",
      "\n",
      "n_iter: 1990/2000, grad norm: 0.002. Training block: lstm\n",
      "actor: -0.060, critic: 0.154, entropy: -2.063, ae: 0.119, lstm: 0.329\n",
      "Average reward: 0.288\n",
      "\n",
      "n_iter: 0/2000, grad norm: 0.036. Training block: actor\n",
      "actor: -0.062, critic: 0.145, entropy: -2.096, ae: 0.119, lstm: 0.330\n",
      "Average reward: 0.293\n",
      "\n",
      "n_iter: 10/2000, grad norm: 0.060. Training block: critic\n",
      "actor: -0.125, critic: 0.135, entropy: -2.080, ae: 0.119, lstm: 0.384\n",
      "Average reward: 0.317\n",
      "\n",
      "n_iter: 20/2000, grad norm: 0.041. Training block: actor\n",
      "actor: -0.135, critic: 0.133, entropy: -2.089, ae: 0.120, lstm: 0.388\n",
      "Average reward: 0.322\n",
      "\n",
      "n_iter: 30/2000, grad norm: 0.020. Training block: actor\n",
      "actor: -0.114, critic: 0.135, entropy: -2.106, ae: 0.120, lstm: 0.384\n",
      "Average reward: 0.315\n",
      "\n",
      "n_iter: 40/2000, grad norm: 0.056. Training block: critic\n",
      "actor: -0.108, critic: 0.118, entropy: -2.102, ae: 0.116, lstm: 0.370\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 50/2000, grad norm: 0.035. Training block: actor\n",
      "actor: -0.121, critic: 0.115, entropy: -2.112, ae: 0.120, lstm: 0.381\n",
      "Average reward: 0.335\n",
      "\n",
      "n_iter: 60/2000, grad norm: 0.053. Training block: critic\n",
      "actor: -0.086, critic: 0.112, entropy: -2.109, ae: 0.115, lstm: 0.357\n",
      "Average reward: 0.316\n",
      "\n",
      "n_iter: 70/2000, grad norm: 0.035. Training block: critic\n",
      "actor: -0.005, critic: 0.115, entropy: -2.127, ae: 0.112, lstm: 0.299\n",
      "Average reward: 0.290\n",
      "\n",
      "n_iter: 80/2000, grad norm: 0.035. Training block: actor\n",
      "actor: -0.145, critic: 0.115, entropy: -2.130, ae: 0.121, lstm: 0.397\n",
      "Average reward: 0.347\n",
      "\n",
      "n_iter: 90/2000, grad norm: 0.035. Training block: actor\n",
      "actor: -0.040, critic: 0.131, entropy: -2.145, ae: 0.122, lstm: 0.348\n",
      "Average reward: 0.311\n",
      "\n",
      "n_iter: 100/2000, grad norm: 0.049. Training block: critic\n",
      "actor: -0.121, critic: 0.114, entropy: -2.146, ae: 0.116, lstm: 0.379\n",
      "Average reward: 0.337\n",
      "\n",
      "n_iter: 110/2000, grad norm: 0.033. Training block: actor\n",
      "actor: -0.109, critic: 0.114, entropy: -2.148, ae: 0.120, lstm: 0.378\n",
      "Average reward: 0.339\n",
      "\n",
      "n_iter: 120/2000, grad norm: 0.033. Training block: critic\n",
      "actor: -0.080, critic: 0.112, entropy: -2.153, ae: 0.118, lstm: 0.363\n",
      "Average reward: 0.323\n",
      "\n",
      "n_iter: 130/2000, grad norm: 0.033. Training block: critic\n",
      "actor: -0.010, critic: 0.120, entropy: -2.163, ae: 0.117, lstm: 0.308\n",
      "Average reward: 0.315\n",
      "\n",
      "n_iter: 140/2000, grad norm: 0.050. Training block: critic\n",
      "actor: -0.033, critic: 0.115, entropy: -2.168, ae: 0.118, lstm: 0.318\n",
      "Average reward: 0.320\n",
      "\n",
      "n_iter: 150/2000, grad norm: 0.017. Training block: actor\n",
      "actor: -0.111, critic: 0.119, entropy: -2.167, ae: 0.121, lstm: 0.362\n",
      "Average reward: 0.352\n",
      "\n",
      "n_iter: 160/2000, grad norm: 0.032. Training block: critic\n",
      "actor: -0.132, critic: 0.106, entropy: -2.172, ae: 0.116, lstm: 0.400\n",
      "Average reward: 0.357\n",
      "\n",
      "n_iter: 170/2000, grad norm: 0.033. Training block: actor\n",
      "actor: -0.005, critic: 0.129, entropy: -2.193, ae: 0.114, lstm: 0.308\n",
      "Average reward: 0.320\n",
      "\n",
      "n_iter: 180/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.121, critic: 0.106, entropy: -2.178, ae: 0.118, lstm: 0.392\n",
      "Average reward: 0.358\n",
      "\n",
      "n_iter: 190/2000, grad norm: 0.032. Training block: critic\n",
      "actor: -0.098, critic: 0.115, entropy: -2.185, ae: 0.120, lstm: 0.369\n",
      "Average reward: 0.352\n",
      "\n",
      "n_iter: 200/2000, grad norm: 0.048. Training block: critic\n",
      "actor: -0.119, critic: 0.108, entropy: -2.184, ae: 0.117, lstm: 0.381\n",
      "Average reward: 0.356\n",
      "\n",
      "n_iter: 210/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.120, critic: 0.109, entropy: -2.188, ae: 0.118, lstm: 0.388\n",
      "Average reward: 0.359\n",
      "\n",
      "n_iter: 220/2000, grad norm: 0.047. Training block: critic\n",
      "actor: -0.051, critic: 0.123, entropy: -2.192, ae: 0.121, lstm: 0.356\n",
      "Average reward: 0.336\n",
      "\n",
      "n_iter: 230/2000, grad norm: 0.032. Training block: critic\n",
      "actor: -0.063, critic: 0.107, entropy: -2.198, ae: 0.117, lstm: 0.352\n",
      "Average reward: 0.344\n",
      "\n",
      "n_iter: 240/2000, grad norm: 0.032. Training block: actor\n",
      "actor: -0.002, critic: 0.115, entropy: -2.200, ae: 0.126, lstm: 0.339\n",
      "Average reward: 0.318\n",
      "\n",
      "n_iter: 250/2000, grad norm: 0.031. Training block: actor\n",
      "actor: -0.093, critic: 0.099, entropy: -2.199, ae: 0.119, lstm: 0.380\n",
      "Average reward: 0.350\n",
      "\n",
      "n_iter: 260/2000, grad norm: 0.017. Training block: actor\n",
      "actor: -0.035, critic: 0.106, entropy: -2.207, ae: 0.121, lstm: 0.361\n",
      "Average reward: 0.332\n",
      "\n",
      "n_iter: 270/2000, grad norm: 0.046. Training block: critic\n",
      "actor: -0.093, critic: 0.101, entropy: -2.212, ae: 0.120, lstm: 0.394\n",
      "Average reward: 0.351\n",
      "\n",
      "n_iter: 280/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.082, critic: 0.110, entropy: -2.220, ae: 0.117, lstm: 0.377\n",
      "Average reward: 0.352\n",
      "\n",
      "n_iter: 290/2000, grad norm: 0.031. Training block: actor\n",
      "actor: -0.093, critic: 0.109, entropy: -2.222, ae: 0.118, lstm: 0.377\n",
      "Average reward: 0.362\n",
      "\n",
      "n_iter: 300/2000, grad norm: 0.031. Training block: critic\n",
      "actor: -0.120, critic: 0.104, entropy: -2.221, ae: 0.122, lstm: 0.398\n",
      "Average reward: 0.374\n",
      "\n",
      "n_iter: 310/2000, grad norm: 0.031. Training block: actor\n",
      "actor: -0.015, critic: 0.130, entropy: -2.231, ae: 0.114, lstm: 0.324\n",
      "Average reward: 0.334\n",
      "\n",
      "n_iter: 320/2000, grad norm: 0.048. Training block: critic\n",
      "actor: -0.023, critic: 0.125, entropy: -2.233, ae: 0.117, lstm: 0.326\n",
      "Average reward: 0.335\n",
      "\n",
      "n_iter: 330/2000, grad norm: 0.046. Training block: critic\n",
      "actor: 0.014, critic: 0.116, entropy: -2.238, ae: 0.115, lstm: 0.307\n",
      "Average reward: 0.325\n",
      "\n",
      "n_iter: 340/2000, grad norm: 0.032. Training block: actor\n",
      "actor: -0.053, critic: 0.128, entropy: -2.232, ae: 0.125, lstm: 0.344\n",
      "Average reward: 0.348\n",
      "\n",
      "n_iter: 350/2000, grad norm: 0.031. Training block: critic\n",
      "actor: -0.086, critic: 0.105, entropy: -2.236, ae: 0.121, lstm: 0.388\n",
      "Average reward: 0.357\n",
      "\n",
      "n_iter: 360/2000, grad norm: 0.031. Training block: actor\n",
      "actor: -0.089, critic: 0.106, entropy: -2.247, ae: 0.118, lstm: 0.395\n",
      "Average reward: 0.364\n",
      "\n",
      "n_iter: 370/2000, grad norm: 0.047. Training block: critic\n",
      "actor: 0.027, critic: 0.124, entropy: -2.251, ae: 0.116, lstm: 0.310\n",
      "Average reward: 0.319\n",
      "\n",
      "n_iter: 380/2000, grad norm: 0.031. Training block: actor\n",
      "actor: -0.072, critic: 0.106, entropy: -2.251, ae: 0.122, lstm: 0.378\n",
      "Average reward: 0.358\n",
      "\n",
      "n_iter: 390/2000, grad norm: 0.046. Training block: critic\n",
      "actor: -0.082, critic: 0.114, entropy: -2.251, ae: 0.112, lstm: 0.354\n",
      "Average reward: 0.367\n",
      "\n",
      "n_iter: 400/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.081, critic: 0.103, entropy: -2.251, ae: 0.118, lstm: 0.390\n",
      "Average reward: 0.361\n",
      "\n",
      "n_iter: 410/2000, grad norm: 0.031. Training block: critic\n",
      "actor: -0.048, critic: 0.128, entropy: -2.258, ae: 0.120, lstm: 0.338\n",
      "Average reward: 0.362\n",
      "\n",
      "n_iter: 420/2000, grad norm: 0.048. Training block: critic\n",
      "actor: 0.026, critic: 0.128, entropy: -2.260, ae: 0.119, lstm: 0.301\n",
      "Average reward: 0.330\n",
      "\n",
      "n_iter: 430/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.076, critic: 0.108, entropy: -2.260, ae: 0.120, lstm: 0.369\n",
      "Average reward: 0.364\n",
      "\n",
      "n_iter: 440/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.113, critic: 0.101, entropy: -2.257, ae: 0.118, lstm: 0.392\n",
      "Average reward: 0.379\n",
      "\n",
      "n_iter: 450/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.072, critic: 0.104, entropy: -2.268, ae: 0.117, lstm: 0.379\n",
      "Average reward: 0.366\n",
      "\n",
      "n_iter: 460/2000, grad norm: 0.046. Training block: critic\n",
      "actor: -0.077, critic: 0.111, entropy: -2.265, ae: 0.119, lstm: 0.380\n",
      "Average reward: 0.372\n",
      "\n",
      "n_iter: 470/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.055, critic: 0.105, entropy: -2.266, ae: 0.119, lstm: 0.379\n",
      "Average reward: 0.359\n",
      "\n",
      "n_iter: 480/2000, grad norm: 0.045. Training block: critic\n",
      "actor: -0.090, critic: 0.099, entropy: -2.266, ae: 0.121, lstm: 0.394\n",
      "Average reward: 0.375\n",
      "\n",
      "n_iter: 490/2000, grad norm: 0.045. Training block: critic\n",
      "actor: -0.097, critic: 0.098, entropy: -2.271, ae: 0.116, lstm: 0.391\n",
      "Average reward: 0.377\n",
      "\n",
      "n_iter: 500/2000, grad norm: 0.047. Training block: critic\n",
      "actor: -0.109, critic: 0.100, entropy: -2.273, ae: 0.119, lstm: 0.400\n",
      "Average reward: 0.387\n",
      "\n",
      "n_iter: 510/2000, grad norm: 0.031. Training block: critic\n",
      "actor: -0.046, critic: 0.114, entropy: -2.269, ae: 0.119, lstm: 0.344\n",
      "Average reward: 0.358\n",
      "\n",
      "n_iter: 520/2000, grad norm: 0.045. Training block: critic\n",
      "actor: -0.053, critic: 0.109, entropy: -2.276, ae: 0.116, lstm: 0.372\n",
      "Average reward: 0.363\n",
      "\n",
      "n_iter: 530/2000, grad norm: 0.045. Training block: critic\n",
      "actor: -0.047, critic: 0.114, entropy: -2.278, ae: 0.120, lstm: 0.363\n",
      "Average reward: 0.362\n",
      "\n",
      "n_iter: 540/2000, grad norm: 0.046. Training block: critic\n",
      "actor: -0.041, critic: 0.112, entropy: -2.279, ae: 0.121, lstm: 0.371\n",
      "Average reward: 0.362\n",
      "\n",
      "n_iter: 550/2000, grad norm: 0.045. Training block: critic\n",
      "actor: -0.043, critic: 0.112, entropy: -2.277, ae: 0.119, lstm: 0.366\n",
      "Average reward: 0.366\n",
      "\n",
      "n_iter: 560/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.071, critic: 0.099, entropy: -2.285, ae: 0.117, lstm: 0.388\n",
      "Average reward: 0.376\n",
      "\n",
      "n_iter: 570/2000, grad norm: 0.031. Training block: actor\n",
      "actor: -0.070, critic: 0.103, entropy: -2.285, ae: 0.118, lstm: 0.384\n",
      "Average reward: 0.377\n",
      "\n",
      "n_iter: 580/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.100, critic: 0.100, entropy: -2.287, ae: 0.117, lstm: 0.397\n",
      "Average reward: 0.390\n",
      "\n",
      "n_iter: 590/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.085, critic: 0.101, entropy: -2.284, ae: 0.117, lstm: 0.387\n",
      "Average reward: 0.383\n",
      "\n",
      "n_iter: 600/2000, grad norm: 0.031. Training block: actor\n",
      "actor: -0.060, critic: 0.108, entropy: -2.289, ae: 0.122, lstm: 0.372\n",
      "Average reward: 0.380\n",
      "\n",
      "n_iter: 610/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.070, critic: 0.106, entropy: -2.294, ae: 0.118, lstm: 0.380\n",
      "Average reward: 0.383\n",
      "\n",
      "n_iter: 620/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.070, critic: 0.103, entropy: -2.294, ae: 0.121, lstm: 0.376\n",
      "Average reward: 0.383\n",
      "\n",
      "n_iter: 630/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.072, critic: 0.119, entropy: -2.296, ae: 0.122, lstm: 0.370\n",
      "Average reward: 0.390\n",
      "\n",
      "n_iter: 640/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.073, critic: 0.107, entropy: -2.293, ae: 0.122, lstm: 0.380\n",
      "Average reward: 0.385\n",
      "\n",
      "n_iter: 650/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.081, critic: 0.109, entropy: -2.296, ae: 0.117, lstm: 0.379\n",
      "Average reward: 0.391\n",
      "\n",
      "n_iter: 660/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.092, critic: 0.104, entropy: -2.298, ae: 0.118, lstm: 0.376\n",
      "Average reward: 0.397\n",
      "\n",
      "n_iter: 670/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.007, critic: 0.133, entropy: -2.297, ae: 0.120, lstm: 0.334\n",
      "Average reward: 0.373\n",
      "\n",
      "n_iter: 680/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.055, critic: 0.103, entropy: -2.297, ae: 0.119, lstm: 0.373\n",
      "Average reward: 0.378\n",
      "\n",
      "n_iter: 690/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.100, critic: 0.099, entropy: -2.303, ae: 0.117, lstm: 0.394\n",
      "Average reward: 0.399\n",
      "\n",
      "n_iter: 700/2000, grad norm: 0.031. Training block: actor\n",
      "actor: 0.032, critic: 0.126, entropy: -2.302, ae: 0.117, lstm: 0.329\n",
      "Average reward: 0.361\n",
      "\n",
      "n_iter: 710/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.083, critic: 0.101, entropy: -2.302, ae: 0.120, lstm: 0.387\n",
      "Average reward: 0.391\n",
      "\n",
      "n_iter: 720/2000, grad norm: 0.044. Training block: critic\n",
      "actor: -0.059, critic: 0.104, entropy: -2.305, ae: 0.116, lstm: 0.373\n",
      "Average reward: 0.387\n",
      "\n",
      "n_iter: 730/2000, grad norm: 0.044. Training block: critic\n",
      "actor: 0.012, critic: 0.126, entropy: -2.298, ae: 0.116, lstm: 0.309\n",
      "Average reward: 0.367\n",
      "\n",
      "n_iter: 740/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.065, critic: 0.108, entropy: -2.307, ae: 0.113, lstm: 0.373\n",
      "Average reward: 0.385\n",
      "\n",
      "n_iter: 750/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.063, critic: 0.108, entropy: -2.304, ae: 0.126, lstm: 0.392\n",
      "Average reward: 0.391\n",
      "\n",
      "n_iter: 760/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.072, critic: 0.104, entropy: -2.307, ae: 0.117, lstm: 0.388\n",
      "Average reward: 0.397\n",
      "\n",
      "n_iter: 770/2000, grad norm: 0.044. Training block: critic\n",
      "actor: -0.096, critic: 0.103, entropy: -2.309, ae: 0.117, lstm: 0.391\n",
      "Average reward: 0.406\n",
      "\n",
      "n_iter: 780/2000, grad norm: 0.044. Training block: critic\n",
      "actor: -0.018, critic: 0.126, entropy: -2.310, ae: 0.116, lstm: 0.353\n",
      "Average reward: 0.382\n",
      "\n",
      "n_iter: 790/2000, grad norm: 0.031. Training block: actor\n",
      "actor: -0.026, critic: 0.122, entropy: -2.309, ae: 0.118, lstm: 0.354\n",
      "Average reward: 0.388\n",
      "\n",
      "n_iter: 800/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.030, critic: 0.110, entropy: -2.308, ae: 0.116, lstm: 0.351\n",
      "Average reward: 0.390\n",
      "\n",
      "n_iter: 810/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.091, critic: 0.098, entropy: -2.308, ae: 0.121, lstm: 0.394\n",
      "Average reward: 0.411\n",
      "\n",
      "n_iter: 820/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.066, critic: 0.114, entropy: -2.311, ae: 0.118, lstm: 0.361\n",
      "Average reward: 0.401\n",
      "\n",
      "n_iter: 830/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.071, critic: 0.095, entropy: -2.311, ae: 0.120, lstm: 0.401\n",
      "Average reward: 0.399\n",
      "\n",
      "n_iter: 840/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.019, critic: 0.128, entropy: -2.316, ae: 0.122, lstm: 0.353\n",
      "Average reward: 0.390\n",
      "\n",
      "n_iter: 850/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.003, critic: 0.117, entropy: -2.314, ae: 0.118, lstm: 0.356\n",
      "Average reward: 0.377\n",
      "\n",
      "n_iter: 860/2000, grad norm: 0.031. Training block: critic\n",
      "actor: -0.012, critic: 0.121, entropy: -2.314, ae: 0.117, lstm: 0.350\n",
      "Average reward: 0.376\n",
      "\n",
      "n_iter: 870/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.069, critic: 0.096, entropy: -2.316, ae: 0.119, lstm: 0.396\n",
      "Average reward: 0.400\n",
      "\n",
      "n_iter: 880/2000, grad norm: 0.044. Training block: critic\n",
      "actor: -0.005, critic: 0.123, entropy: -2.316, ae: 0.122, lstm: 0.371\n",
      "Average reward: 0.387\n",
      "\n",
      "n_iter: 890/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.077, critic: 0.100, entropy: -2.314, ae: 0.116, lstm: 0.385\n",
      "Average reward: 0.406\n",
      "\n",
      "n_iter: 900/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.083, critic: 0.100, entropy: -2.313, ae: 0.122, lstm: 0.396\n",
      "Average reward: 0.415\n",
      "\n",
      "n_iter: 910/2000, grad norm: 0.031. Training block: actor\n",
      "actor: 0.046, critic: 0.147, entropy: -2.324, ae: 0.118, lstm: 0.312\n",
      "Average reward: 0.366\n",
      "\n",
      "n_iter: 920/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.049, critic: 0.113, entropy: -2.313, ae: 0.123, lstm: 0.369\n",
      "Average reward: 0.404\n",
      "\n",
      "n_iter: 930/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.061, critic: 0.109, entropy: -2.319, ae: 0.116, lstm: 0.372\n",
      "Average reward: 0.406\n",
      "\n",
      "n_iter: 940/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.074, critic: 0.104, entropy: -2.315, ae: 0.121, lstm: 0.387\n",
      "Average reward: 0.411\n",
      "\n",
      "n_iter: 950/2000, grad norm: 0.045. Training block: critic\n",
      "actor: -0.048, critic: 0.100, entropy: -2.319, ae: 0.120, lstm: 0.396\n",
      "Average reward: 0.401\n",
      "\n",
      "n_iter: 960/2000, grad norm: 0.016. Training block: actor\n",
      "actor: 0.005, critic: 0.124, entropy: -2.316, ae: 0.120, lstm: 0.348\n",
      "Average reward: 0.389\n",
      "\n",
      "n_iter: 970/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.041, critic: 0.106, entropy: -2.319, ae: 0.122, lstm: 0.386\n",
      "Average reward: 0.406\n",
      "\n",
      "n_iter: 980/2000, grad norm: 0.016. Training block: actor\n",
      "actor: 0.037, critic: 0.127, entropy: -2.319, ae: 0.120, lstm: 0.345\n",
      "Average reward: 0.370\n",
      "\n",
      "n_iter: 990/2000, grad norm: 0.015. Training block: actor\n",
      "actor: -0.061, critic: 0.097, entropy: -2.319, ae: 0.118, lstm: 0.387\n",
      "Average reward: 0.409\n",
      "\n",
      "n_iter: 1000/2000, grad norm: 0.031. Training block: actor\n",
      "actor: 0.070, critic: 0.138, entropy: -2.320, ae: 0.115, lstm: 0.298\n",
      "Average reward: 0.368\n",
      "\n",
      "n_iter: 1010/2000, grad norm: 0.044. Training block: critic\n",
      "actor: 0.036, critic: 0.133, entropy: -2.320, ae: 0.122, lstm: 0.327\n",
      "Average reward: 0.381\n",
      "\n",
      "n_iter: 1020/2000, grad norm: 0.015. Training block: actor\n",
      "actor: -0.063, critic: 0.107, entropy: -2.322, ae: 0.117, lstm: 0.384\n",
      "Average reward: 0.412\n",
      "\n",
      "n_iter: 1030/2000, grad norm: 0.031. Training block: actor\n",
      "actor: -0.080, critic: 0.100, entropy: -2.319, ae: 0.121, lstm: 0.396\n",
      "Average reward: 0.419\n",
      "\n",
      "n_iter: 1040/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.058, critic: 0.101, entropy: -2.320, ae: 0.119, lstm: 0.383\n",
      "Average reward: 0.409\n",
      "\n",
      "n_iter: 1050/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.042, critic: 0.111, entropy: -2.325, ae: 0.115, lstm: 0.367\n",
      "Average reward: 0.405\n",
      "\n",
      "n_iter: 1060/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.046, critic: 0.108, entropy: -2.320, ae: 0.120, lstm: 0.374\n",
      "Average reward: 0.407\n",
      "\n",
      "n_iter: 1070/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.065, critic: 0.100, entropy: -2.322, ae: 0.120, lstm: 0.385\n",
      "Average reward: 0.413\n",
      "\n",
      "n_iter: 1080/2000, grad norm: 0.015. Training block: actor\n",
      "actor: -0.052, critic: 0.111, entropy: -2.320, ae: 0.123, lstm: 0.368\n",
      "Average reward: 0.410\n",
      "\n",
      "n_iter: 1090/2000, grad norm: 0.029. Training block: actor\n",
      "actor: -0.039, critic: 0.100, entropy: -2.323, ae: 0.119, lstm: 0.383\n",
      "Average reward: 0.402\n",
      "\n",
      "n_iter: 1100/2000, grad norm: 0.044. Training block: critic\n",
      "actor: -0.058, critic: 0.101, entropy: -2.323, ae: 0.120, lstm: 0.395\n",
      "Average reward: 0.417\n",
      "\n",
      "n_iter: 1110/2000, grad norm: 0.031. Training block: actor\n",
      "actor: 0.073, critic: 0.145, entropy: -2.321, ae: 0.121, lstm: 0.326\n",
      "Average reward: 0.378\n",
      "\n",
      "n_iter: 1120/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.037, critic: 0.107, entropy: -2.319, ae: 0.119, lstm: 0.376\n",
      "Average reward: 0.407\n",
      "\n",
      "n_iter: 1130/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.053, critic: 0.111, entropy: -2.323, ae: 0.118, lstm: 0.384\n",
      "Average reward: 0.412\n",
      "\n",
      "n_iter: 1140/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.049, critic: 0.103, entropy: -2.319, ae: 0.119, lstm: 0.380\n",
      "Average reward: 0.418\n",
      "\n",
      "n_iter: 1150/2000, grad norm: 0.044. Training block: critic\n",
      "actor: -0.064, critic: 0.106, entropy: -2.324, ae: 0.117, lstm: 0.388\n",
      "Average reward: 0.419\n",
      "\n",
      "n_iter: 1160/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.067, critic: 0.106, entropy: -2.320, ae: 0.119, lstm: 0.389\n",
      "Average reward: 0.417\n",
      "\n",
      "n_iter: 1170/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.051, critic: 0.101, entropy: -2.320, ae: 0.119, lstm: 0.386\n",
      "Average reward: 0.416\n",
      "\n",
      "n_iter: 1180/2000, grad norm: 0.015. Training block: actor\n",
      "actor: -0.076, critic: 0.096, entropy: -2.322, ae: 0.120, lstm: 0.388\n",
      "Average reward: 0.427\n",
      "\n",
      "n_iter: 1190/2000, grad norm: 0.044. Training block: critic\n",
      "actor: -0.050, critic: 0.104, entropy: -2.320, ae: 0.119, lstm: 0.385\n",
      "Average reward: 0.410\n",
      "\n",
      "n_iter: 1200/2000, grad norm: 0.030. Training block: actor\n",
      "actor: 0.047, critic: 0.136, entropy: -2.319, ae: 0.121, lstm: 0.322\n",
      "Average reward: 0.383\n",
      "\n",
      "n_iter: 1210/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.052, critic: 0.105, entropy: -2.320, ae: 0.116, lstm: 0.382\n",
      "Average reward: 0.412\n",
      "\n",
      "n_iter: 1220/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.027, critic: 0.111, entropy: -2.323, ae: 0.119, lstm: 0.386\n",
      "Average reward: 0.409\n",
      "\n",
      "n_iter: 1230/2000, grad norm: 0.044. Training block: critic\n",
      "actor: -0.016, critic: 0.112, entropy: -2.323, ae: 0.117, lstm: 0.359\n",
      "Average reward: 0.404\n",
      "\n",
      "n_iter: 1240/2000, grad norm: 0.015. Training block: actor\n",
      "actor: -0.065, critic: 0.103, entropy: -2.321, ae: 0.116, lstm: 0.377\n",
      "Average reward: 0.428\n",
      "\n",
      "n_iter: 1250/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.058, critic: 0.114, entropy: -2.320, ae: 0.116, lstm: 0.372\n",
      "Average reward: 0.424\n",
      "\n",
      "n_iter: 1260/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.037, critic: 0.113, entropy: -2.317, ae: 0.118, lstm: 0.373\n",
      "Average reward: 0.415\n",
      "\n",
      "n_iter: 1270/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.079, critic: 0.099, entropy: -2.320, ae: 0.118, lstm: 0.392\n",
      "Average reward: 0.431\n",
      "\n",
      "n_iter: 1280/2000, grad norm: 0.029. Training block: critic\n",
      "actor: -0.055, critic: 0.102, entropy: -2.319, ae: 0.121, lstm: 0.390\n",
      "Average reward: 0.426\n",
      "\n",
      "n_iter: 1290/2000, grad norm: 0.030. Training block: actor\n",
      "actor: 0.053, critic: 0.135, entropy: -2.324, ae: 0.116, lstm: 0.324\n",
      "Average reward: 0.388\n",
      "\n",
      "n_iter: 1300/2000, grad norm: 0.029. Training block: actor\n",
      "actor: -0.044, critic: 0.104, entropy: -2.318, ae: 0.117, lstm: 0.389\n",
      "Average reward: 0.418\n",
      "\n",
      "n_iter: 1310/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.059, critic: 0.096, entropy: -2.320, ae: 0.118, lstm: 0.390\n",
      "Average reward: 0.425\n",
      "\n",
      "n_iter: 1320/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.020, critic: 0.117, entropy: -2.319, ae: 0.120, lstm: 0.355\n",
      "Average reward: 0.419\n",
      "\n",
      "n_iter: 1330/2000, grad norm: 0.016. Training block: actor\n",
      "actor: 0.031, critic: 0.145, entropy: -2.323, ae: 0.117, lstm: 0.335\n",
      "Average reward: 0.401\n",
      "\n",
      "n_iter: 1340/2000, grad norm: 0.015. Training block: actor\n",
      "actor: -0.067, critic: 0.108, entropy: -2.315, ae: 0.119, lstm: 0.371\n",
      "Average reward: 0.434\n",
      "\n",
      "n_iter: 1350/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.070, critic: 0.099, entropy: -2.317, ae: 0.120, lstm: 0.393\n",
      "Average reward: 0.435\n",
      "\n",
      "n_iter: 1360/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.054, critic: 0.112, entropy: -2.320, ae: 0.118, lstm: 0.381\n",
      "Average reward: 0.426\n",
      "\n",
      "n_iter: 1370/2000, grad norm: 0.015. Training block: actor\n",
      "actor: -0.037, critic: 0.111, entropy: -2.316, ae: 0.119, lstm: 0.371\n",
      "Average reward: 0.424\n",
      "\n",
      "n_iter: 1380/2000, grad norm: 0.029. Training block: actor\n",
      "actor: -0.026, critic: 0.105, entropy: -2.315, ae: 0.122, lstm: 0.371\n",
      "Average reward: 0.413\n",
      "\n",
      "n_iter: 1390/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.077, critic: 0.102, entropy: -2.317, ae: 0.120, lstm: 0.396\n",
      "Average reward: 0.437\n",
      "\n",
      "n_iter: 1400/2000, grad norm: 0.029. Training block: actor\n",
      "actor: -0.011, critic: 0.110, entropy: -2.314, ae: 0.125, lstm: 0.386\n",
      "Average reward: 0.413\n",
      "\n",
      "n_iter: 1410/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.042, critic: 0.107, entropy: -2.316, ae: 0.118, lstm: 0.377\n",
      "Average reward: 0.430\n",
      "\n",
      "n_iter: 1420/2000, grad norm: 0.016. Training block: actor\n",
      "actor: 0.027, critic: 0.129, entropy: -2.314, ae: 0.119, lstm: 0.337\n",
      "Average reward: 0.409\n",
      "\n",
      "n_iter: 1430/2000, grad norm: 0.015. Training block: actor\n",
      "actor: -0.028, critic: 0.107, entropy: -2.316, ae: 0.119, lstm: 0.389\n",
      "Average reward: 0.419\n",
      "\n",
      "n_iter: 1440/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.070, critic: 0.105, entropy: -2.315, ae: 0.118, lstm: 0.391\n",
      "Average reward: 0.445\n",
      "\n",
      "n_iter: 1450/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.032, critic: 0.104, entropy: -2.315, ae: 0.122, lstm: 0.388\n",
      "Average reward: 0.431\n",
      "\n",
      "n_iter: 1460/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.071, critic: 0.106, entropy: -2.318, ae: 0.119, lstm: 0.383\n",
      "Average reward: 0.447\n",
      "\n",
      "n_iter: 1470/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.073, critic: 0.101, entropy: -2.314, ae: 0.124, lstm: 0.396\n",
      "Average reward: 0.448\n",
      "\n",
      "n_iter: 1480/2000, grad norm: 0.029. Training block: actor\n",
      "actor: -0.048, critic: 0.100, entropy: -2.317, ae: 0.119, lstm: 0.389\n",
      "Average reward: 0.436\n",
      "\n",
      "n_iter: 1490/2000, grad norm: 0.029. Training block: actor\n",
      "actor: -0.042, critic: 0.101, entropy: -2.314, ae: 0.123, lstm: 0.389\n",
      "Average reward: 0.434\n",
      "\n",
      "n_iter: 1500/2000, grad norm: 0.030. Training block: critic\n",
      "actor: 0.022, critic: 0.125, entropy: -2.317, ae: 0.117, lstm: 0.352\n",
      "Average reward: 0.414\n",
      "\n",
      "n_iter: 1510/2000, grad norm: 0.015. Training block: actor\n",
      "actor: -0.060, critic: 0.098, entropy: -2.314, ae: 0.120, lstm: 0.389\n",
      "Average reward: 0.441\n",
      "\n",
      "n_iter: 1520/2000, grad norm: 0.029. Training block: critic\n",
      "actor: -0.065, critic: 0.096, entropy: -2.314, ae: 0.119, lstm: 0.392\n",
      "Average reward: 0.444\n",
      "\n",
      "n_iter: 1530/2000, grad norm: 0.029. Training block: actor\n",
      "actor: -0.082, critic: 0.100, entropy: -2.314, ae: 0.115, lstm: 0.395\n",
      "Average reward: 0.451\n",
      "\n",
      "n_iter: 1540/2000, grad norm: 0.043. Training block: critic\n",
      "actor: -0.029, critic: 0.114, entropy: -2.312, ae: 0.120, lstm: 0.373\n",
      "Average reward: 0.432\n",
      "\n",
      "n_iter: 1550/2000, grad norm: 0.015. Training block: actor\n",
      "actor: -0.028, critic: 0.107, entropy: -2.310, ae: 0.124, lstm: 0.385\n",
      "Average reward: 0.429\n",
      "\n",
      "n_iter: 1560/2000, grad norm: 0.043. Training block: critic\n",
      "actor: 0.022, critic: 0.130, entropy: -2.315, ae: 0.122, lstm: 0.344\n",
      "Average reward: 0.407\n",
      "\n",
      "n_iter: 1570/2000, grad norm: 0.029. Training block: critic\n",
      "actor: -0.060, critic: 0.100, entropy: -2.310, ae: 0.119, lstm: 0.395\n",
      "Average reward: 0.442\n",
      "\n",
      "n_iter: 1580/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.045, critic: 0.108, entropy: -2.311, ae: 0.117, lstm: 0.382\n",
      "Average reward: 0.438\n",
      "\n",
      "n_iter: 1590/2000, grad norm: 0.029. Training block: actor\n",
      "actor: -0.039, critic: 0.100, entropy: -2.311, ae: 0.123, lstm: 0.409\n",
      "Average reward: 0.432\n",
      "\n",
      "n_iter: 1600/2000, grad norm: 0.030. Training block: critic\n",
      "actor: 0.013, critic: 0.126, entropy: -2.313, ae: 0.119, lstm: 0.350\n",
      "Average reward: 0.415\n",
      "\n",
      "n_iter: 1610/2000, grad norm: 0.030. Training block: actor\n",
      "actor: -0.042, critic: 0.109, entropy: -2.312, ae: 0.122, lstm: 0.383\n",
      "Average reward: 0.438\n",
      "\n",
      "n_iter: 1620/2000, grad norm: 0.030. Training block: actor\n",
      "actor: 0.031, critic: 0.132, entropy: -2.313, ae: 0.126, lstm: 0.349\n",
      "Average reward: 0.411\n",
      "\n",
      "n_iter: 1630/2000, grad norm: 0.029. Training block: actor\n",
      "actor: -0.056, critic: 0.101, entropy: -2.311, ae: 0.118, lstm: 0.395\n",
      "Average reward: 0.442\n",
      "\n",
      "n_iter: 1640/2000, grad norm: 0.029. Training block: actor\n",
      "actor: -0.063, critic: 0.099, entropy: -2.309, ae: 0.121, lstm: 0.394\n",
      "Average reward: 0.446\n",
      "\n",
      "n_iter: 1650/2000, grad norm: 0.029. Training block: critic\n",
      "actor: -0.032, critic: 0.113, entropy: -2.309, ae: 0.120, lstm: 0.373\n",
      "Average reward: 0.436\n",
      "\n",
      "n_iter: 1660/2000, grad norm: 0.029. Training block: critic\n",
      "actor: -0.060, critic: 0.101, entropy: -2.308, ae: 0.119, lstm: 0.391\n",
      "Average reward: 0.446\n",
      "\n",
      "n_iter: 1670/2000, grad norm: 0.029. Training block: actor\n",
      "actor: -0.050, critic: 0.103, entropy: -2.311, ae: 0.119, lstm: 0.388\n",
      "Average reward: 0.442\n",
      "\n",
      "n_iter: 1680/2000, grad norm: 0.015. Training block: actor\n",
      "actor: -0.007, critic: 0.111, entropy: -2.308, ae: 0.116, lstm: 0.369\n",
      "Average reward: 0.423\n",
      "\n",
      "n_iter: 1690/2000, grad norm: 0.043. Training block: critic\n",
      "actor: -0.038, critic: 0.112, entropy: -2.310, ae: 0.120, lstm: 0.390\n",
      "Average reward: 0.440\n",
      "\n",
      "n_iter: 1700/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.014, critic: 0.113, entropy: -2.308, ae: 0.119, lstm: 0.369\n",
      "Average reward: 0.428\n",
      "\n",
      "n_iter: 1710/2000, grad norm: 0.029. Training block: actor\n",
      "actor: -0.066, critic: 0.097, entropy: -2.308, ae: 0.119, lstm: 0.390\n",
      "Average reward: 0.446\n",
      "\n",
      "n_iter: 1720/2000, grad norm: 0.030. Training block: actor\n",
      "actor: 0.050, critic: 0.141, entropy: -2.305, ae: 0.116, lstm: 0.335\n",
      "Average reward: 0.411\n",
      "\n",
      "n_iter: 1730/2000, grad norm: 0.029. Training block: actor\n",
      "actor: 0.001, critic: 0.128, entropy: -2.308, ae: 0.115, lstm: 0.355\n",
      "Average reward: 0.427\n",
      "\n",
      "n_iter: 1740/2000, grad norm: 0.015. Training block: actor\n",
      "actor: -0.043, critic: 0.099, entropy: -2.308, ae: 0.120, lstm: 0.388\n",
      "Average reward: 0.440\n",
      "\n",
      "n_iter: 1750/2000, grad norm: 0.029. Training block: actor\n",
      "actor: -0.020, critic: 0.107, entropy: -2.305, ae: 0.117, lstm: 0.384\n",
      "Average reward: 0.428\n",
      "\n",
      "n_iter: 1760/2000, grad norm: 0.029. Training block: actor\n",
      "actor: -0.052, critic: 0.100, entropy: -2.304, ae: 0.119, lstm: 0.386\n",
      "Average reward: 0.445\n",
      "\n",
      "n_iter: 1770/2000, grad norm: 0.044. Training block: critic\n",
      "actor: -0.041, critic: 0.102, entropy: -2.302, ae: 0.123, lstm: 0.391\n",
      "Average reward: 0.443\n",
      "\n",
      "n_iter: 1780/2000, grad norm: 0.043. Training block: critic\n",
      "actor: -0.054, critic: 0.097, entropy: -2.302, ae: 0.118, lstm: 0.399\n",
      "Average reward: 0.447\n",
      "\n",
      "n_iter: 1790/2000, grad norm: 0.042. Training block: critic\n",
      "actor: -0.053, critic: 0.098, entropy: -2.303, ae: 0.116, lstm: 0.389\n",
      "Average reward: 0.448\n",
      "\n",
      "n_iter: 1800/2000, grad norm: 0.043. Training block: critic\n",
      "actor: -0.028, critic: 0.110, entropy: -2.301, ae: 0.120, lstm: 0.373\n",
      "Average reward: 0.448\n",
      "\n",
      "n_iter: 1810/2000, grad norm: 0.043. Training block: critic\n",
      "actor: -0.056, critic: 0.093, entropy: -2.300, ae: 0.116, lstm: 0.396\n",
      "Average reward: 0.456\n",
      "\n",
      "n_iter: 1820/2000, grad norm: 0.030. Training block: actor\n",
      "actor: 0.041, critic: 0.133, entropy: -2.303, ae: 0.115, lstm: 0.333\n",
      "Average reward: 0.420\n",
      "\n",
      "n_iter: 1830/2000, grad norm: 0.046. Training block: critic\n",
      "actor: 0.071, critic: 0.145, entropy: -2.303, ae: 0.117, lstm: 0.325\n",
      "Average reward: 0.408\n",
      "\n",
      "n_iter: 1840/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.001, critic: 0.120, entropy: -2.304, ae: 0.118, lstm: 0.353\n",
      "Average reward: 0.435\n",
      "\n",
      "n_iter: 1850/2000, grad norm: 0.015. Training block: actor\n",
      "actor: -0.046, critic: 0.104, entropy: -2.302, ae: 0.118, lstm: 0.380\n",
      "Average reward: 0.450\n",
      "\n",
      "n_iter: 1860/2000, grad norm: 0.029. Training block: critic\n",
      "actor: -0.045, critic: 0.103, entropy: -2.300, ae: 0.116, lstm: 0.381\n",
      "Average reward: 0.452\n",
      "\n",
      "n_iter: 1870/2000, grad norm: 0.044. Training block: critic\n",
      "actor: -0.030, critic: 0.099, entropy: -2.301, ae: 0.118, lstm: 0.388\n",
      "Average reward: 0.441\n",
      "\n",
      "n_iter: 1880/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.002, critic: 0.127, entropy: -2.303, ae: 0.117, lstm: 0.350\n",
      "Average reward: 0.431\n",
      "\n",
      "n_iter: 1890/2000, grad norm: 0.029. Training block: critic\n",
      "actor: -0.050, critic: 0.114, entropy: -2.301, ae: 0.116, lstm: 0.376\n",
      "Average reward: 0.452\n",
      "\n",
      "n_iter: 1900/2000, grad norm: 0.030. Training block: critic\n",
      "actor: 0.053, critic: 0.136, entropy: -2.299, ae: 0.114, lstm: 0.336\n",
      "Average reward: 0.413\n",
      "\n",
      "n_iter: 1910/2000, grad norm: 0.045. Training block: critic\n",
      "actor: -0.039, critic: 0.111, entropy: -2.299, ae: 0.117, lstm: 0.376\n",
      "Average reward: 0.453\n",
      "\n",
      "n_iter: 1920/2000, grad norm: 0.016. Training block: actor\n",
      "actor: 0.033, critic: 0.143, entropy: -2.299, ae: 0.118, lstm: 0.336\n",
      "Average reward: 0.428\n",
      "\n",
      "n_iter: 1930/2000, grad norm: 0.030. Training block: critic\n",
      "actor: -0.003, critic: 0.118, entropy: -2.297, ae: 0.121, lstm: 0.357\n",
      "Average reward: 0.438\n",
      "\n",
      "n_iter: 1940/2000, grad norm: 0.029. Training block: critic\n",
      "actor: -0.067, critic: 0.098, entropy: -2.298, ae: 0.119, lstm: 0.394\n",
      "Average reward: 0.457\n",
      "\n",
      "n_iter: 1950/2000, grad norm: 0.029. Training block: critic\n",
      "actor: -0.052, critic: 0.097, entropy: -2.298, ae: 0.119, lstm: 0.395\n",
      "Average reward: 0.449\n",
      "\n",
      "n_iter: 1960/2000, grad norm: 0.043. Training block: critic\n",
      "actor: 0.022, critic: 0.148, entropy: -2.297, ae: 0.118, lstm: 0.331\n",
      "Average reward: 0.427\n",
      "\n",
      "n_iter: 1970/2000, grad norm: 0.016. Training block: actor\n",
      "actor: -0.054, critic: 0.101, entropy: -2.300, ae: 0.118, lstm: 0.398\n",
      "Average reward: 0.448\n",
      "\n",
      "n_iter: 1980/2000, grad norm: 0.030. Training block: actor\n",
      "actor: 0.041, critic: 0.126, entropy: -2.297, ae: 0.124, lstm: 0.355\n",
      "Average reward: 0.414\n",
      "\n",
      "n_iter: 1990/2000, grad norm: 0.030. Training block: actor\n",
      "actor: 0.060, critic: 0.148, entropy: -2.299, ae: 0.116, lstm: 0.323\n",
      "Average reward: 0.413\n",
      "\n",
      "n_iter: 0/5000, grad norm: 0.002. Training block: full\n",
      "actor: 0.007, critic: 0.124, entropy: -2.296, ae: 0.118, lstm: 0.336\n",
      "Average reward: 0.435\n",
      "\n",
      "n_iter: 10/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.051, critic: 0.118, entropy: -2.295, ae: 0.118, lstm: 0.272\n",
      "Average reward: 0.459\n",
      "\n",
      "n_iter: 20/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.006, critic: 0.130, entropy: -2.295, ae: 0.120, lstm: 0.212\n",
      "Average reward: 0.439\n",
      "\n",
      "n_iter: 30/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.051, critic: 0.105, entropy: -2.292, ae: 0.117, lstm: 0.207\n",
      "Average reward: 0.451\n",
      "\n",
      "n_iter: 40/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.002, critic: 0.124, entropy: -2.290, ae: 0.118, lstm: 0.188\n",
      "Average reward: 0.437\n",
      "\n",
      "n_iter: 50/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.052, critic: 0.109, entropy: -2.289, ae: 0.118, lstm: 0.177\n",
      "Average reward: 0.449\n",
      "\n",
      "n_iter: 60/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.039, critic: 0.116, entropy: -2.290, ae: 0.115, lstm: 0.155\n",
      "Average reward: 0.451\n",
      "\n",
      "n_iter: 70/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.064, critic: 0.150, entropy: -2.287, ae: 0.120, lstm: 0.136\n",
      "Average reward: 0.407\n",
      "\n",
      "n_iter: 80/5000, grad norm: 0.002. Training block: full\n",
      "actor: 0.009, critic: 0.127, entropy: -2.287, ae: 0.115, lstm: 0.131\n",
      "Average reward: 0.432\n",
      "\n",
      "n_iter: 90/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.003, critic: 0.129, entropy: -2.283, ae: 0.118, lstm: 0.122\n",
      "Average reward: 0.441\n",
      "\n",
      "n_iter: 100/5000, grad norm: 0.002. Training block: full\n",
      "actor: 0.037, critic: 0.122, entropy: -2.292, ae: 0.118, lstm: 0.113\n",
      "Average reward: 0.422\n",
      "\n",
      "n_iter: 110/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.049, critic: 0.098, entropy: -2.286, ae: 0.114, lstm: 0.114\n",
      "Average reward: 0.457\n",
      "\n",
      "n_iter: 120/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.051, critic: 0.112, entropy: -2.288, ae: 0.113, lstm: 0.105\n",
      "Average reward: 0.462\n",
      "\n",
      "n_iter: 130/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.077, critic: 0.104, entropy: -2.284, ae: 0.116, lstm: 0.109\n",
      "Average reward: 0.467\n",
      "\n",
      "n_iter: 140/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.045, critic: 0.104, entropy: -2.285, ae: 0.116, lstm: 0.096\n",
      "Average reward: 0.461\n",
      "\n",
      "n_iter: 150/5000, grad norm: 0.002. Training block: full\n",
      "actor: 0.009, critic: 0.123, entropy: -2.280, ae: 0.107, lstm: 0.077\n",
      "Average reward: 0.434\n",
      "\n",
      "n_iter: 160/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.041, critic: 0.098, entropy: -2.282, ae: 0.111, lstm: 0.083\n",
      "Average reward: 0.458\n",
      "\n",
      "n_iter: 170/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.029, critic: 0.108, entropy: -2.272, ae: 0.114, lstm: 0.079\n",
      "Average reward: 0.457\n",
      "\n",
      "n_iter: 180/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.022, critic: 0.120, entropy: -2.276, ae: 0.111, lstm: 0.072\n",
      "Average reward: 0.453\n",
      "\n",
      "n_iter: 190/5000, grad norm: 0.002. Training block: full\n",
      "actor: 0.074, critic: 0.137, entropy: -2.270, ae: 0.118, lstm: 0.066\n",
      "Average reward: 0.423\n",
      "\n",
      "n_iter: 200/5000, grad norm: 0.002. Training block: full\n",
      "actor: 0.031, critic: 0.131, entropy: -2.266, ae: 0.115, lstm: 0.068\n",
      "Average reward: 0.441\n",
      "\n",
      "n_iter: 210/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.057, critic: 0.102, entropy: -2.273, ae: 0.112, lstm: 0.065\n",
      "Average reward: 0.466\n",
      "\n",
      "n_iter: 220/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.023, critic: 0.134, entropy: -2.268, ae: 0.112, lstm: 0.057\n",
      "Average reward: 0.440\n",
      "\n",
      "n_iter: 230/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.063, critic: 0.096, entropy: -2.275, ae: 0.110, lstm: 0.059\n",
      "Average reward: 0.468\n",
      "\n",
      "n_iter: 240/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.039, critic: 0.103, entropy: -2.270, ae: 0.114, lstm: 0.060\n",
      "Average reward: 0.465\n",
      "\n",
      "n_iter: 250/5000, grad norm: 0.002. Training block: full\n",
      "actor: 0.039, critic: 0.145, entropy: -2.273, ae: 0.112, lstm: 0.045\n",
      "Average reward: 0.441\n",
      "\n",
      "n_iter: 260/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.034, critic: 0.096, entropy: -2.269, ae: 0.109, lstm: 0.051\n",
      "Average reward: 0.462\n",
      "\n",
      "n_iter: 270/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.038, critic: 0.099, entropy: -2.267, ae: 0.108, lstm: 0.046\n",
      "Average reward: 0.460\n",
      "\n",
      "n_iter: 280/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.069, critic: 0.097, entropy: -2.262, ae: 0.111, lstm: 0.048\n",
      "Average reward: 0.474\n",
      "\n",
      "n_iter: 290/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.056, critic: 0.109, entropy: -2.262, ae: 0.110, lstm: 0.043\n",
      "Average reward: 0.476\n",
      "\n",
      "n_iter: 300/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.011, critic: 0.117, entropy: -2.266, ae: 0.111, lstm: 0.038\n",
      "Average reward: 0.462\n",
      "\n",
      "n_iter: 310/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.046, critic: 0.103, entropy: -2.267, ae: 0.108, lstm: 0.041\n",
      "Average reward: 0.469\n",
      "\n",
      "n_iter: 320/5000, grad norm: 0.002. Training block: full\n",
      "actor: 0.093, critic: 0.149, entropy: -2.263, ae: 0.113, lstm: 0.034\n",
      "Average reward: 0.422\n",
      "\n",
      "n_iter: 330/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.068, critic: 0.094, entropy: -2.271, ae: 0.110, lstm: 0.042\n",
      "Average reward: 0.481\n",
      "\n",
      "n_iter: 340/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.045, critic: 0.103, entropy: -2.266, ae: 0.108, lstm: 0.035\n",
      "Average reward: 0.479\n",
      "\n",
      "n_iter: 350/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.042, critic: 0.097, entropy: -2.261, ae: 0.111, lstm: 0.039\n",
      "Average reward: 0.470\n",
      "\n",
      "n_iter: 360/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.017, critic: 0.104, entropy: -2.265, ae: 0.108, lstm: 0.035\n",
      "Average reward: 0.460\n",
      "\n",
      "n_iter: 370/5000, grad norm: 0.002. Training block: full\n",
      "actor: 0.113, critic: 0.160, entropy: -2.274, ae: 0.107, lstm: 0.031\n",
      "Average reward: 0.400\n",
      "\n",
      "n_iter: 380/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.000, critic: 0.118, entropy: -2.268, ae: 0.108, lstm: 0.034\n",
      "Average reward: 0.450\n",
      "\n",
      "n_iter: 390/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.037, critic: 0.102, entropy: -2.262, ae: 0.110, lstm: 0.033\n",
      "Average reward: 0.466\n",
      "\n",
      "n_iter: 400/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.094, entropy: -2.264, ae: 0.108, lstm: 0.032\n",
      "Average reward: 0.475\n",
      "\n",
      "n_iter: 410/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.037, critic: 0.136, entropy: -2.274, ae: 0.107, lstm: 0.026\n",
      "Average reward: 0.438\n",
      "\n",
      "n_iter: 420/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.044, critic: 0.107, entropy: -2.264, ae: 0.110, lstm: 0.029\n",
      "Average reward: 0.469\n",
      "\n",
      "n_iter: 430/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.096, critic: 0.166, entropy: -2.264, ae: 0.110, lstm: 0.026\n",
      "Average reward: 0.424\n",
      "\n",
      "n_iter: 440/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.037, critic: 0.120, entropy: -2.270, ae: 0.110, lstm: 0.028\n",
      "Average reward: 0.474\n",
      "\n",
      "n_iter: 450/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.056, critic: 0.095, entropy: -2.262, ae: 0.113, lstm: 0.031\n",
      "Average reward: 0.479\n",
      "\n",
      "n_iter: 460/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.070, critic: 0.097, entropy: -2.261, ae: 0.110, lstm: 0.029\n",
      "Average reward: 0.481\n",
      "\n",
      "n_iter: 470/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.040, critic: 0.105, entropy: -2.262, ae: 0.109, lstm: 0.026\n",
      "Average reward: 0.471\n",
      "\n",
      "n_iter: 480/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.039, critic: 0.103, entropy: -2.257, ae: 0.110, lstm: 0.027\n",
      "Average reward: 0.474\n",
      "\n",
      "n_iter: 490/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.067, critic: 0.094, entropy: -2.256, ae: 0.109, lstm: 0.027\n",
      "Average reward: 0.481\n",
      "\n",
      "n_iter: 500/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.045, critic: 0.131, entropy: -2.260, ae: 0.109, lstm: 0.024\n",
      "Average reward: 0.440\n",
      "\n",
      "n_iter: 510/5000, grad norm: 0.002. Training block: full\n",
      "actor: 0.024, critic: 0.134, entropy: -2.258, ae: 0.109, lstm: 0.023\n",
      "Average reward: 0.457\n",
      "\n",
      "n_iter: 520/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.078, critic: 0.100, entropy: -2.262, ae: 0.110, lstm: 0.025\n",
      "Average reward: 0.485\n",
      "\n",
      "n_iter: 530/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.017, critic: 0.121, entropy: -2.260, ae: 0.113, lstm: 0.027\n",
      "Average reward: 0.469\n",
      "\n",
      "n_iter: 540/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.051, critic: 0.093, entropy: -2.258, ae: 0.109, lstm: 0.024\n",
      "Average reward: 0.476\n",
      "\n",
      "n_iter: 550/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.045, critic: 0.101, entropy: -2.257, ae: 0.110, lstm: 0.024\n",
      "Average reward: 0.478\n",
      "\n",
      "n_iter: 560/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.022, critic: 0.114, entropy: -2.255, ae: 0.108, lstm: 0.023\n",
      "Average reward: 0.468\n",
      "\n",
      "n_iter: 570/5000, grad norm: 0.002. Training block: full\n",
      "actor: 0.019, critic: 0.126, entropy: -2.257, ae: 0.110, lstm: 0.023\n",
      "Average reward: 0.454\n",
      "\n",
      "n_iter: 580/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.013, critic: 0.106, entropy: -2.255, ae: 0.111, lstm: 0.022\n",
      "Average reward: 0.463\n",
      "\n",
      "n_iter: 590/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.031, critic: 0.104, entropy: -2.258, ae: 0.106, lstm: 0.021\n",
      "Average reward: 0.472\n",
      "\n",
      "n_iter: 600/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.103, entropy: -2.253, ae: 0.108, lstm: 0.020\n",
      "Average reward: 0.484\n",
      "\n",
      "n_iter: 610/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.014, critic: 0.127, entropy: -2.252, ae: 0.108, lstm: 0.019\n",
      "Average reward: 0.467\n",
      "\n",
      "n_iter: 620/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.036, critic: 0.100, entropy: -2.249, ae: 0.110, lstm: 0.022\n",
      "Average reward: 0.483\n",
      "\n",
      "n_iter: 630/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.008, critic: 0.109, entropy: -2.244, ae: 0.110, lstm: 0.021\n",
      "Average reward: 0.471\n",
      "\n",
      "n_iter: 640/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.015, critic: 0.111, entropy: -2.250, ae: 0.107, lstm: 0.018\n",
      "Average reward: 0.478\n",
      "\n",
      "n_iter: 650/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.058, critic: 0.096, entropy: -2.249, ae: 0.109, lstm: 0.019\n",
      "Average reward: 0.492\n",
      "\n",
      "n_iter: 660/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.069, critic: 0.097, entropy: -2.250, ae: 0.108, lstm: 0.019\n",
      "Average reward: 0.497\n",
      "\n",
      "n_iter: 670/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.051, critic: 0.116, entropy: -2.245, ae: 0.111, lstm: 0.020\n",
      "Average reward: 0.495\n",
      "\n",
      "n_iter: 680/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.023, critic: 0.107, entropy: -2.241, ae: 0.110, lstm: 0.019\n",
      "Average reward: 0.481\n",
      "\n",
      "n_iter: 690/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.043, critic: 0.092, entropy: -2.238, ae: 0.109, lstm: 0.017\n",
      "Average reward: 0.493\n",
      "\n",
      "n_iter: 700/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.081, critic: 0.157, entropy: -2.245, ae: 0.109, lstm: 0.014\n",
      "Average reward: 0.443\n",
      "\n",
      "n_iter: 710/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.022, critic: 0.108, entropy: -2.243, ae: 0.109, lstm: 0.019\n",
      "Average reward: 0.481\n",
      "\n",
      "n_iter: 720/5000, grad norm: 0.002. Training block: full\n",
      "actor: 0.069, critic: 0.140, entropy: -2.245, ae: 0.107, lstm: 0.017\n",
      "Average reward: 0.445\n",
      "\n",
      "n_iter: 730/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.046, critic: 0.154, entropy: -2.247, ae: 0.105, lstm: 0.016\n",
      "Average reward: 0.460\n",
      "\n",
      "n_iter: 740/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.020, critic: 0.106, entropy: -2.246, ae: 0.107, lstm: 0.016\n",
      "Average reward: 0.463\n",
      "\n",
      "n_iter: 750/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.099, critic: 0.151, entropy: -2.252, ae: 0.103, lstm: 0.013\n",
      "Average reward: 0.441\n",
      "\n",
      "n_iter: 760/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.046, critic: 0.093, entropy: -2.244, ae: 0.108, lstm: 0.017\n",
      "Average reward: 0.487\n",
      "\n",
      "n_iter: 770/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.000, critic: 0.112, entropy: -2.241, ae: 0.110, lstm: 0.017\n",
      "Average reward: 0.478\n",
      "\n",
      "n_iter: 780/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.039, critic: 0.129, entropy: -2.244, ae: 0.107, lstm: 0.016\n",
      "Average reward: 0.459\n",
      "\n",
      "n_iter: 790/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.020, critic: 0.102, entropy: -2.243, ae: 0.107, lstm: 0.016\n",
      "Average reward: 0.479\n",
      "\n",
      "n_iter: 800/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.016, critic: 0.110, entropy: -2.248, ae: 0.107, lstm: 0.016\n",
      "Average reward: 0.481\n",
      "\n",
      "n_iter: 810/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.046, critic: 0.098, entropy: -2.241, ae: 0.106, lstm: 0.015\n",
      "Average reward: 0.489\n",
      "\n",
      "n_iter: 820/5000, grad norm: 0.002. Training block: full\n",
      "actor: -0.032, critic: 0.097, entropy: -2.244, ae: 0.106, lstm: 0.015\n",
      "Average reward: 0.484\n",
      "\n",
      "n_iter: 830/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.046, critic: 0.100, entropy: -2.248, ae: 0.106, lstm: 0.014\n",
      "Average reward: 0.491\n",
      "\n",
      "n_iter: 840/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.013, critic: 0.116, entropy: -2.242, ae: 0.105, lstm: 0.013\n",
      "Average reward: 0.477\n",
      "\n",
      "n_iter: 850/5000, grad norm: 0.002. Training block: full\n",
      "actor: 0.035, critic: 0.133, entropy: -2.243, ae: 0.106, lstm: 0.012\n",
      "Average reward: 0.456\n",
      "\n",
      "n_iter: 860/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.104, critic: 0.174, entropy: -2.243, ae: 0.109, lstm: 0.012\n",
      "Average reward: 0.438\n",
      "\n",
      "n_iter: 870/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.025, critic: 0.113, entropy: -2.248, ae: 0.107, lstm: 0.013\n",
      "Average reward: 0.482\n",
      "\n",
      "n_iter: 880/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.047, critic: 0.095, entropy: -2.241, ae: 0.109, lstm: 0.015\n",
      "Average reward: 0.486\n",
      "\n",
      "n_iter: 890/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.046, critic: 0.102, entropy: -2.249, ae: 0.106, lstm: 0.014\n",
      "Average reward: 0.490\n",
      "\n",
      "n_iter: 900/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.083, critic: 0.095, entropy: -2.245, ae: 0.107, lstm: 0.014\n",
      "Average reward: 0.499\n",
      "\n",
      "n_iter: 910/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.067, critic: 0.092, entropy: -2.246, ae: 0.108, lstm: 0.013\n",
      "Average reward: 0.489\n",
      "\n",
      "n_iter: 920/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.063, critic: 0.097, entropy: -2.241, ae: 0.108, lstm: 0.015\n",
      "Average reward: 0.492\n",
      "\n",
      "n_iter: 930/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.004, critic: 0.125, entropy: -2.244, ae: 0.106, lstm: 0.012\n",
      "Average reward: 0.476\n",
      "\n",
      "n_iter: 940/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.088, critic: 0.172, entropy: -2.242, ae: 0.107, lstm: 0.011\n",
      "Average reward: 0.440\n",
      "\n",
      "n_iter: 950/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.068, critic: 0.098, entropy: -2.242, ae: 0.108, lstm: 0.015\n",
      "Average reward: 0.492\n",
      "\n",
      "n_iter: 960/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.060, critic: 0.092, entropy: -2.238, ae: 0.107, lstm: 0.013\n",
      "Average reward: 0.492\n",
      "\n",
      "n_iter: 970/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.039, critic: 0.103, entropy: -2.239, ae: 0.107, lstm: 0.014\n",
      "Average reward: 0.487\n",
      "\n",
      "n_iter: 980/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.043, critic: 0.092, entropy: -2.242, ae: 0.107, lstm: 0.013\n",
      "Average reward: 0.489\n",
      "\n",
      "n_iter: 990/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.009, critic: 0.138, entropy: -2.236, ae: 0.109, lstm: 0.013\n",
      "Average reward: 0.468\n",
      "\n",
      "n_iter: 1000/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.006, critic: 0.124, entropy: -2.236, ae: 0.109, lstm: 0.012\n",
      "Average reward: 0.477\n",
      "\n",
      "n_iter: 1010/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.006, critic: 0.107, entropy: -2.239, ae: 0.104, lstm: 0.012\n",
      "Average reward: 0.472\n",
      "\n",
      "n_iter: 1020/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.113, entropy: -2.237, ae: 0.109, lstm: 0.013\n",
      "Average reward: 0.495\n",
      "\n",
      "n_iter: 1030/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.064, critic: 0.093, entropy: -2.233, ae: 0.105, lstm: 0.012\n",
      "Average reward: 0.495\n",
      "\n",
      "n_iter: 1040/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.058, critic: 0.099, entropy: -2.240, ae: 0.106, lstm: 0.012\n",
      "Average reward: 0.494\n",
      "\n",
      "n_iter: 1050/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.057, critic: 0.100, entropy: -2.239, ae: 0.108, lstm: 0.015\n",
      "Average reward: 0.490\n",
      "\n",
      "n_iter: 1060/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.005, critic: 0.130, entropy: -2.231, ae: 0.109, lstm: 0.013\n",
      "Average reward: 0.475\n",
      "\n",
      "n_iter: 1070/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.042, critic: 0.094, entropy: -2.236, ae: 0.108, lstm: 0.012\n",
      "Average reward: 0.489\n",
      "\n",
      "n_iter: 1080/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.074, critic: 0.096, entropy: -2.233, ae: 0.107, lstm: 0.012\n",
      "Average reward: 0.499\n",
      "\n",
      "n_iter: 1090/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.020, critic: 0.128, entropy: -2.235, ae: 0.103, lstm: 0.010\n",
      "Average reward: 0.468\n",
      "\n",
      "n_iter: 1100/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.022, critic: 0.142, entropy: -2.231, ae: 0.107, lstm: 0.011\n",
      "Average reward: 0.469\n",
      "\n",
      "n_iter: 1110/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.012, critic: 0.121, entropy: -2.230, ae: 0.109, lstm: 0.012\n",
      "Average reward: 0.481\n",
      "\n",
      "n_iter: 1120/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.033, critic: 0.105, entropy: -2.227, ae: 0.108, lstm: 0.010\n",
      "Average reward: 0.490\n",
      "\n",
      "n_iter: 1130/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.062, critic: 0.094, entropy: -2.234, ae: 0.105, lstm: 0.011\n",
      "Average reward: 0.498\n",
      "\n",
      "n_iter: 1140/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.033, critic: 0.107, entropy: -2.235, ae: 0.105, lstm: 0.011\n",
      "Average reward: 0.490\n",
      "\n",
      "n_iter: 1150/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.027, critic: 0.104, entropy: -2.235, ae: 0.109, lstm: 0.011\n",
      "Average reward: 0.487\n",
      "\n",
      "n_iter: 1160/5000, grad norm: 0.002. Training block: full\n",
      "actor: 0.096, critic: 0.174, entropy: -2.236, ae: 0.106, lstm: 0.009\n",
      "Average reward: 0.439\n",
      "\n",
      "n_iter: 1170/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.063, critic: 0.093, entropy: -2.234, ae: 0.106, lstm: 0.012\n",
      "Average reward: 0.496\n",
      "\n",
      "n_iter: 1180/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.033, critic: 0.102, entropy: -2.233, ae: 0.107, lstm: 0.012\n",
      "Average reward: 0.487\n",
      "\n",
      "n_iter: 1190/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.066, critic: 0.146, entropy: -2.233, ae: 0.104, lstm: 0.011\n",
      "Average reward: 0.450\n",
      "\n",
      "n_iter: 1200/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.013, critic: 0.121, entropy: -2.230, ae: 0.108, lstm: 0.010\n",
      "Average reward: 0.471\n",
      "\n",
      "n_iter: 1210/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.035, critic: 0.140, entropy: -2.235, ae: 0.109, lstm: 0.010\n",
      "Average reward: 0.459\n",
      "\n",
      "n_iter: 1220/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.015, critic: 0.120, entropy: -2.235, ae: 0.106, lstm: 0.011\n",
      "Average reward: 0.474\n",
      "\n",
      "n_iter: 1230/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.009, critic: 0.124, entropy: -2.237, ae: 0.105, lstm: 0.010\n",
      "Average reward: 0.481\n",
      "\n",
      "n_iter: 1240/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.046, critic: 0.098, entropy: -2.234, ae: 0.106, lstm: 0.010\n",
      "Average reward: 0.495\n",
      "\n",
      "n_iter: 1250/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.083, critic: 0.150, entropy: -2.227, ae: 0.107, lstm: 0.009\n",
      "Average reward: 0.441\n",
      "\n",
      "n_iter: 1260/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.047, critic: 0.152, entropy: -2.231, ae: 0.106, lstm: 0.009\n",
      "Average reward: 0.464\n",
      "\n",
      "n_iter: 1270/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.028, critic: 0.104, entropy: -2.239, ae: 0.107, lstm: 0.011\n",
      "Average reward: 0.488\n",
      "\n",
      "n_iter: 1280/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.046, critic: 0.102, entropy: -2.233, ae: 0.106, lstm: 0.011\n",
      "Average reward: 0.494\n",
      "\n",
      "n_iter: 1290/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.031, critic: 0.109, entropy: -2.229, ae: 0.107, lstm: 0.010\n",
      "Average reward: 0.492\n",
      "\n",
      "n_iter: 1300/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.054, critic: 0.091, entropy: -2.229, ae: 0.107, lstm: 0.010\n",
      "Average reward: 0.501\n",
      "\n",
      "n_iter: 1310/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.003, critic: 0.115, entropy: -2.231, ae: 0.105, lstm: 0.009\n",
      "Average reward: 0.483\n",
      "\n",
      "n_iter: 1320/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.047, critic: 0.101, entropy: -2.229, ae: 0.106, lstm: 0.009\n",
      "Average reward: 0.505\n",
      "\n",
      "n_iter: 1330/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.038, critic: 0.096, entropy: -2.228, ae: 0.103, lstm: 0.009\n",
      "Average reward: 0.500\n",
      "\n",
      "n_iter: 1340/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.030, critic: 0.122, entropy: -2.228, ae: 0.105, lstm: 0.010\n",
      "Average reward: 0.472\n",
      "\n",
      "n_iter: 1350/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.031, critic: 0.107, entropy: -2.227, ae: 0.107, lstm: 0.009\n",
      "Average reward: 0.491\n",
      "\n",
      "n_iter: 1360/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.036, critic: 0.102, entropy: -2.234, ae: 0.104, lstm: 0.009\n",
      "Average reward: 0.493\n",
      "\n",
      "n_iter: 1370/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.034, critic: 0.120, entropy: -2.223, ae: 0.108, lstm: 0.010\n",
      "Average reward: 0.479\n",
      "\n",
      "n_iter: 1380/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.023, critic: 0.099, entropy: -2.227, ae: 0.107, lstm: 0.010\n",
      "Average reward: 0.489\n",
      "\n",
      "n_iter: 1390/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.057, critic: 0.152, entropy: -2.232, ae: 0.105, lstm: 0.007\n",
      "Average reward: 0.468\n",
      "\n",
      "n_iter: 1400/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.053, critic: 0.152, entropy: -2.227, ae: 0.105, lstm: 0.008\n",
      "Average reward: 0.469\n",
      "\n",
      "n_iter: 1410/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.004, critic: 0.128, entropy: -2.227, ae: 0.108, lstm: 0.009\n",
      "Average reward: 0.486\n",
      "\n",
      "n_iter: 1420/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.057, critic: 0.102, entropy: -2.231, ae: 0.107, lstm: 0.010\n",
      "Average reward: 0.503\n",
      "\n",
      "n_iter: 1430/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.049, critic: 0.145, entropy: -2.225, ae: 0.104, lstm: 0.009\n",
      "Average reward: 0.462\n",
      "\n",
      "n_iter: 1440/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.043, critic: 0.099, entropy: -2.225, ae: 0.105, lstm: 0.008\n",
      "Average reward: 0.497\n",
      "\n",
      "n_iter: 1450/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.062, critic: 0.152, entropy: -2.228, ae: 0.102, lstm: 0.008\n",
      "Average reward: 0.457\n",
      "\n",
      "n_iter: 1460/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.024, critic: 0.101, entropy: -2.229, ae: 0.104, lstm: 0.009\n",
      "Average reward: 0.493\n",
      "\n",
      "n_iter: 1470/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.025, critic: 0.112, entropy: -2.226, ae: 0.105, lstm: 0.008\n",
      "Average reward: 0.500\n",
      "\n",
      "n_iter: 1480/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.021, critic: 0.122, entropy: -2.230, ae: 0.109, lstm: 0.009\n",
      "Average reward: 0.495\n",
      "\n",
      "n_iter: 1490/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.032, critic: 0.095, entropy: -2.222, ae: 0.106, lstm: 0.008\n",
      "Average reward: 0.497\n",
      "\n",
      "n_iter: 1500/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.038, critic: 0.106, entropy: -2.232, ae: 0.105, lstm: 0.009\n",
      "Average reward: 0.499\n",
      "\n",
      "n_iter: 1510/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.009, critic: 0.119, entropy: -2.227, ae: 0.103, lstm: 0.008\n",
      "Average reward: 0.492\n",
      "\n",
      "n_iter: 1520/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.025, critic: 0.099, entropy: -2.230, ae: 0.107, lstm: 0.009\n",
      "Average reward: 0.491\n",
      "\n",
      "n_iter: 1530/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.040, critic: 0.101, entropy: -2.229, ae: 0.104, lstm: 0.008\n",
      "Average reward: 0.495\n",
      "\n",
      "n_iter: 1540/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.047, critic: 0.095, entropy: -2.223, ae: 0.108, lstm: 0.008\n",
      "Average reward: 0.506\n",
      "\n",
      "n_iter: 1550/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.035, critic: 0.098, entropy: -2.223, ae: 0.105, lstm: 0.008\n",
      "Average reward: 0.496\n",
      "\n",
      "n_iter: 1560/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.010, critic: 0.114, entropy: -2.220, ae: 0.106, lstm: 0.007\n",
      "Average reward: 0.493\n",
      "\n",
      "n_iter: 1570/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.019, critic: 0.100, entropy: -2.226, ae: 0.104, lstm: 0.007\n",
      "Average reward: 0.494\n",
      "\n",
      "n_iter: 1580/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.071, critic: 0.147, entropy: -2.224, ae: 0.103, lstm: 0.007\n",
      "Average reward: 0.463\n",
      "\n",
      "n_iter: 1590/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.038, critic: 0.126, entropy: -2.233, ae: 0.105, lstm: 0.009\n",
      "Average reward: 0.471\n",
      "\n",
      "n_iter: 1600/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.056, critic: 0.092, entropy: -2.229, ae: 0.106, lstm: 0.008\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 1610/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.039, critic: 0.103, entropy: -2.224, ae: 0.105, lstm: 0.008\n",
      "Average reward: 0.494\n",
      "\n",
      "n_iter: 1620/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.069, critic: 0.095, entropy: -2.231, ae: 0.104, lstm: 0.008\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 1630/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.061, critic: 0.094, entropy: -2.225, ae: 0.105, lstm: 0.007\n",
      "Average reward: 0.509\n",
      "\n",
      "n_iter: 1640/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.014, critic: 0.118, entropy: -2.227, ae: 0.105, lstm: 0.007\n",
      "Average reward: 0.485\n",
      "\n",
      "n_iter: 1650/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.032, critic: 0.099, entropy: -2.227, ae: 0.104, lstm: 0.008\n",
      "Average reward: 0.494\n",
      "\n",
      "n_iter: 1660/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.012, critic: 0.123, entropy: -2.225, ae: 0.104, lstm: 0.007\n",
      "Average reward: 0.494\n",
      "\n",
      "n_iter: 1670/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.017, critic: 0.134, entropy: -2.226, ae: 0.107, lstm: 0.008\n",
      "Average reward: 0.487\n",
      "\n",
      "n_iter: 1680/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.069, critic: 0.095, entropy: -2.227, ae: 0.104, lstm: 0.007\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 1690/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.059, critic: 0.096, entropy: -2.226, ae: 0.104, lstm: 0.007\n",
      "Average reward: 0.509\n",
      "\n",
      "n_iter: 1700/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.073, critic: 0.099, entropy: -2.222, ae: 0.106, lstm: 0.007\n",
      "Average reward: 0.514\n",
      "\n",
      "n_iter: 1710/5000, grad norm: 0.000. Training block: full\n",
      "actor: -0.054, critic: 0.092, entropy: -2.224, ae: 0.105, lstm: 0.007\n",
      "Average reward: 0.505\n",
      "\n",
      "n_iter: 1720/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.025, critic: 0.134, entropy: -2.222, ae: 0.105, lstm: 0.006\n",
      "Average reward: 0.479\n",
      "\n",
      "n_iter: 1730/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.023, critic: 0.127, entropy: -2.221, ae: 0.105, lstm: 0.007\n",
      "Average reward: 0.481\n",
      "\n",
      "n_iter: 1740/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.052, critic: 0.091, entropy: -2.217, ae: 0.107, lstm: 0.008\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 1750/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.014, critic: 0.122, entropy: -2.219, ae: 0.106, lstm: 0.008\n",
      "Average reward: 0.497\n",
      "\n",
      "n_iter: 1760/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.034, critic: 0.093, entropy: -2.221, ae: 0.105, lstm: 0.007\n",
      "Average reward: 0.498\n",
      "\n",
      "n_iter: 1770/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.013, critic: 0.110, entropy: -2.220, ae: 0.105, lstm: 0.007\n",
      "Average reward: 0.498\n",
      "\n",
      "n_iter: 1780/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.005, critic: 0.122, entropy: -2.223, ae: 0.108, lstm: 0.008\n",
      "Average reward: 0.489\n",
      "\n",
      "n_iter: 1790/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.042, critic: 0.093, entropy: -2.226, ae: 0.104, lstm: 0.007\n",
      "Average reward: 0.501\n",
      "\n",
      "n_iter: 1800/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.019, critic: 0.107, entropy: -2.227, ae: 0.106, lstm: 0.006\n",
      "Average reward: 0.496\n",
      "\n",
      "n_iter: 1810/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.106, critic: 0.168, entropy: -2.223, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.450\n",
      "\n",
      "n_iter: 1820/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.062, critic: 0.095, entropy: -2.221, ae: 0.105, lstm: 0.007\n",
      "Average reward: 0.510\n",
      "\n",
      "n_iter: 1830/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.004, critic: 0.111, entropy: -2.222, ae: 0.105, lstm: 0.007\n",
      "Average reward: 0.491\n",
      "\n",
      "n_iter: 1840/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.059, critic: 0.094, entropy: -2.213, ae: 0.107, lstm: 0.007\n",
      "Average reward: 0.515\n",
      "\n",
      "n_iter: 1850/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.049, critic: 0.092, entropy: -2.218, ae: 0.106, lstm: 0.007\n",
      "Average reward: 0.506\n",
      "\n",
      "n_iter: 1860/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.026, critic: 0.107, entropy: -2.218, ae: 0.107, lstm: 0.006\n",
      "Average reward: 0.502\n",
      "\n",
      "n_iter: 1870/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.052, critic: 0.089, entropy: -2.219, ae: 0.105, lstm: 0.007\n",
      "Average reward: 0.510\n",
      "\n",
      "n_iter: 1880/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.082, critic: 0.145, entropy: -2.224, ae: 0.103, lstm: 0.005\n",
      "Average reward: 0.464\n",
      "\n",
      "n_iter: 1890/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.037, critic: 0.103, entropy: -2.224, ae: 0.106, lstm: 0.006\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 1900/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.001, critic: 0.108, entropy: -2.218, ae: 0.106, lstm: 0.007\n",
      "Average reward: 0.490\n",
      "\n",
      "n_iter: 1910/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.017, critic: 0.094, entropy: -2.218, ae: 0.106, lstm: 0.007\n",
      "Average reward: 0.501\n",
      "\n",
      "n_iter: 1920/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.055, critic: 0.137, entropy: -2.220, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.469\n",
      "\n",
      "n_iter: 1930/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.001, critic: 0.121, entropy: -2.216, ae: 0.105, lstm: 0.006\n",
      "Average reward: 0.498\n",
      "\n",
      "n_iter: 1940/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.015, critic: 0.121, entropy: -2.212, ae: 0.106, lstm: 0.006\n",
      "Average reward: 0.487\n",
      "\n",
      "n_iter: 1950/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.047, critic: 0.092, entropy: -2.220, ae: 0.103, lstm: 0.006\n",
      "Average reward: 0.510\n",
      "\n",
      "n_iter: 1960/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.038, critic: 0.096, entropy: -2.218, ae: 0.106, lstm: 0.006\n",
      "Average reward: 0.503\n",
      "\n",
      "n_iter: 1970/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.010, critic: 0.114, entropy: -2.215, ae: 0.107, lstm: 0.007\n",
      "Average reward: 0.488\n",
      "\n",
      "n_iter: 1980/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.023, critic: 0.097, entropy: -2.216, ae: 0.103, lstm: 0.006\n",
      "Average reward: 0.501\n",
      "\n",
      "n_iter: 1990/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.023, critic: 0.102, entropy: -2.222, ae: 0.104, lstm: 0.006\n",
      "Average reward: 0.495\n",
      "\n",
      "n_iter: 2000/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.030, critic: 0.096, entropy: -2.219, ae: 0.105, lstm: 0.006\n",
      "Average reward: 0.498\n",
      "\n",
      "n_iter: 2010/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.068, critic: 0.141, entropy: -2.216, ae: 0.103, lstm: 0.005\n",
      "Average reward: 0.467\n",
      "\n",
      "n_iter: 2020/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.024, critic: 0.144, entropy: -2.217, ae: 0.103, lstm: 0.006\n",
      "Average reward: 0.488\n",
      "\n",
      "n_iter: 2030/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.024, critic: 0.111, entropy: -2.221, ae: 0.103, lstm: 0.005\n",
      "Average reward: 0.492\n",
      "\n",
      "n_iter: 2040/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.040, critic: 0.097, entropy: -2.212, ae: 0.104, lstm: 0.006\n",
      "Average reward: 0.501\n",
      "\n",
      "n_iter: 2050/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.047, critic: 0.092, entropy: -2.221, ae: 0.104, lstm: 0.006\n",
      "Average reward: 0.505\n",
      "\n",
      "n_iter: 2060/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.013, critic: 0.118, entropy: -2.222, ae: 0.105, lstm: 0.006\n",
      "Average reward: 0.499\n",
      "\n",
      "n_iter: 2070/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.048, critic: 0.102, entropy: -2.214, ae: 0.105, lstm: 0.007\n",
      "Average reward: 0.509\n",
      "\n",
      "n_iter: 2080/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.051, critic: 0.160, entropy: -2.230, ae: 0.107, lstm: 0.006\n",
      "Average reward: 0.473\n",
      "\n",
      "n_iter: 2090/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.007, critic: 0.117, entropy: -2.225, ae: 0.103, lstm: 0.005\n",
      "Average reward: 0.479\n",
      "\n",
      "n_iter: 2100/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.032, critic: 0.113, entropy: -2.211, ae: 0.104, lstm: 0.006\n",
      "Average reward: 0.503\n",
      "\n",
      "n_iter: 2110/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.031, critic: 0.107, entropy: -2.220, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.502\n",
      "\n",
      "n_iter: 2120/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.037, critic: 0.093, entropy: -2.217, ae: 0.104, lstm: 0.006\n",
      "Average reward: 0.494\n",
      "\n",
      "n_iter: 2130/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.025, critic: 0.128, entropy: -2.221, ae: 0.105, lstm: 0.005\n",
      "Average reward: 0.485\n",
      "\n",
      "n_iter: 2140/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.058, critic: 0.098, entropy: -2.215, ae: 0.105, lstm: 0.006\n",
      "Average reward: 0.506\n",
      "\n",
      "n_iter: 2150/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.019, critic: 0.131, entropy: -2.223, ae: 0.102, lstm: 0.006\n",
      "Average reward: 0.483\n",
      "\n",
      "n_iter: 2160/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.015, critic: 0.130, entropy: -2.214, ae: 0.107, lstm: 0.006\n",
      "Average reward: 0.486\n",
      "\n",
      "n_iter: 2170/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.028, critic: 0.107, entropy: -2.218, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.502\n",
      "\n",
      "n_iter: 2180/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.027, critic: 0.106, entropy: -2.220, ae: 0.105, lstm: 0.005\n",
      "Average reward: 0.499\n",
      "\n",
      "n_iter: 2190/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.056, critic: 0.092, entropy: -2.223, ae: 0.106, lstm: 0.006\n",
      "Average reward: 0.505\n",
      "\n",
      "n_iter: 2200/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.073, critic: 0.090, entropy: -2.217, ae: 0.105, lstm: 0.005\n",
      "Average reward: 0.520\n",
      "\n",
      "n_iter: 2210/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.014, critic: 0.132, entropy: -2.230, ae: 0.102, lstm: 0.005\n",
      "Average reward: 0.479\n",
      "\n",
      "n_iter: 2220/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.043, critic: 0.096, entropy: -2.218, ae: 0.104, lstm: 0.006\n",
      "Average reward: 0.506\n",
      "\n",
      "n_iter: 2230/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.096, entropy: -2.221, ae: 0.105, lstm: 0.006\n",
      "Average reward: 0.513\n",
      "\n",
      "n_iter: 2240/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.010, critic: 0.117, entropy: -2.214, ae: 0.102, lstm: 0.005\n",
      "Average reward: 0.498\n",
      "\n",
      "n_iter: 2250/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.049, critic: 0.093, entropy: -2.215, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.511\n",
      "\n",
      "n_iter: 2260/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.043, critic: 0.097, entropy: -2.214, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.507\n",
      "\n",
      "n_iter: 2270/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.048, critic: 0.094, entropy: -2.213, ae: 0.106, lstm: 0.006\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 2280/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.034, critic: 0.136, entropy: -2.213, ae: 0.103, lstm: 0.005\n",
      "Average reward: 0.477\n",
      "\n",
      "n_iter: 2290/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.007, critic: 0.127, entropy: -2.212, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.491\n",
      "\n",
      "n_iter: 2300/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.029, critic: 0.110, entropy: -2.210, ae: 0.105, lstm: 0.005\n",
      "Average reward: 0.508\n",
      "\n",
      "n_iter: 2310/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.038, critic: 0.122, entropy: -2.217, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.480\n",
      "\n",
      "n_iter: 2320/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.049, critic: 0.093, entropy: -2.218, ae: 0.103, lstm: 0.005\n",
      "Average reward: 0.513\n",
      "\n",
      "n_iter: 2330/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.057, critic: 0.089, entropy: -2.214, ae: 0.106, lstm: 0.006\n",
      "Average reward: 0.515\n",
      "\n",
      "n_iter: 2340/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.035, critic: 0.101, entropy: -2.216, ae: 0.105, lstm: 0.005\n",
      "Average reward: 0.514\n",
      "\n",
      "n_iter: 2350/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.014, critic: 0.104, entropy: -2.215, ae: 0.105, lstm: 0.006\n",
      "Average reward: 0.501\n",
      "\n",
      "n_iter: 2360/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.031, critic: 0.099, entropy: -2.212, ae: 0.105, lstm: 0.005\n",
      "Average reward: 0.510\n",
      "\n",
      "n_iter: 2370/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.032, critic: 0.095, entropy: -2.215, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.507\n",
      "\n",
      "n_iter: 2380/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.043, critic: 0.094, entropy: -2.214, ae: 0.103, lstm: 0.005\n",
      "Average reward: 0.513\n",
      "\n",
      "n_iter: 2390/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.052, critic: 0.091, entropy: -2.214, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 2400/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.023, critic: 0.101, entropy: -2.214, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.503\n",
      "\n",
      "n_iter: 2410/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.034, critic: 0.131, entropy: -2.215, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.483\n",
      "\n",
      "n_iter: 2420/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.020, critic: 0.099, entropy: -2.217, ae: 0.106, lstm: 0.006\n",
      "Average reward: 0.508\n",
      "\n",
      "n_iter: 2430/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.046, critic: 0.141, entropy: -2.225, ae: 0.100, lstm: 0.005\n",
      "Average reward: 0.484\n",
      "\n",
      "n_iter: 2440/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.040, critic: 0.089, entropy: -2.210, ae: 0.106, lstm: 0.006\n",
      "Average reward: 0.508\n",
      "\n",
      "n_iter: 2450/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.059, critic: 0.090, entropy: -2.209, ae: 0.106, lstm: 0.005\n",
      "Average reward: 0.515\n",
      "\n",
      "n_iter: 2460/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.056, critic: 0.102, entropy: -2.214, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.517\n",
      "\n",
      "n_iter: 2470/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.026, critic: 0.144, entropy: -2.215, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.478\n",
      "\n",
      "n_iter: 2480/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.056, critic: 0.097, entropy: -2.215, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.508\n",
      "\n",
      "n_iter: 2490/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.047, critic: 0.097, entropy: -2.212, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.508\n",
      "\n",
      "n_iter: 2500/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.058, critic: 0.090, entropy: -2.214, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 2510/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.017, critic: 0.138, entropy: -2.216, ae: 0.106, lstm: 0.005\n",
      "Average reward: 0.491\n",
      "\n",
      "n_iter: 2520/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.035, critic: 0.107, entropy: -2.215, ae: 0.103, lstm: 0.005\n",
      "Average reward: 0.502\n",
      "\n",
      "n_iter: 2530/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.003, critic: 0.124, entropy: -2.215, ae: 0.105, lstm: 0.005\n",
      "Average reward: 0.494\n",
      "\n",
      "n_iter: 2540/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.036, critic: 0.111, entropy: -2.214, ae: 0.105, lstm: 0.005\n",
      "Average reward: 0.508\n",
      "\n",
      "n_iter: 2550/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.026, critic: 0.103, entropy: -2.218, ae: 0.106, lstm: 0.006\n",
      "Average reward: 0.498\n",
      "\n",
      "n_iter: 2560/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.027, critic: 0.103, entropy: -2.219, ae: 0.105, lstm: 0.005\n",
      "Average reward: 0.500\n",
      "\n",
      "n_iter: 2570/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.035, critic: 0.097, entropy: -2.211, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.510\n",
      "\n",
      "n_iter: 2580/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.084, critic: 0.163, entropy: -2.220, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.469\n",
      "\n",
      "n_iter: 2590/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.030, critic: 0.129, entropy: -2.220, ae: 0.101, lstm: 0.004\n",
      "Average reward: 0.484\n",
      "\n",
      "n_iter: 2600/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.077, critic: 0.160, entropy: -2.224, ae: 0.103, lstm: 0.005\n",
      "Average reward: 0.474\n",
      "\n",
      "n_iter: 2610/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.026, critic: 0.101, entropy: -2.222, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.500\n",
      "\n",
      "n_iter: 2620/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.016, critic: 0.126, entropy: -2.220, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.493\n",
      "\n",
      "n_iter: 2630/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.037, critic: 0.102, entropy: -2.220, ae: 0.102, lstm: 0.005\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 2640/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.062, critic: 0.149, entropy: -2.215, ae: 0.106, lstm: 0.005\n",
      "Average reward: 0.471\n",
      "\n",
      "n_iter: 2650/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.101, entropy: -2.213, ae: 0.105, lstm: 0.005\n",
      "Average reward: 0.515\n",
      "\n",
      "n_iter: 2660/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.049, critic: 0.144, entropy: -2.215, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.476\n",
      "\n",
      "n_iter: 2670/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.022, critic: 0.106, entropy: -2.212, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.494\n",
      "\n",
      "n_iter: 2680/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.026, critic: 0.106, entropy: -2.220, ae: 0.108, lstm: 0.005\n",
      "Average reward: 0.501\n",
      "\n",
      "n_iter: 2690/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.011, critic: 0.132, entropy: -2.215, ae: 0.101, lstm: 0.004\n",
      "Average reward: 0.491\n",
      "\n",
      "n_iter: 2700/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.076, critic: 0.157, entropy: -2.209, ae: 0.105, lstm: 0.005\n",
      "Average reward: 0.461\n",
      "\n",
      "n_iter: 2710/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.005, critic: 0.122, entropy: -2.219, ae: 0.106, lstm: 0.005\n",
      "Average reward: 0.497\n",
      "\n",
      "n_iter: 2720/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.051, critic: 0.091, entropy: -2.215, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 2730/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.069, critic: 0.102, entropy: -2.220, ae: 0.105, lstm: 0.005\n",
      "Average reward: 0.514\n",
      "\n",
      "n_iter: 2740/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.078, critic: 0.177, entropy: -2.220, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.464\n",
      "\n",
      "n_iter: 2750/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.023, critic: 0.129, entropy: -2.210, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.486\n",
      "\n",
      "n_iter: 2760/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.072, critic: 0.157, entropy: -2.212, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.472\n",
      "\n",
      "n_iter: 2770/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.048, critic: 0.134, entropy: -2.220, ae: 0.101, lstm: 0.004\n",
      "Average reward: 0.467\n",
      "\n",
      "n_iter: 2780/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.075, critic: 0.094, entropy: -2.214, ae: 0.102, lstm: 0.005\n",
      "Average reward: 0.521\n",
      "\n",
      "n_iter: 2790/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.034, critic: 0.110, entropy: -2.214, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.509\n",
      "\n",
      "n_iter: 2800/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.045, critic: 0.148, entropy: -2.208, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.478\n",
      "\n",
      "n_iter: 2810/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.029, critic: 0.112, entropy: -2.213, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.507\n",
      "\n",
      "n_iter: 2820/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.054, critic: 0.095, entropy: -2.211, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 2830/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.075, critic: 0.093, entropy: -2.217, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.516\n",
      "\n",
      "n_iter: 2840/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.054, critic: 0.092, entropy: -2.212, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.507\n",
      "\n",
      "n_iter: 2850/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.023, critic: 0.138, entropy: -2.216, ae: 0.101, lstm: 0.005\n",
      "Average reward: 0.479\n",
      "\n",
      "n_iter: 2860/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.054, critic: 0.090, entropy: -2.218, ae: 0.103, lstm: 0.005\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 2870/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.043, critic: 0.094, entropy: -2.214, ae: 0.105, lstm: 0.005\n",
      "Average reward: 0.507\n",
      "\n",
      "n_iter: 2880/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.019, critic: 0.122, entropy: -2.217, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.488\n",
      "\n",
      "n_iter: 2890/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.064, critic: 0.088, entropy: -2.219, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.517\n",
      "\n",
      "n_iter: 2900/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.104, critic: 0.176, entropy: -2.219, ae: 0.100, lstm: 0.004\n",
      "Average reward: 0.448\n",
      "\n",
      "n_iter: 2910/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.046, critic: 0.097, entropy: -2.214, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.510\n",
      "\n",
      "n_iter: 2920/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.045, critic: 0.101, entropy: -2.213, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.509\n",
      "\n",
      "n_iter: 2930/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.006, critic: 0.127, entropy: -2.215, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.493\n",
      "\n",
      "n_iter: 2940/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.057, critic: 0.087, entropy: -2.212, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 2950/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.026, critic: 0.101, entropy: -2.214, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.503\n",
      "\n",
      "n_iter: 2960/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.036, critic: 0.130, entropy: -2.217, ae: 0.101, lstm: 0.004\n",
      "Average reward: 0.482\n",
      "\n",
      "n_iter: 2970/5000, grad norm: 0.000. Training block: full\n",
      "actor: -0.062, critic: 0.099, entropy: -2.216, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.524\n",
      "\n",
      "n_iter: 2980/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.102, critic: 0.172, entropy: -2.211, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.463\n",
      "\n",
      "n_iter: 2990/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.017, critic: 0.104, entropy: -2.215, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.501\n",
      "\n",
      "n_iter: 3000/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.027, critic: 0.104, entropy: -2.212, ae: 0.104, lstm: 0.005\n",
      "Average reward: 0.501\n",
      "\n",
      "n_iter: 3010/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.046, critic: 0.146, entropy: -2.217, ae: 0.106, lstm: 0.003\n",
      "Average reward: 0.477\n",
      "\n",
      "n_iter: 3020/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.004, critic: 0.113, entropy: -2.217, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.490\n",
      "\n",
      "n_iter: 3030/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.030, critic: 0.094, entropy: -2.220, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.499\n",
      "\n",
      "n_iter: 3040/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.102, critic: 0.169, entropy: -2.221, ae: 0.100, lstm: 0.004\n",
      "Average reward: 0.461\n",
      "\n",
      "n_iter: 3050/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.075, critic: 0.172, entropy: -2.219, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.468\n",
      "\n",
      "n_iter: 3060/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.006, critic: 0.115, entropy: -2.217, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.484\n",
      "\n",
      "n_iter: 3070/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.062, critic: 0.093, entropy: -2.216, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.511\n",
      "\n",
      "n_iter: 3080/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.006, critic: 0.131, entropy: -2.216, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.492\n",
      "\n",
      "n_iter: 3090/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.008, critic: 0.139, entropy: -2.210, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.493\n",
      "\n",
      "n_iter: 3100/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.073, critic: 0.097, entropy: -2.211, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.517\n",
      "\n",
      "n_iter: 3110/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.072, critic: 0.088, entropy: -2.214, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 3120/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.068, critic: 0.094, entropy: -2.208, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.514\n",
      "\n",
      "n_iter: 3130/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.005, critic: 0.129, entropy: -2.213, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.492\n",
      "\n",
      "n_iter: 3140/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.017, critic: 0.119, entropy: -2.210, ae: 0.105, lstm: 0.004\n",
      "Average reward: 0.500\n",
      "\n",
      "n_iter: 3150/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.005, critic: 0.133, entropy: -2.210, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.498\n",
      "\n",
      "n_iter: 3160/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.028, critic: 0.121, entropy: -2.216, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.497\n",
      "\n",
      "n_iter: 3170/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.072, critic: 0.090, entropy: -2.213, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.515\n",
      "\n",
      "n_iter: 3180/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.073, critic: 0.096, entropy: -2.217, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.518\n",
      "\n",
      "n_iter: 3190/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.002, critic: 0.126, entropy: -2.213, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.489\n",
      "\n",
      "n_iter: 3200/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.099, entropy: -2.214, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.509\n",
      "\n",
      "n_iter: 3210/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.052, critic: 0.096, entropy: -2.210, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.513\n",
      "\n",
      "n_iter: 3220/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.068, critic: 0.091, entropy: -2.213, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.519\n",
      "\n",
      "n_iter: 3230/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.004, critic: 0.117, entropy: -2.213, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.494\n",
      "\n",
      "n_iter: 3240/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.066, critic: 0.164, entropy: -2.206, ae: 0.105, lstm: 0.004\n",
      "Average reward: 0.475\n",
      "\n",
      "n_iter: 3250/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.027, critic: 0.104, entropy: -2.208, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.505\n",
      "\n",
      "n_iter: 3260/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.034, critic: 0.099, entropy: -2.202, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.506\n",
      "\n",
      "n_iter: 3270/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.033, critic: 0.103, entropy: -2.208, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.511\n",
      "\n",
      "n_iter: 3280/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.078, critic: 0.158, entropy: -2.212, ae: 0.101, lstm: 0.003\n",
      "Average reward: 0.471\n",
      "\n",
      "n_iter: 3290/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.058, critic: 0.096, entropy: -2.209, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.517\n",
      "\n",
      "n_iter: 3300/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.058, critic: 0.152, entropy: -2.215, ae: 0.101, lstm: 0.003\n",
      "Average reward: 0.476\n",
      "\n",
      "n_iter: 3310/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.053, critic: 0.089, entropy: -2.211, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.513\n",
      "\n",
      "n_iter: 3320/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.024, critic: 0.100, entropy: -2.208, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 3330/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.064, critic: 0.090, entropy: -2.210, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.521\n",
      "\n",
      "n_iter: 3340/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.025, critic: 0.093, entropy: -2.210, ae: 0.105, lstm: 0.004\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 3350/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.006, critic: 0.109, entropy: -2.210, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 3360/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.032, critic: 0.134, entropy: -2.202, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.488\n",
      "\n",
      "n_iter: 3370/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.014, critic: 0.107, entropy: -2.206, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.502\n",
      "\n",
      "n_iter: 3380/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.116, critic: 0.176, entropy: -2.203, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.457\n",
      "\n",
      "n_iter: 3390/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.040, critic: 0.098, entropy: -2.202, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.514\n",
      "\n",
      "n_iter: 3400/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.001, critic: 0.116, entropy: -2.212, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.499\n",
      "\n",
      "n_iter: 3410/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.019, critic: 0.099, entropy: -2.209, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.501\n",
      "\n",
      "n_iter: 3420/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.004, critic: 0.109, entropy: -2.208, ae: 0.105, lstm: 0.004\n",
      "Average reward: 0.489\n",
      "\n",
      "n_iter: 3430/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.022, critic: 0.097, entropy: -2.211, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.502\n",
      "\n",
      "n_iter: 3440/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.007, critic: 0.110, entropy: -2.205, ae: 0.105, lstm: 0.004\n",
      "Average reward: 0.499\n",
      "\n",
      "n_iter: 3450/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.065, critic: 0.093, entropy: -2.207, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.522\n",
      "\n",
      "n_iter: 3460/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.094, entropy: -2.206, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.520\n",
      "\n",
      "n_iter: 3470/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.008, critic: 0.118, entropy: -2.210, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.503\n",
      "\n",
      "n_iter: 3480/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.013, critic: 0.109, entropy: -2.210, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.500\n",
      "\n",
      "n_iter: 3490/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.091, entropy: -2.208, ae: 0.101, lstm: 0.003\n",
      "Average reward: 0.521\n",
      "\n",
      "n_iter: 3500/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.031, critic: 0.138, entropy: -2.210, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.489\n",
      "\n",
      "n_iter: 3510/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.027, critic: 0.124, entropy: -2.211, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.484\n",
      "\n",
      "n_iter: 3520/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.036, critic: 0.100, entropy: -2.212, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.511\n",
      "\n",
      "n_iter: 3530/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.034, critic: 0.100, entropy: -2.210, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.508\n",
      "\n",
      "n_iter: 3540/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.051, critic: 0.099, entropy: -2.211, ae: 0.100, lstm: 0.003\n",
      "Average reward: 0.522\n",
      "\n",
      "n_iter: 3550/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.051, critic: 0.134, entropy: -2.205, ae: 0.105, lstm: 0.003\n",
      "Average reward: 0.482\n",
      "\n",
      "n_iter: 3560/5000, grad norm: 0.000. Training block: full\n",
      "actor: -0.042, critic: 0.086, entropy: -2.209, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.510\n",
      "\n",
      "n_iter: 3570/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.029, critic: 0.097, entropy: -2.212, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.503\n",
      "\n",
      "n_iter: 3580/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.040, critic: 0.093, entropy: -2.210, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.510\n",
      "\n",
      "n_iter: 3590/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.069, critic: 0.099, entropy: -2.209, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.523\n",
      "\n",
      "n_iter: 3600/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.063, critic: 0.167, entropy: -2.206, ae: 0.101, lstm: 0.002\n",
      "Average reward: 0.480\n",
      "\n",
      "n_iter: 3610/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.043, critic: 0.094, entropy: -2.216, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 3620/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.056, critic: 0.088, entropy: -2.208, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.520\n",
      "\n",
      "n_iter: 3630/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.029, critic: 0.093, entropy: -2.204, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.508\n",
      "\n",
      "n_iter: 3640/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.016, critic: 0.119, entropy: -2.214, ae: 0.101, lstm: 0.003\n",
      "Average reward: 0.497\n",
      "\n",
      "n_iter: 3650/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.016, critic: 0.103, entropy: -2.214, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.502\n",
      "\n",
      "n_iter: 3660/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.025, critic: 0.139, entropy: -2.212, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.486\n",
      "\n",
      "n_iter: 3670/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.032, critic: 0.111, entropy: -2.215, ae: 0.100, lstm: 0.003\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 3680/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.046, critic: 0.155, entropy: -2.205, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.488\n",
      "\n",
      "n_iter: 3690/5000, grad norm: 0.000. Training block: full\n",
      "actor: -0.020, critic: 0.098, entropy: -2.209, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.503\n",
      "\n",
      "n_iter: 3700/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.051, critic: 0.088, entropy: -2.213, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.516\n",
      "\n",
      "n_iter: 3710/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.041, critic: 0.095, entropy: -2.214, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.509\n",
      "\n",
      "n_iter: 3720/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.014, critic: 0.102, entropy: -2.210, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.503\n",
      "\n",
      "n_iter: 3730/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.055, critic: 0.090, entropy: -2.210, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.518\n",
      "\n",
      "n_iter: 3740/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.042, critic: 0.089, entropy: -2.208, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.517\n",
      "\n",
      "n_iter: 3750/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.063, critic: 0.154, entropy: -2.208, ae: 0.101, lstm: 0.003\n",
      "Average reward: 0.479\n",
      "\n",
      "n_iter: 3760/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.039, critic: 0.129, entropy: -2.209, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.482\n",
      "\n",
      "n_iter: 3770/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.057, critic: 0.164, entropy: -2.214, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.478\n",
      "\n",
      "n_iter: 3780/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.060, critic: 0.093, entropy: -2.202, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.517\n",
      "\n",
      "n_iter: 3790/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.041, critic: 0.131, entropy: -2.206, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.482\n",
      "\n",
      "n_iter: 3800/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.047, critic: 0.093, entropy: -2.207, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.519\n",
      "\n",
      "n_iter: 3810/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.041, critic: 0.089, entropy: -2.208, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.511\n",
      "\n",
      "n_iter: 3820/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.002, critic: 0.114, entropy: -2.210, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.500\n",
      "\n",
      "n_iter: 3830/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.057, critic: 0.149, entropy: -2.210, ae: 0.101, lstm: 0.003\n",
      "Average reward: 0.476\n",
      "\n",
      "n_iter: 3840/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.070, critic: 0.091, entropy: -2.210, ae: 0.102, lstm: 0.004\n",
      "Average reward: 0.520\n",
      "\n",
      "n_iter: 3850/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.043, critic: 0.091, entropy: -2.208, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.513\n",
      "\n",
      "n_iter: 3860/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.011, critic: 0.122, entropy: -2.211, ae: 0.100, lstm: 0.003\n",
      "Average reward: 0.502\n",
      "\n",
      "n_iter: 3870/5000, grad norm: 0.000. Training block: full\n",
      "actor: -0.035, critic: 0.092, entropy: -2.207, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.511\n",
      "\n",
      "n_iter: 3880/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.047, critic: 0.087, entropy: -2.210, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.510\n",
      "\n",
      "n_iter: 3890/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.016, critic: 0.120, entropy: -2.205, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.495\n",
      "\n",
      "n_iter: 3900/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.057, critic: 0.141, entropy: -2.207, ae: 0.100, lstm: 0.003\n",
      "Average reward: 0.478\n",
      "\n",
      "n_iter: 3910/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.019, critic: 0.101, entropy: -2.208, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.508\n",
      "\n",
      "n_iter: 3920/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.004, critic: 0.111, entropy: -2.209, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.502\n",
      "\n",
      "n_iter: 3930/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.024, critic: 0.127, entropy: -2.210, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.495\n",
      "\n",
      "n_iter: 3940/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.057, critic: 0.151, entropy: -2.211, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.479\n",
      "\n",
      "n_iter: 3950/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.025, critic: 0.128, entropy: -2.209, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.490\n",
      "\n",
      "n_iter: 3960/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.050, critic: 0.087, entropy: -2.206, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.519\n",
      "\n",
      "n_iter: 3970/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.024, critic: 0.130, entropy: -2.203, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.492\n",
      "\n",
      "n_iter: 3980/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.016, critic: 0.130, entropy: -2.207, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.499\n",
      "\n",
      "n_iter: 3990/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.024, critic: 0.114, entropy: -2.212, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.509\n",
      "\n",
      "n_iter: 4000/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.020, critic: 0.115, entropy: -2.209, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.505\n",
      "\n",
      "n_iter: 4010/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.006, critic: 0.114, entropy: -2.211, ae: 0.101, lstm: 0.003\n",
      "Average reward: 0.500\n",
      "\n",
      "n_iter: 4020/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.034, critic: 0.099, entropy: -2.209, ae: 0.104, lstm: 0.004\n",
      "Average reward: 0.509\n",
      "\n",
      "n_iter: 4030/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.011, critic: 0.126, entropy: -2.205, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.496\n",
      "\n",
      "n_iter: 4040/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.011, critic: 0.113, entropy: -2.209, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.499\n",
      "\n",
      "n_iter: 4050/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.041, critic: 0.088, entropy: -2.211, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.509\n",
      "\n",
      "n_iter: 4060/5000, grad norm: 0.000. Training block: full\n",
      "actor: -0.044, critic: 0.096, entropy: -2.211, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.513\n",
      "\n",
      "n_iter: 4070/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.027, critic: 0.108, entropy: -2.212, ae: 0.101, lstm: 0.003\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 4080/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.018, critic: 0.122, entropy: -2.208, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.503\n",
      "\n",
      "n_iter: 4090/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.024, critic: 0.105, entropy: -2.201, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.507\n",
      "\n",
      "n_iter: 4100/5000, grad norm: 0.000. Training block: full\n",
      "actor: -0.046, critic: 0.107, entropy: -2.205, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.524\n",
      "\n",
      "n_iter: 4110/5000, grad norm: 0.000. Training block: full\n",
      "actor: -0.038, critic: 0.087, entropy: -2.206, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 4120/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.010, critic: 0.128, entropy: -2.197, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.501\n",
      "\n",
      "n_iter: 4130/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.015, critic: 0.106, entropy: -2.204, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.505\n",
      "\n",
      "n_iter: 4140/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.033, critic: 0.099, entropy: -2.207, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 4150/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.031, critic: 0.120, entropy: -2.208, ae: 0.105, lstm: 0.003\n",
      "Average reward: 0.492\n",
      "\n",
      "n_iter: 4160/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.026, critic: 0.116, entropy: -2.204, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.493\n",
      "\n",
      "n_iter: 4170/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.049, critic: 0.089, entropy: -2.204, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.517\n",
      "\n",
      "n_iter: 4180/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.029, critic: 0.098, entropy: -2.211, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 4190/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.007, critic: 0.104, entropy: -2.208, ae: 0.100, lstm: 0.003\n",
      "Average reward: 0.501\n",
      "\n",
      "n_iter: 4200/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.043, critic: 0.089, entropy: -2.208, ae: 0.101, lstm: 0.003\n",
      "Average reward: 0.518\n",
      "\n",
      "n_iter: 4210/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.045, critic: 0.085, entropy: -2.211, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.516\n",
      "\n",
      "n_iter: 4220/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.009, critic: 0.108, entropy: -2.205, ae: 0.103, lstm: 0.004\n",
      "Average reward: 0.506\n",
      "\n",
      "n_iter: 4230/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.034, critic: 0.093, entropy: -2.208, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.514\n",
      "\n",
      "n_iter: 4240/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.001, critic: 0.107, entropy: -2.214, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.501\n",
      "\n",
      "n_iter: 4250/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.013, critic: 0.127, entropy: -2.206, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.496\n",
      "\n",
      "n_iter: 4260/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.010, critic: 0.116, entropy: -2.209, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.494\n",
      "\n",
      "n_iter: 4270/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.019, critic: 0.106, entropy: -2.208, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 4280/5000, grad norm: 0.000. Training block: full\n",
      "actor: -0.016, critic: 0.122, entropy: -2.205, ae: 0.105, lstm: 0.003\n",
      "Average reward: 0.508\n",
      "\n",
      "n_iter: 4290/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.035, critic: 0.094, entropy: -2.205, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.513\n",
      "\n",
      "n_iter: 4300/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.060, critic: 0.092, entropy: -2.208, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.516\n",
      "\n",
      "n_iter: 4310/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.029, critic: 0.115, entropy: -2.208, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.508\n",
      "\n",
      "n_iter: 4320/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.028, critic: 0.105, entropy: -2.211, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.506\n",
      "\n",
      "n_iter: 4330/5000, grad norm: 0.000. Training block: full\n",
      "actor: -0.037, critic: 0.094, entropy: -2.208, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.509\n",
      "\n",
      "n_iter: 4340/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.025, critic: 0.148, entropy: -2.210, ae: 0.102, lstm: 0.002\n",
      "Average reward: 0.494\n",
      "\n",
      "n_iter: 4350/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.047, critic: 0.148, entropy: -2.211, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.486\n",
      "\n",
      "n_iter: 4360/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.039, critic: 0.092, entropy: -2.208, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 4370/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.044, critic: 0.137, entropy: -2.207, ae: 0.101, lstm: 0.003\n",
      "Average reward: 0.483\n",
      "\n",
      "n_iter: 4380/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.039, critic: 0.089, entropy: -2.215, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 4390/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.007, critic: 0.127, entropy: -2.205, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 4400/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.048, critic: 0.099, entropy: -2.202, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.509\n",
      "\n",
      "n_iter: 4410/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.069, critic: 0.085, entropy: -2.205, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.520\n",
      "\n",
      "n_iter: 4420/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.041, critic: 0.136, entropy: -2.218, ae: 0.100, lstm: 0.003\n",
      "Average reward: 0.475\n",
      "\n",
      "n_iter: 4430/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.016, critic: 0.123, entropy: -2.205, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.503\n",
      "\n",
      "n_iter: 4440/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.093, critic: 0.184, entropy: -2.205, ae: 0.105, lstm: 0.002\n",
      "Average reward: 0.471\n",
      "\n",
      "n_iter: 4450/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.009, critic: 0.135, entropy: -2.218, ae: 0.099, lstm: 0.003\n",
      "Average reward: 0.493\n",
      "\n",
      "n_iter: 4460/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.022, critic: 0.117, entropy: -2.213, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.497\n",
      "\n",
      "n_iter: 4470/5000, grad norm: 0.000. Training block: full\n",
      "actor: -0.005, critic: 0.120, entropy: -2.212, ae: 0.101, lstm: 0.003\n",
      "Average reward: 0.502\n",
      "\n",
      "n_iter: 4480/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.027, critic: 0.097, entropy: -2.215, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 4490/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.049, critic: 0.148, entropy: -2.208, ae: 0.105, lstm: 0.003\n",
      "Average reward: 0.488\n",
      "\n",
      "n_iter: 4500/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.053, critic: 0.092, entropy: -2.208, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.519\n",
      "\n",
      "n_iter: 4510/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.057, critic: 0.088, entropy: -2.203, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.524\n",
      "\n",
      "n_iter: 4520/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.020, critic: 0.127, entropy: -2.208, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.490\n",
      "\n",
      "n_iter: 4530/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.064, critic: 0.152, entropy: -2.212, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.478\n",
      "\n",
      "n_iter: 4540/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.007, critic: 0.120, entropy: -2.218, ae: 0.100, lstm: 0.002\n",
      "Average reward: 0.490\n",
      "\n",
      "n_iter: 4550/5000, grad norm: 0.000. Training block: full\n",
      "actor: -0.024, critic: 0.110, entropy: -2.208, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.509\n",
      "\n",
      "n_iter: 4560/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.024, critic: 0.095, entropy: -2.211, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.502\n",
      "\n",
      "n_iter: 4570/5000, grad norm: 0.000. Training block: full\n",
      "actor: -0.022, critic: 0.099, entropy: -2.208, ae: 0.102, lstm: 0.002\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 4580/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.027, critic: 0.102, entropy: -2.209, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 4590/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.005, critic: 0.111, entropy: -2.208, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.503\n",
      "\n",
      "n_iter: 4600/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.032, critic: 0.097, entropy: -2.209, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.513\n",
      "\n",
      "n_iter: 4610/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.002, critic: 0.112, entropy: -2.210, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.507\n",
      "\n",
      "n_iter: 4620/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.057, critic: 0.098, entropy: -2.205, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.519\n",
      "\n",
      "n_iter: 4630/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.027, critic: 0.093, entropy: -2.211, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.506\n",
      "\n",
      "n_iter: 4640/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.043, critic: 0.088, entropy: -2.208, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.515\n",
      "\n",
      "n_iter: 4650/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.041, critic: 0.092, entropy: -2.205, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.518\n",
      "\n",
      "n_iter: 4660/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.054, critic: 0.090, entropy: -2.213, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.515\n",
      "\n",
      "n_iter: 4670/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.040, critic: 0.094, entropy: -2.209, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.517\n",
      "\n",
      "n_iter: 4680/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.006, critic: 0.121, entropy: -2.207, ae: 0.102, lstm: 0.002\n",
      "Average reward: 0.498\n",
      "\n",
      "n_iter: 4690/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.045, critic: 0.098, entropy: -2.217, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 4700/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.042, critic: 0.095, entropy: -2.202, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.518\n",
      "\n",
      "n_iter: 4710/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.048, critic: 0.143, entropy: -2.212, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.477\n",
      "\n",
      "n_iter: 4720/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.029, critic: 0.100, entropy: -2.213, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.507\n",
      "\n",
      "n_iter: 4730/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.015, critic: 0.110, entropy: -2.211, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.501\n",
      "\n",
      "n_iter: 4740/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.051, critic: 0.105, entropy: -2.222, ae: 0.101, lstm: 0.003\n",
      "Average reward: 0.512\n",
      "\n",
      "n_iter: 4750/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.031, critic: 0.114, entropy: -2.209, ae: 0.100, lstm: 0.003\n",
      "Average reward: 0.507\n",
      "\n",
      "n_iter: 4760/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.005, critic: 0.110, entropy: -2.213, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.497\n",
      "\n",
      "n_iter: 4770/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.064, critic: 0.091, entropy: -2.209, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.516\n",
      "\n",
      "n_iter: 4780/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.007, critic: 0.121, entropy: -2.210, ae: 0.100, lstm: 0.002\n",
      "Average reward: 0.501\n",
      "\n",
      "n_iter: 4790/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.010, critic: 0.107, entropy: -2.209, ae: 0.101, lstm: 0.003\n",
      "Average reward: 0.496\n",
      "\n",
      "n_iter: 4800/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.019, critic: 0.118, entropy: -2.219, ae: 0.101, lstm: 0.003\n",
      "Average reward: 0.504\n",
      "\n",
      "n_iter: 4810/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.002, critic: 0.125, entropy: -2.207, ae: 0.102, lstm: 0.002\n",
      "Average reward: 0.501\n",
      "\n",
      "n_iter: 4820/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.001, critic: 0.115, entropy: -2.214, ae: 0.103, lstm: 0.002\n",
      "Average reward: 0.498\n",
      "\n",
      "n_iter: 4830/5000, grad norm: 0.000. Training block: full\n",
      "actor: -0.032, critic: 0.105, entropy: -2.210, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.505\n",
      "\n",
      "n_iter: 4840/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.038, critic: 0.103, entropy: -2.214, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.509\n",
      "\n",
      "n_iter: 4850/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.028, critic: 0.134, entropy: -2.213, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.483\n",
      "\n",
      "n_iter: 4860/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.033, critic: 0.130, entropy: -2.210, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.481\n",
      "\n",
      "n_iter: 4870/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.031, critic: 0.135, entropy: -2.214, ae: 0.101, lstm: 0.002\n",
      "Average reward: 0.486\n",
      "\n",
      "n_iter: 4880/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.043, critic: 0.134, entropy: -2.217, ae: 0.099, lstm: 0.003\n",
      "Average reward: 0.477\n",
      "\n",
      "n_iter: 4890/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.058, critic: 0.090, entropy: -2.211, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.518\n",
      "\n",
      "n_iter: 4900/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.032, critic: 0.099, entropy: -2.213, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.513\n",
      "\n",
      "n_iter: 4910/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.023, critic: 0.119, entropy: -2.206, ae: 0.104, lstm: 0.003\n",
      "Average reward: 0.510\n",
      "\n",
      "n_iter: 4920/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.038, critic: 0.094, entropy: -2.209, ae: 0.101, lstm: 0.003\n",
      "Average reward: 0.510\n",
      "\n",
      "n_iter: 4930/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.052, critic: 0.096, entropy: -2.215, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.515\n",
      "\n",
      "n_iter: 4940/5000, grad norm: 0.000. Training block: full\n",
      "actor: -0.025, critic: 0.098, entropy: -2.214, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.508\n",
      "\n",
      "n_iter: 4950/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.051, critic: 0.090, entropy: -2.212, ae: 0.102, lstm: 0.002\n",
      "Average reward: 0.513\n",
      "\n",
      "n_iter: 4960/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.024, critic: 0.127, entropy: -2.213, ae: 0.102, lstm: 0.003\n",
      "Average reward: 0.490\n",
      "\n",
      "n_iter: 4970/5000, grad norm: 0.001. Training block: full\n",
      "actor: -0.004, critic: 0.111, entropy: -2.210, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.502\n",
      "\n",
      "n_iter: 4980/5000, grad norm: 0.000. Training block: full\n",
      "actor: -0.057, critic: 0.090, entropy: -2.211, ae: 0.103, lstm: 0.003\n",
      "Average reward: 0.515\n",
      "\n",
      "n_iter: 4990/5000, grad norm: 0.001. Training block: full\n",
      "actor: 0.010, critic: 0.126, entropy: -2.211, ae: 0.102, lstm: 0.002\n",
      "Average reward: 0.492\n",
      "\n"
     ]
    }
   ],
   "source": [
    "progress_m = train(\n",
    "    agent = agent_m, \n",
    "    num_iterations = [1000, 2000, 2000, 5000], \n",
    "    iter_per_batch = [1, 1, 2, 2], \n",
    "    blocks = [['ae'], ['lstm'], ['actor', 'critic'], ['full']]\n",
    ")\n",
    "\n",
    "filename = 'stats_m_low_entr.json'\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(progress_m, f, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'stats_m'\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(progress_m, f, indent = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
